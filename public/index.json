[{"authors":["admin"],"categories":null,"content":"I am a Senior Lecturer in the Department of Statistics, Faculty of Applied Sciences at the University of Sri Jayewardenepura. I received my PhD in statistics from Monash University, Australia in 2019. My thesis advisors were Professor Rob J Hyndman and Professor George Athanasopoulos.\nI was an Associate Investigator of the Australian Research Council (ARC) Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS).\nI am a co-founder and co-organizer of RLadies-Colombo, Sri Lanka, a local chapter of R-Ladies Global, an organization that promotes diversity in the R community worldwide. I served as the coordinator of the statistical consulting service, University of Sri Jayewardenepura from 2020 to 2023.\nI enjoy solving general data science problems from three different angles: theoretical, computational, applied. On this website you will find some of my work and interests in statistics and data analysis. My research focuses on developing new statistical machine learning tools to help both practitioners and theoreticians make more open, explainable and reproducible data-driven discoveries. I am also interested in R and Python programming language.\nPriyanga Dilini Talagala PhD in Statistics, Monash University, Australia is my sister.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://thiyanga.netlify.app/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Senior Lecturer in the Department of Statistics, Faculty of Applied Sciences at the University of Sri Jayewardenepura. I received my PhD in statistics from Monash University, Australia in 2019. My thesis advisors were Professor Rob J Hyndman and Professor George Athanasopoulos.\nI was an Associate Investigator of the Australian Research Council (ARC) Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS).\nI am a co-founder and co-organizer of RLadies-Colombo, Sri Lanka, a local chapter of R-Ladies Global, an organization that promotes diversity in the R community worldwide.","tags":null,"title":"Thiyanga S. Talagala","type":"authors"},{"authors":null,"categories":null,"content":"STA 474 2.0 Statistical Consultancy BSc (Hons) Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Year and Semester: 2022 - Semester 2\nCommencement date: 09 December 2022\nCourse meeting time: Friday, 1.00pm - 3.00pm\nLocation: Online/ Department of Statistics, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Tuesday 3:00pm â€“ 4:00pm. Email me for other times.\nE-mail is the best way to get in contact with meâ€”I will respond to all course-related e-mails within 24 hours.\nTools: To consultants Course outline\n1. Slides\nClick here\n2. Gitrepo\nClick here\n3. Project log form\npdf\nrmd\nTools: To clients website: https://scs-fas-sjp.netlify.app/\n","date":1635033600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1635120000,"objectID":"3a130f328988b10d10283d7b42e339ef","permalink":"https://thiyanga.netlify.app/courses/statisticalconsultancy/","publishdate":"2021-10-24T00:00:00Z","relpermalink":"/courses/statisticalconsultancy/","section":"courses","summary":"STA 474 2.0 Statistical Consultancy BSc (Hons) Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Year and Semester: 2022 - Semester 2\nCommencement date: 09 December 2022\nCourse meeting time: Friday, 1.00pm - 3.00pm\nLocation: Online/ Department of Statistics, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Tuesday 3:00pm â€“ 4:00pm. Email me for other times.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"STA 331 2.0 Stochastic Processes BSc (Hons) Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 2\nCommencement date: 28 July 2020\nCourse meeting time: Tuesday, 1.00pm - 3.00pm\nLocation: Online/ Department of Statistics, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Tuesday 3:00pm â€“ 4:00pm. Email me for other times.\nE-mail is the best way to get in contact with meâ€”I will respond to all course-related e-mails within 24 hours.\n","date":1595894400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1595894400,"objectID":"9c0788947d26d9a05e0fbb26729f15b0","permalink":"https://thiyanga.netlify.app/courses/sta33120_stochastic_processes_2020/","publishdate":"2020-07-28T00:00:00Z","relpermalink":"/courses/sta33120_stochastic_processes_2020/","section":"courses","summary":"STA 331 2.0 Stochastic Processes BSc (Hons) Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 2\nCommencement date: 28 July 2020\nCourse meeting time: Tuesday, 1.00pm - 3.00pm\nLocation: Online/ Department of Statistics, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Tuesday 3:00pm â€“ 4:00pm.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"STA 506 2.0 Linear Regression Analysis Postgraduate Certificate Program in Applied Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 1\nCommencement date: 29 August 2020\nCourse meeting time: Saturday, 2.00pm - 4.00pm\nLocation: Online/ LCS 2, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nSoftware: R programming language\nContact Information Lecturer-in-charge: Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Saturday 4:00pm â€“ 5:00pm. Email me for other times.\nE-mail is the best way to get in contact with meâ€”I will respond to all course-related e-mails within 24 hours.\n","date":1594339200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1594339200,"objectID":"2316a50c2857ebd9e6743a52e272832e","permalink":"https://thiyanga.netlify.app/courses/regression2020/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/courses/regression2020/","section":"courses","summary":"STA 506 2.0 Linear Regression Analysis Postgraduate Certificate Program in Applied Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 1\nCommencement date: 29 August 2020\nCourse meeting time: Saturday, 2.00pm - 4.00pm\nLocation: Online/ LCS 2, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nSoftware: R programming language\nContact Information Lecturer-in-charge: Dr Thiyanga S Talagala","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"STA 517 3.0 Programming and Statistical Computing with R MSc in Applied Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 1\nCommencement date: 15 August 2020\nCourse meeting time: Sunday, 10.15am - 1.15pm\nLocation: Online/ Stat Lab 1, Faculty of Applied Sciences, USJ\nPlease enrol in Google classroom and LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Sunday 1.15pm â€“ 2:15pm. Email me for other times.\nE-mail is the best way to get in contact with meâ€”I will respond to all course-related e-mails within 24 hours.\n","date":1594339200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1594339200,"objectID":"f08e411187c6e9f4f47b869608e89e00","permalink":"https://thiyanga.netlify.app/courses/rmsc2020/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/courses/rmsc2020/","section":"courses","summary":"STA 517 3.0 Programming and Statistical Computing with R MSc in Applied Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 1\nCommencement date: 15 August 2020\nCourse meeting time: Sunday, 10.15am - 1.15pm\nLocation: Online/ Stat Lab 1, Faculty of Applied Sciences, USJ\nPlease enrol in Google classroom and LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"","date":1635202800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635202800,"objectID":"d22b2f6828596d8f93868ae6177e5d04","permalink":"https://thiyanga.netlify.app/courses/statisticalconsultancy/contentcon/","publishdate":"2021-10-26T00:00:00+01:00","relpermalink":"/courses/statisticalconsultancy/contentcon/","section":"courses","summary":"","tags":null,"title":"STA 474 2.0 Statistical Consultancy","type":"docs"},{"authors":null,"categories":null,"content":"Here is your road map for the course!\nWeek 1 Introduction Week 2 - 3 Markov Chains ğŸ“š Individual Assignment - week 3\nWeek 4 Classification of states Week 5 Limiting Probabilities Week ( 1 September 2020 ) Holiday\nWeek 6 Continuous Parameter Markov Chains Week 7 - 8 Week 7 ğŸ“š In-class assignment\nWeek 7 - 8 Poisson Process (cont.), Interarrival and Waiting Time Distributions\nAssignment discussion.\nWeek 9 Poisson Process (cont.), Splitting of a Poisson process, Compound Poisson processes Week 10 Ion Switching| Kaggle competition\nWeek 11 Nonhomogeneous Poisson Processes Week 12 - 14 Birth and death process - Introduction, Pure Birth Process\nPartial Differential Equations\nPure Death Process\nAnswers for Pure Death Process - Download from LMS\nAssignment 3: Please go the LMS (Due date: 24 Nov 2020)\nBirth-and-Death Process\nBirth-and-Death Process - important results\nWeek 15 Birth-and-Death Process - important results (cont) Revision\nIndividual Presentations - SIR models\nPast papers Visit LMS\nResources Visual Explanation of Markov Chains\nEND\n","date":1595804400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595804400,"objectID":"e12b40334feab19bbc61f3993d464904","permalink":"https://thiyanga.netlify.app/courses/sta33120_stochastic_processes_2020/contentr_stochastic/","publishdate":"2020-07-27T00:00:00+01:00","relpermalink":"/courses/sta33120_stochastic_processes_2020/contentr_stochastic/","section":"courses","summary":"Here is your road map for the course!\nWeek 1 Introduction Week 2 - 3 Markov Chains ğŸ“š Individual Assignment - week 3\nWeek 4 Classification of states Week 5 Limiting Probabilities Week ( 1 September 2020 ) Holiday\nWeek 6 Continuous Parameter Markov Chains Week 7 - 8 Week 7 ğŸ“š In-class assignment\nWeek 7 - 8 Poisson Process (cont.), Interarrival and Waiting Time Distributions\nAssignment discussion.\nWeek 9 Poisson Process (cont.","tags":null,"title":"STA 331 2.0 Stochastic Processes","type":"docs"},{"authors":null,"categories":null,"content":"Here is your road map for the course!\nWeek 1-4: lectures (online)\nWeek 1 Introduction to regression analysis\nSimple linear regression\nTerminologies\nCorrelation\nğŸ“šSlides ğŸ“’ [Reading-Ch1 Introduction to Linear Regression Analysis] ğŸ“Š Data Sets - anscombe ğŸ“ Problems - Install R and R studio ğŸ”–Answers Week 2 - 3 Simple linear regression (cont.)\nSimple linear regression model\nLeast-squares estimation of the parameters\nğŸ“šSlides ğŸ“’ [Reading-Ch2/2.2.2 Introduction to Linear Regression Analysis] ğŸ“Š Data Sets - alr3::heights ğŸ“ Problems ğŸ”–Answers - Discussions Week 4 Simple linear regression (cont.)\nModel adequacy checking\nIntroduction\nResidual Analysis\nğŸ“šSlides ğŸ“’ Reading - Ch1 (2.6) and Ch4 (4.2.3) ğŸ“Š Data Sets ğŸ“ Problems ğŸ”–Answers Week 5-6: Discussion/practical (in class)\nWeek 5 - 6 Coefficient of determination\nHypothesis testing on the slope and intercept\nInterval estimation in simple linear regression\nPrediction of new observations: point estimates and prediction intervals\nRegression through the origin\nRegression analysis with R\nProblem discussion and Regression Analysis with R\nRegression analysis with other software (Python, Minitab, SPSS, Excel) ğŸ“š\nğŸ“š 1. Slides 2. Basics of R Programming ğŸ“’ Reading - Ch1 and Ch2 (2.3, 2.4) ğŸ“Š Data Set - house.csv ğŸ“ Problems Tutorial 2 ğŸ”– Additional problems - Ch2 Problems: 2.1 - 2.17 *\nWeek 7 - 8: lectures (online)\nWeek 7 R for Reproducible Scientific Analysis - Visit Google Classroom\nAssignment due: 19 Oct 2020\nMid Exam: Cancelled due to Covid-19 Outbreak\nWeek 8 Multiple linear regression\nIntroduction\nEstimation of the model parameters\nResidual analysis\nğŸ“š Slides ğŸ“’ Reading - Ch3 ğŸ“Š Data Sets - heart.data.csv ğŸ“ Problems ğŸ”–Answers Week 9 ANOVA\nTest of significance of regression\nTests on individual regression coefficients\nğŸ“š Slides ğŸ“’ Reading - here ğŸ“Š Data Sets - heart.data.csv and alr3::heights ğŸ“ Problems - Quiz Google Classroom ğŸ”–Answers Week 10 Confidence intervals in multiple regression\nConfidence intervals on the regression coefficients\nConfidence interval estimation of the mean response\nPrediction of new observations\nMid Evaluation Assignment - Visit LMS/ Google Classroom (1 Nov 2020) ğŸ“ Assignment deadline: 15 Nov 2020\nSpecial considerations email me on or before 8 Nov 2020\nğŸ“š Slides ğŸ“’ Reading - Chapter 3, Montgomery, Peck, Vining ğŸ“Š Data Sets ğŸ“ Problems ğŸ”–Answers Week 11 Transformations\nVariance-stabilization transformations\nTransformations to linearize the model\nAnalytical methods for selecting a transformation\nğŸ“šSlides ğŸ“’ Reading - Section 3.3, Montgomery, Peck, Vining ğŸ“Š Data Sets - coconut.csv salarydata.csv ğŸ“ Problems ğŸ”–Answers 14 November 2020 - Public Holiday (Deepavali Festival Day) Week 12 Detection and treatment of outliers\nDiagnostics for leverage and influence\nImportance of detecting influential observations\nLeverage\nMeasures of influence\nTreatment of influential observations\nRegression with qualitative variables\nIndicator/ Dummy variables\nIndicator variable with more than two levels\nMore than one indicator variable\nInteraction term involving dummy variables\nğŸ“š Slides-i Slides-ii ğŸ“’ Reading - Ch6, 11.1, Ch8 (Montgomery, Peck, Vining) ğŸ“Š Data Sets - see slides ğŸ“ Problems ğŸ”–Answers - see Week 13 discussion notes Week 13-14: Discussion/practical (live - zoom)\nWeek 13 Variable selection procedures\nIntroduction\nAll possible regressions\nForward selection procedure\nBackward elimination procedure\nStepwise method\nğŸ“š Slides ğŸ“’ Reading - Ch 9 ğŸ“Š Data Sets -\treal-estate.csv ğŸ“ Problems ğŸ”–Answers - Inclass discussion Week 14 Multicollinearity\nIntroduction\nMultocollinearity diagnostics\nTreatments for dealing with multicollinearity\nBootstrapping in regression\nIntroduction to bootstrap sampling\nBootstrap sampling in regression\nBootsrap confidence intervals\nğŸ“šSlides - 1 Slides - 2 ğŸ“’ Reading - Ch 10 ğŸ“Š Data Sets-bloodpressure ğŸ“ Problems ğŸ”–Answers - Inclass discussion Mid semester examination - Answer discussions.\nModel questions: Download from the Google Classroom. We will discuss answers next week (12 Dec 2020).\nWeek 15: Revision (live - zoom)\nWeek 15: Revision Current state-of-art techniques in regression analysis and statistical modelling\nModel questions: Discuss answers\nOpen problems\nRecap\nğŸ“šSlides ğŸ“’ Reading ğŸ“Š Data Sets ğŸ“ Problems ğŸ”–Answers Week 16-18: Study leave and Final Examination\nWeek 16: Study leave Week 17-18: Final exam END\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"d970c4b18ab5d5a91afd734ef95f973b","permalink":"https://thiyanga.netlify.app/courses/regression2020/contentreg/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/regression2020/contentreg/","section":"courses","summary":"Here is your road map for the course!\nWeek 1-4: lectures (online)\nWeek 1 Introduction to regression analysis\nSimple linear regression\nTerminologies\nCorrelation\nğŸ“šSlides ğŸ“’ [Reading-Ch1 Introduction to Linear Regression Analysis] ğŸ“Š Data Sets - anscombe ğŸ“ Problems - Install R and R studio ğŸ”–Answers Week 2 - 3 Simple linear regression (cont.)\nSimple linear regression model\nLeast-squares estimation of the parameters\nğŸ“šSlides ğŸ“’ [Reading-Ch2/2.2.2 Introduction to Linear Regression Analysis] ğŸ“Š Data Sets - alr3::heights ğŸ“ Problems ğŸ”–Answers - Discussions Week 4 Simple linear regression (cont.","tags":null,"title":"Schedule and Lectorials","type":"docs"},{"authors":null,"categories":null,"content":"Here is your road map for the course!\nWeek 0 Help - R and R Studio Download and Install\nğŸ“—\nWeek 1-2: lectures (online)\nWeek 1 Introduction and basics of R programming ğŸ“šSlides ğŸ“’ Reading-2.1, 2.2, 5.1 ğŸ“Š Data Sets ğŸ“ Problems ğŸ”–Answers Week 2 Data structures (Matrices, Arrays, List, Data frames, Factors) ğŸ“šSlides ğŸ“’ Reading-5.3, 5.8 ğŸ“Š Cheat sheet ğŸ“ Problems ğŸ”– Answers Week 3-7: lectures (in-class)\nWeek 3 Built-in functions in R ğŸ“šSlides ğŸ“’ Reading-Section 2.3 ğŸ“Š Data Sets - iris ğŸ“ Problems - EDA on iris ğŸ”–Answers - In class discussion (13 Sep 2020) Week 4 Writing functions in R and control structures ğŸ“šSlides ğŸ“’ Reading-Section 2.3 ğŸ“Š Data Sets ğŸ“ Problems ğŸ”–Answers ğŸ’»\nWeek 5 Introduction to the tidyverse, pipe operator and data import and export ğŸ“š Slides ğŸ“’ Reading ğŸ“Š Data Sets ğŸ“ Problems ğŸ”–Answers Week 6 Reproducible reporting with R Markdown ğŸ“š Slides ğŸ“’ Reading ğŸ“Š Data Sets ğŸ“ Problems ğŸ”–Answers Week 7: mid exam (in class) Week 8-12: lectures (online): Covid-19 outbreak\nWeek 8 Data wrangling with tidyr ğŸ“š Slides ğŸ“’ Reading -R4DS Ch12 ğŸ“Š Cheat sheet ğŸ“ Problems ğŸ”–Answers Data wrangling with dplyr ğŸ“š Slides ğŸ“’ Reading -R4DS Ch12 ğŸ“Š Cheat sheet ğŸ“ Problems ğŸ”– Answers Week 9 The grammar of graphics ğŸ“š Slides ğŸ“’ Reading ğŸ“Š Data Sets - Details ğŸ“ Problems\t- Perform EDA on palmerpenguins using ggplot2 ğŸ”–Answers Load palmerpenguins using,\nlibrary(palmerpenguins) data(package = \u0026#39;palmerpenguins\u0026#39;) Week 10 Statistical modelling - Regression Analysis ğŸ“š Slides ğŸ“’ Reading ğŸ“Š Data Sets -\tihouse.csv ğŸ“ Problems - i ğŸ”–Answers Week 11 Methods of generating random numbers ğŸ“š Slides ğŸ“’ Reading ğŸ“Š Data Sets ğŸ“ Problems ğŸ”– Answers Week 12 Functional programming with R ğŸ“šSlides - part 1 Slides - part 2 ğŸ“’ Reading ğŸ“Š Cheat sheet ğŸ“ Problems ğŸ”– Answers Week 13-14: Discussion/practical (in class)\nWeek 13 Hypothesis testing ğŸ“šSlides ğŸ“’ Reading ğŸ“Š Data Sets ğŸ“ Problems ğŸ”– Answers The method of Monte Carlo ğŸ“šSlides ğŸ“’ Reading ğŸ“Š Data Sets ğŸ“ Problems - Questions given in the note. ğŸ”–Answers Assignment (10 marks): Details visit google classroom or LMS. Week 14 Bootstrap and Jackknife ğŸ“š Slides ğŸ“’ Reading ğŸ“Š Data Sets - iris ğŸ“ Problems ğŸ”–Answers Week 15: Revision (live zoom)\nWeek 15: Revision ğŸ“š Recap ğŸ“’ Model questions and Answers - Download from google classroom Mid semester examination - Answer discussions. Week 16-18: Study leave and Final Examination\nWeek 16: Study leave Week 17-18: Final exam END\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"5441d486ec4b5f6f38fe81b1ec82b3d5","permalink":"https://thiyanga.netlify.app/courses/rmsc2020/contentr/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/rmsc2020/contentr/","section":"courses","summary":"Here is your road map for the course!\nWeek 0 Help - R and R Studio Download and Install\nğŸ“—\nWeek 1-2: lectures (online)\nWeek 1 Introduction and basics of R programming ğŸ“šSlides ğŸ“’ Reading-2.1, 2.2, 5.1 ğŸ“Š Data Sets ğŸ“ Problems ğŸ”–Answers Week 2 Data structures (Matrices, Arrays, List, Data frames, Factors) ğŸ“šSlides ğŸ“’ Reading-5.3, 5.8 ğŸ“Š Cheat sheet ğŸ“ Problems ğŸ”– Answers Week 3-7: lectures (in-class)\nWeek 3 Built-in functions in R ğŸ“šSlides ğŸ“’ Reading-Section 2.","tags":null,"title":"Schedule and Lectorials","type":"docs"},{"authors":null,"categories":["ggplot2"],"content":"Florence Nightingale showed the world that data can save lives.\nToday, February 11, is recognized globally as the International Day of Women and Girls in Science. To mark this day, I recreated Florence Nightingaleâ€™s famous Coxcomb chart using R programming with hashtag#tidyverse mainly using hashtag#tidyr hashtag#dplyr and hashtag#ggplot2. It was one of the earliest and most powerful examples of data visualization influencing public policy.\nNightingale was not only a nurse but also a statistician. At a time when women had limited access to science, she used data to demonstrate that more soldiers were dying from preventable diseases than from battle wounds during the Crimean War. Her visualization changed healthcare policy. This plot is a reminder that:\nâ€¢ Data is powerful when communicated clearly.\nâ€¢ Visualization is not just decoration. It is evidence.\nâ€¢ Science needs more women and more visible role models.\n#rprogramming #InternationalDayOfWomenAndGirlsInScience #WomenInScience #FlorenceNightingale #DataVisualization #WomenInSTEM #GirlsInScience #OWSD\n## Packages library(tidyverse) library(HistData) ## Data data(\u0026#34;Nightingale\u0026#34;) glimpse(Nightingale) ## Rows: 24\r## Columns: 10\r## $ Date \u0026lt;date\u0026gt; 1854-04-01, 1854-05-01, 1854-06-01, 1854-07-01, 1854-08-â€¦\r## $ Month \u0026lt;ord\u0026gt; Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec, Jan, Feb, Maâ€¦\r## $ Year \u0026lt;int\u0026gt; 1854, 1854, 1854, 1854, 1854, 1854, 1854, 1854, 1854, 185â€¦\r## $ Army \u0026lt;int\u0026gt; 8571, 23333, 28333, 28722, 30246, 30290, 30643, 29736, 32â€¦\r## $ Disease \u0026lt;int\u0026gt; 1, 12, 11, 359, 828, 788, 503, 844, 1725, 2761, 2120, 120â€¦\r## $ Wounds \u0026lt;int\u0026gt; 0, 0, 0, 0, 1, 81, 132, 287, 114, 83, 42, 32, 48, 49, 209â€¦\r## $ Other \u0026lt;int\u0026gt; 5, 9, 6, 23, 30, 70, 128, 106, 131, 324, 361, 172, 57, 37â€¦\r## $ Disease.rate \u0026lt;dbl\u0026gt; 1.4, 6.2, 4.7, 150.0, 328.5, 312.2, 197.0, 340.6, 631.5, â€¦\r## $ Wounds.rate \u0026lt;dbl\u0026gt; 0.0, 0.0, 0.0, 0.0, 0.4, 32.1, 51.7, 115.8, 41.7, 30.7, 1â€¦\r## $ Other.rate \u0026lt;dbl\u0026gt; 7.0, 4.6, 2.5, 9.6, 11.9, 27.7, 50.1, 42.8, 48.0, 120.0, â€¦ ## Data Pre-processing and Plotting Nightingale |\u0026gt; select(Date, Month, Year, contains(\u0026#34;rate\u0026#34;)) |\u0026gt; pivot_longer(cols = 4:6, names_to = \u0026#34;Cause\u0026#34;, values_to = \u0026#34;Rate\u0026#34;)|\u0026gt; mutate(Cause = gsub(\u0026#34;.rate\u0026#34;, \u0026#34;\u0026#34;, Cause), period = ifelse(Date \u0026lt;= as.Date(\u0026#34;1855-03-01\u0026#34;), \u0026#34;APRIL 1854 TO MARCH 1855\u0026#34;, \u0026#34;APRIL 1855 TO MARCH 1856\u0026#34;), Month = fct_relevel(Month, \u0026#34;Jul\u0026#34;, \u0026#34;Aug\u0026#34;, \u0026#34;Sep\u0026#34;, \u0026#34;Oct\u0026#34;, \u0026#34;Nov\u0026#34;, \u0026#34;Dec\u0026#34;, \u0026#34;Jan\u0026#34;, \u0026#34;Feb\u0026#34;, \u0026#34;Mar\u0026#34;, \u0026#34;Apr\u0026#34;, \u0026#34;May\u0026#34;, \u0026#34;Jun\u0026#34;))|\u0026gt; ggplot(aes(x=Month, y=Rate, fill=Cause)) + geom_col(width=1, alpha=0.5) + coord_equal(ratio = 1) + coord_polar() + facet_wrap(~period) + scale_fill_manual(values = c(\u0026#34;skyblue3\u0026#34;, \u0026#34;grey30\u0026#34;, \u0026#34;#fb9a99\u0026#34;)) + scale_y_sqrt() + theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(), strip.text = element_text(size = 11), legend.position = \u0026#34;bottom\u0026#34;, plot.margin = unit(c(10, 10, 10, 10), \u0026#34;pt\u0026#34;), plot.title = element_text(vjust = 5)) ","date":1770768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1770768000,"objectID":"477fd9901df6dc80441d26fd3a444751","permalink":"https://thiyanga.netlify.app/post/blog/","publishdate":"2026-02-11T00:00:00Z","relpermalink":"/post/blog/","section":"post","summary":"February 11, is recognized globally as the International Day of Women and Girls in Science.","tags":["R","ggplot2"],"title":"Recreating Nightingale's most famous diagram, known as the Coxcomb","type":"post"},{"authors":null,"categories":null,"content":"\rWhen I first heard about the OWSD â€œShort Talk, Big Impactâ€ competition, I knew it was not going to be just another presentation. I had only 180 seconds to communicate years of research, spark curiosity, and leave a lasting impression.\nMy talk was titled â€œExploring Artistic Legacy: Analyzing Artifact Differences Across Kingdoms Using Machine Learning.â€ It reflected my dual identity as both a data scientist and an artist, and my passion for discovering the mathematical beauty hidden within our cultural artifacts.\nBefore the Event OWSD made the process incredibly organized. The OWSD team guided us with great care. We received detailed information about the event, the judging criteria, and even examples of successful short talks to learn from. These resources helped me understand what makes a talk memorable in such a short span of time. The organizers also walked us through how the competition would unfold; from the time limits to the technical arrangements. That helped calm my nerves a bit, because I knew what to expect.\nPlanning My Talk My research topic is quite complex, and simplifying it into something engaging was a challenge in itself. I didnâ€™t want to oversimplify the science, but I also didnâ€™t want to lose the audience in technical jargon. So, I planned my talk using a simple but powerful technique: I started with something familiar (a concept that anyone could relate to) and gradually led the audience into the heart of my work.\nStrategy 1\nI began with something familiar, the worlds of art and data science, and drew parallels between the two.\nâ€œArtists see patterns in shapes. Data scientists see patterns in data. They both tell stories about the world.â€\nFrom there, I gently led the audience toward the unknown â€” the idea that machine learning can uncover mathematical concepts embedded in historical artifacts. This transition helped the audience travel with me, step by step, from everyday understanding to a new and thought-provoking perspective.\nStrategy 2\nI also used visuals strategically. A well-designed image can say what fifty words cannot. Each visual was chosen carefully to support my message, not distract from it. For example, I used visuals of ancient murals and artifacts to illustrate how geometry, tessellation, and symmetry reveal the deep mathematical roots of our artistic heritage.\nStrategy 3\nThe environment was another thing I paid close attention to. The day of my talk coincided with World Mathematics Day, and this yearâ€™s theme was â€œMathematics, Art, and Creativity.â€ It aligned perfectly with my topic, and I used that to my advantage by showing. It helped create a meaningful connection with the occasion and made my talk feel timely and relevant.\nFurthermore, I also set up my background to match the theme of my talk. I arranged my room with artistic elements that reflected both mathematics and creativity, creating an environment that visually supported my message and helped the audience feel the connection between art, science, and culture.\nStrategy 4\nAnd one thing I never did: memorize by heart. Iâ€™ve learned that when you memorize, you lose the natural rhythm of speaking. Instead, I practiced enough to know my key points and let the rest flow naturally. That way, my words sounded genuine and spontaneous, not rehearsed.\nWhat I Learned This experience taught me that clarity is more powerful than complexity. If your audience can understand and remember one key message, youâ€™ve succeeded. It also reminded me of the importance of storytelling in science.\nI also realized that the impact of a short talk doesnâ€™t end when the timer stops. The feedback I received afterward from people who said my talk helped them see my research differently was truly rewarding.\nThe Impact The response to my talk was heartwarming. Many told me they had never thought of mathematics and art as connected before. Some said the talk made them curious about the patterns hidden in culture and that curiosity, I believe, is the true success of any scientific communication.\nThe lessons I learned from the competition have become an integral part of my teaching. I now incorporate them into my Scientific Writing and Communication and Essential Skills in Statistics course units when teaching undergraduate and postgraduate students in the fields of Statistics, Data Science, and Artificial Intelligence. I have also been invited by several organizations to conduct training sessions on effective scientific communication and data storytelling.\nFurthermore, this experience has also given me a platform to give a voice to our proud artifacts and historical paintings in Sri Lanka, highlighting the mathematical concepts rooted within them and how technology can help preserve and celebrate this heritage on a global stage.\nParticipating in the OWSD competition gave me more than just a platform. I learned how to distill my ideas, how to communicate science with heart, and how to make every second count.\nThank you A huge thank you to Erin Johnson and Giulia Signori of the OWSD Secretariat. They highlighted the positive aspects of each talk and appreciated the valuable messages shared with the audience. The way they organized the event was also an excellent learning experience for us, providing insights into effective event planning and audience engagement.\nA big shout-out to UNESCO-OWSD and The World Academy of Sciences (TWAS) for providing this valuable opportunity by organizing such an impactful event.\nMy 180 seconds might have been short, but the impact it created will stay with me for a long time. ","date":1761696000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1761696000,"objectID":"ffa2f90452e2f818dd0c081c83d3d070","permalink":"https://thiyanga.netlify.app/post/owsd/","publishdate":"2025-10-29T00:00:00Z","relpermalink":"/post/owsd/","section":"post","summary":"When I first heard about the OWSD â€œShort Talk, Big Impactâ€ competition, I knew it was not going to be just another presentation. I had only 180 seconds to communicate years of research, spark curiosity, and leave a lasting impression.\nMy talk was titled â€œExploring Artistic Legacy: Analyzing Artifact Differences Across Kingdoms Using Machine Learning.â€ It reflected my dual identity as both a data scientist and an artist, and my passion for discovering the mathematical beauty hidden within our cultural artifacts.","tags":["Short Talk","Big Impact","3MT","OWSD","UNESCO"],"title":"How I Managed My Precious 180 Seconds at the UNESCO-OWSD Short Talk, Big Impact Competition and the Impact It Made","type":"post"},{"authors":null,"categories":null,"content":"\rThe Posit::conf 2023 (formerly known as RStudio conference) was held in Hyatt Regency in Chicago, Illinois, USA from 16 to 20 September, 2023. This was the first conference held since the name was changed from RStudio to Posit. It was a conference full of learning, making connections, and feeling inspired. As an attendee, I had the privilege of participating in workshops, attending various events, listening to great talks, meeting talented individuals, and experiencing the empowering atmosphere of R Ladies. I am immensely grateful for Posit Software, PBC formerly RStudio, PBC for this valuable opportunity. In this blog post, I\u0026rsquo;ll share my experience from Posit::conf 2023.\nSafe, positive, inclusive and respectful and welcoming atmosphere for everyone The conference had a code of conduct in place, which provided a safer environment by setting clear guidelines for expected behavior, ensuring that all participants feel respected, safe, included, and free from any form of harassment or discrimination. It provided a positive and welcoming atmosphere for everyone attending the event.\nWorkshops The Posit conference workshops showcase a diverse array of topics, ensuring that there\u0026rsquo;s something for every data scientist, analyst, or programmer. These sessions are led by experts in their respective fields. I attended Big data with arrow in R conducted by Steph Hazlitt \u0026amp; Nic Crane and Data science workflows with Posit tools: Python focus by Sam Edwardes and Gagandeep Singh.\nThe workshops truly represent the breadth and depth of the data science field, catering to the diverse needs and interests of attendees. The most of the workshop materials from the Posit conference have been published on their respective GitHub pages. This move toward open accessibility of workshop content is a significant benefit to conference attendees and the broader community.\nJan Pauls\u0026rsquo;s inspiring story, Keynotes, Talks The Posit conference began with an inspiring narrative shared by Jan Paul, whose story is deeply intertwined with the vital relationship between the Penobscot people and their life-sustaining river on Indian Island. Jan Paul works for the Penobscot Nation in the Department of Natural Resources and Water Quality. Her work involves employing open-source technology, including tools like R and the RStudio IDE, for data analysis. Her mission is to ensure the well-being of the river, thereby safeguarding the health of her people. You can watch the story using the following link:\nThe keynotes, talks and lightning talks featured an impressive line-up of speakers on various topics. The talks comprehensively address various facets of data science, spanning topics such as data wrangling, modeling, communication, production tools, reproducible research, open science, and sharing experiences on transitioning to R and Python. Jeremy Howard gave a fascinating keynote on A Hackersâ€™ Guide to Language Models.\nR Ladies R Ladies, a community that promotes gender diversity in the R programming community, had a significant presence at the conference. It was inspiring to see so many talented women sharing their expertise and experiences, and it reinforced the importance of diversity in tech. R Ladies events provided excellent networking opportunities. I had the chance to connect with amazing professionals, exchange ideas, and build lasting connections.\nOpportunity Scholar Program It was a fantastic initiative that ensured a diverse group of individuals had access to this enriching experience.\nMeeting Great People Lastly, the people I met. Ample opportunities were provided for conference attendees to expand their networks. These events included a book signing reception, engaging \u0026ldquo;Birds of a Feather\u0026rdquo; coffee meetups, and a lively trivia night, among others. The R community is filled with passionate and talented individuals who are eager to collaborate and share knowledge. Building relationships with like-minded professionals and making new friends was truly invaluable.\nSightseeing After the Conference While Posit::conf 2023 was undeniably the highlight of my trip, I couldn\u0026rsquo;t resist the allure of exploring the beautiful city that hosted this incredible event. After the conference wrapped up, I embarked on a sightseeing adventure that allowed me to immerse myself in the local culture and history.\n","date":1697587200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697587200,"objectID":"9619129985f8d526e8c3853fec14cdec","permalink":"https://thiyanga.netlify.app/post/posit/","publishdate":"2023-10-18T00:00:00Z","relpermalink":"/post/posit/","section":"post","summary":"The Posit::conf 2023 (formerly known as RStudio conference) was held in Hyatt Regency in Chicago, Illinois, USA from 16 to 20 September, 2023. This was the first conference held since the name was changed from RStudio to Posit. It was a conference full of learning, making connections, and feeling inspired. As an attendee, I had the privilege of participating in workshops, attending various events, listening to great talks, meeting talented individuals, and experiencing the empowering atmosphere of R Ladies.","tags":["R","Python"],"title":"My Posit::conf 2023 Experience - A Conference of Insights, Knowledge, Connections, and Explorations","type":"post"},{"authors":null,"categories":null,"content":"","date":1681257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681257600,"objectID":"d1e861e939c4099fff7d4ea706e24220","permalink":"https://thiyanga.netlify.app/project/dengue/","publishdate":"2023-04-12T00:00:00Z","relpermalink":"/project/dengue/","section":"project","summary":"Potential impacts of climate change on dengue fever","tags":["Demo"],"title":"Small Bite-Big threat = Small Data-Big Impact","type":"project"},{"authors":null,"categories":["R","tidyverse","tsibble","time series"],"content":"\rCreating data and time objects\rThe lubridate package in R provides a set of functions for working with dates and times.\nyear-month-date ymd function\rymd function converts a character vector of dates in the format â€œyear-month-dayâ€ to a Date object. The name of the function stands for â€œyear-month-dayâ€, which is the order of the components in the date format that the function expects.\nlibrary(lubridate)\rdates.ex1 \u0026lt;- c(\u0026quot;2022-03-15\u0026quot;, \u0026quot;2022-03-16\u0026quot;, \u0026quot;2022-03-17\u0026quot;)\rclass(dates.ex1)\r[1] \u0026quot;character\u0026quot;\rdates1 \u0026lt;- ymd(dates.ex1)\rdates1\r[1] \u0026quot;2022-03-15\u0026quot; \u0026quot;2022-03-16\u0026quot; \u0026quot;2022-03-17\u0026quot;\rclass(dates1)\r[1] \u0026quot;Date\u0026quot;\ryear-month-day ymd function\rThe ymd() function also supports variations of the â€œyear-month-dayâ€ format, such as â€œyear/month/dayâ€ or â€œyear.month.dayâ€.\ndates.ex2 \u0026lt;- c(\u0026quot;2022/03/15\u0026quot;, \u0026quot;2022/03/16\u0026quot;, \u0026quot;2022/03/17\u0026quot;)\rdates2 \u0026lt;- ymd(dates.ex2)\rdates2\r[1] \u0026quot;2022-03-15\u0026quot; \u0026quot;2022-03-16\u0026quot; \u0026quot;2022-03-17\u0026quot;\rclass(dates2)\r[1] \u0026quot;Date\u0026quot;\rdates.ex3 \u0026lt;- c(\u0026quot;2022/03/15\u0026quot;, \u0026quot;2022/03/16\u0026quot;, \u0026quot;2022/03/17\u0026quot;)\rdates2 \u0026lt;- ymd(dates.ex2)\rdates2\r[1] \u0026quot;2022-03-15\u0026quot; \u0026quot;2022-03-16\u0026quot; \u0026quot;2022-03-17\u0026quot;\rclass(dates2)\r[1] \u0026quot;Date\u0026quot;\rmonth-date-year mdy function\rmdy(c(\u0026quot;03-15-2023\u0026quot;, \u0026quot;03-16-2023\u0026quot;))\r[1] \u0026quot;2023-03-15\u0026quot; \u0026quot;2023-03-16\u0026quot;\rdate-month-year dmy function\rdmy(c(\u0026quot;15-03-2023\u0026quot;, \u0026quot;16-03-2023\u0026quot;))\r[1] \u0026quot;2023-03-15\u0026quot; \u0026quot;2023-03-16\u0026quot;\rdates with strings\rydm(\u0026quot;2023, March 15th\u0026quot;)\rWarning: All formats failed to parse. No formats found.\r[1] NA\rmdy(\u0026quot;March 15th, 2023\u0026quot;)\r[1] \u0026quot;2023-03-15\u0026quot;\rmdy(\u0026quot;Mar 15th, 2023\u0026quot;)\r[1] \u0026quot;2023-03-15\u0026quot;\rmdy(\u0026quot;Wednesday, March 15th, 2023\u0026quot;)\r[1] \u0026quot;2023-03-15\u0026quot;\rmdy(\u0026quot;15th, March, 2023\u0026quot;)\rWarning: All formats failed to parse. No formats found.\r[1] NA\rhour-minutes-second hms working with dates and times\rhms(\u0026quot;10:30:00\u0026quot;)\r[1] \u0026quot;10H 30M 0S\u0026quot;\rymd_hm, ymd_hms and mdy_hms\rymd_hm(\u0026quot;2023-03-15 10:30\u0026quot;)\r[1] \u0026quot;2023-03-15 10:30:00 UTC\u0026quot;\rymd_hms(\u0026quot;2023-03-15 10:30:00\u0026quot;)\r[1] \u0026quot;2023-03-15 10:30:00 UTC\u0026quot;\rmdy_hms(\u0026quot;03-15-2023 10:30:00\u0026quot;)\r[1] \u0026quot;2023-03-15 10:30:00 UTC\u0026quot;\rparse_date_time\rIf you have a date format that doesnâ€™t match any of the built-in formats, you can use the parse_date_time() function in lubridate to specify a custom format.\ndates.ex4 \u0026lt;- c(\u0026quot;2022/03/15 10:30:00\u0026quot;, \u0026quot;2022/03/16 11:00:00\u0026quot;, \u0026quot;2022/03/17 12:15:00\u0026quot;)\r# Define the custom format using the format string\rdate_format \u0026lt;- \u0026quot;%Y/%m/%d %H:%M:%S\u0026quot;\r# Convert the character vector to POSIXct objects using parse_date_time()\rparse_date_time(dates.ex4, date_format)\r[1] \u0026quot;2022-03-15 10:30:00 UTC\u0026quot; \u0026quot;2022-03-16 11:00:00 UTC\u0026quot;\r[3] \u0026quot;2022-03-17 12:15:00 UTC\u0026quot;\rCreating a sequence of time\ry1 \u0026lt;- seq(as.Date(\u0026quot;2012-01-01\u0026quot;),as.Date(\u0026quot;2012-12-01\u0026quot;), by = \u0026quot;1 month\u0026quot;)\ry1\r[1] \u0026quot;2012-01-01\u0026quot; \u0026quot;2012-02-01\u0026quot; \u0026quot;2012-03-01\u0026quot; \u0026quot;2012-04-01\u0026quot; \u0026quot;2012-05-01\u0026quot;\r[6] \u0026quot;2012-06-01\u0026quot; \u0026quot;2012-07-01\u0026quot; \u0026quot;2012-08-01\u0026quot; \u0026quot;2012-09-01\u0026quot; \u0026quot;2012-10-01\u0026quot;\r[11] \u0026quot;2012-11-01\u0026quot; \u0026quot;2012-12-01\u0026quot;\rclass(y1)\r[1] \u0026quot;Date\u0026quot;\rseq(as.Date(\u0026quot;2023-03-01\u0026quot;),as.Date(\u0026quot;2023-04-01\u0026quot;), by = \u0026quot;1 week\u0026quot;)\r[1] \u0026quot;2023-03-01\u0026quot; \u0026quot;2023-03-08\u0026quot; \u0026quot;2023-03-15\u0026quot; \u0026quot;2023-03-22\u0026quot; \u0026quot;2023-03-29\u0026quot;\rExtract various time components\rLetâ€™s see how to extract various time components from the elements of the following Date object.\ny2023 \u0026lt;- seq(as.Date(\u0026quot;2023-01-01\u0026quot;),as.Date(\u0026quot;2023-12-31\u0026quot;), by = \u0026quot;1 month\u0026quot;)\ry2023\r[1] \u0026quot;2023-01-01\u0026quot; \u0026quot;2023-02-01\u0026quot; \u0026quot;2023-03-01\u0026quot; \u0026quot;2023-04-01\u0026quot; \u0026quot;2023-05-01\u0026quot;\r[6] \u0026quot;2023-06-01\u0026quot; \u0026quot;2023-07-01\u0026quot; \u0026quot;2023-08-01\u0026quot; \u0026quot;2023-09-01\u0026quot; \u0026quot;2023-10-01\u0026quot;\r[11] \u0026quot;2023-11-01\u0026quot; \u0026quot;2023-12-01\u0026quot;\ryear(): Extracts the year component\nyear(y2023)\r[1] 2023 2023 2023 2023 2023 2023 2023 2023 2023 2023 2023 2023\rquarter(): Extracts the quarter\nquarter(y2023)\r[1] 1 1 1 2 2 2 3 3 3 4 4 4\rmonth(): Extracts the month component\nmonth(y2023)\r[1] 1 2 3 4 5 6 7 8 9 10 11 12\rweek(): Extracts the week component\nweek(y2023)\r[1] 1 5 9 13 18 22 26 31 35 40 44 48\rday(): Extracts the day component\nday(y2023)\r[1] 1 1 1 1 1 1 1 1 1 1 1 1\rTo illustrate the remaining functions I use the following example\nmydate \u0026lt;- ymd_hms(\u0026quot;2023-03-15 10:30:01\u0026quot;)\rhour(): Extracts the hour component\nhour(mydate)\r[1] 10\rminute(): Extracts the minute component\nminute(mydate)\r[1] 30\rsecond(): Extracts the second component\nsecond(mydate)\r[1] 1\r","date":1678752000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678752000,"objectID":"035118e2381d5f49d65e392a05e66928","permalink":"https://thiyanga.netlify.app/post/tsviz/","publishdate":"2023-03-14T00:00:00Z","relpermalink":"/post/tsviz/","section":"post","summary":"Time series data wrangling","tags":["R","tidyverse","tsibble","time series"],"title":"Some useful functions to wrangle with time series data","type":"post"},{"authors":null,"categories":["R","RStudio","Quarto","Python"],"content":"\rI created this blog using Quarto. Here are the steps that I used to create the blog.\nStep 1\rInstall Quarto. Follow the instructions in this tutorial.\nOn R Console install Quarto using the command\ninstall.packages(quarto)\rStep 2\rCreate a git hub repository and create a RStudio project.\nStep 3\rThe type the following command in the RStudio terminal\nquarto create-project myblog --type website:blog\rThis will create a folder called myblog with the following documents inside.\nCopy all the documents inside the folder into your project folder, and delete the myblog folder.\nStep 4\rRename index.qmd to blog.qmd and rename about.qmd to index.qmd.\nStep 5\rInclude your details to _quarto.yml.\nStep 6\rClick Render button to preview the blog.\nTo preview the website in the current directory type the following command in the terminal\nquarto preview\rStep 7\rTo publish the blog with Netlify, type the following command.\nquarto publish netlify\rOther useful links\rhttps://albert-rapp.de/posts/13_quarto_blog_writing_guide/13_quarto_blog_writing_guide.html\nhttps://quarto.org/docs/publishing/netlify.html\nhttps://beamilz.com/posts/2022-06-05-creating-a-blog-with-quarto/en/\nThemes\n","date":1667692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667692800,"objectID":"19afee8bc49d3835805d3cec5e31061d","permalink":"https://thiyanga.netlify.app/post/blog/","publishdate":"2022-11-06T00:00:00Z","relpermalink":"/post/blog/","section":"post","summary":"In this post, you will learn how to build a website using Quarto.","tags":["R","RStudio","Quarto","Python"],"title":"Building a website using Quarto","type":"post"},{"authors":null,"categories":null,"content":"Content 1. Python basics\n2. Python Modules and Packages - Installation\n3. Data Visualization with Python\nData Visualization slides\n4. Data Wrangling with Python\n","date":1667174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667174400,"objectID":"1dda7b139e59ba7167c6bc64fd571f2b","permalink":"https://thiyanga.netlify.app/project/python/","publishdate":"2022-10-31T00:00:00Z","relpermalink":"/project/python/","section":"project","summary":"Python Instructional Resources","tags":["Demo"],"title":"Introduction to Python","type":"project"},{"authors":null,"categories":["R","RStudio","Error"],"content":"\rError: C stack usage is too close to the limit\rWhile using Rstudio on macOS Mojave (version 10.14.6) to work with R, I recently ran across the following problem.\nIn order to fix the error, I deleted the .Rprofile. You can erase everything in the â€œ.Rprofileâ€ by using the commands listed below.\nfile.edit(file.path(\u0026quot;~\u0026quot;, \u0026quot;.Rprofile\u0026quot;)) file.edit(\u0026quot;.Rprofile\u0026quot;)\r","date":1665878400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665878400,"objectID":"0da7a245c6eb32109f274de58e6dd2f0","permalink":"https://thiyanga.netlify.app/post/error1/","publishdate":"2022-10-16T00:00:00Z","relpermalink":"/post/error1/","section":"post","summary":"Delete .Rprofile","tags":["R","RStudio","Error"],"title":"Error: C stack usage is too close to the limit","type":"post"},{"authors":null,"categories":["R","tidyverse","ggplot2","scatterplot","visdat","plotly"],"content":"\rData\rIn this post I am going to use penguins dataset in palmerpenguins package in R. First we load the dataset.\nlibrary(palmerpenguins)\rlibrary(skimr)\rlibrary(tidyverse)\rlibrary(plotly)\rlibrary(visdat)\rlibrary(patchwork)\rdata(\u0026quot;penguins\u0026quot;)\rHere is an overview of the dataset.\nskim(penguins)\rTable 1: Data summary\rName\rpenguins\rNumber of rows\r344\rNumber of columns\r8\r_______________________\rColumn type frequency:\rfactor\r3\rnumeric\r5\r________________________\rGroup variables\rNone\rVariable type: factor\nskim_variable\rn_missing\rcomplete_rate\rordered\rn_unique\rtop_counts\rspecies\r0\r1.00\rFALSE\r3\rAde: 152, Gen: 124, Chi: 68\risland\r0\r1.00\rFALSE\r3\rBis: 168, Dre: 124, Tor: 52\rsex\r11\r0.97\rFALSE\r2\rmal: 168, fem: 165\rVariable type: numeric\nskim_variable\rn_missing\rcomplete_rate\rmean\rsd\rp0\rp25\rp50\rp75\rp100\rhist\rbill_length_mm\r2\r0.99\r43.92\r5.46\r32.1\r39.23\r44.45\r48.5\r59.6\râ–ƒâ–‡â–‡â–†â–\rbill_depth_mm\r2\r0.99\r17.15\r1.97\r13.1\r15.60\r17.30\r18.7\r21.5\râ–…â–…â–‡â–‡â–‚\rflipper_length_mm\r2\r0.99\r200.92\r14.06\r172.0\r190.00\r197.00\r213.0\r231.0\râ–‚â–‡â–ƒâ–…â–‚\rbody_mass_g\r2\r0.99\r4201.75\r801.95\r2700.0\r3550.00\r4050.00\r4750.0\r6300.0\râ–ƒâ–‡â–†â–ƒâ–‚\ryear\r0\r1.00\r2008.03\r0.82\r2007.0\r2007.00\r2008.00\r2009.0\r2009.0\râ–‡â–â–‡â–â–‡\rsummary(penguins)\rspecies island bill_length_mm bill_depth_mm Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 Mean :43.92 Mean :17.15 3rd Qu.:48.50 3rd Qu.:18.70 Max. :59.60 Max. :21.50 NA\u0026#39;s :2 NA\u0026#39;s :2 flipper_length_mm body_mass_g sex year Min. :172.0 Min. :2700 female:165 Min. :2007 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 Median :197.0 Median :4050 NA\u0026#39;s : 11 Median :2008 Mean :200.9 Mean :4202 Mean :2008 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 Max. :231.0 Max. :6300 Max. :2009 NA\u0026#39;s :2 NA\u0026#39;s :2 Before moving on to the full logistic regression model, itâ€™s a good idea to look at the associations between each predictor and gender. Before moving on to the whole model, Itâ€™s critical to first grasp these linkages. We can use logistic regression to look at all of the predictors simultaneously.\np1_species \u0026lt;- penguins %\u0026gt;% na.omit() %\u0026gt;%\rcount(species,sex) %\u0026gt;% group_by(species) %\u0026gt;% mutate(Percentage = 100*n/sum(n)) %\u0026gt;% ggplot(aes(x = species,y = Percentage,fill=sex))+\rgeom_bar(stat=\u0026quot;identity\u0026quot;) + scale_fill_manual(values = c(\u0026quot;purple\u0026quot;,\u0026quot;cyan4\u0026quot;)) +\rcoord_flip() +\rtheme(legend.position = \u0026quot;bottom\u0026quot;) +\rggtitle(\u0026quot;a\u0026quot;) p2_island \u0026lt;- penguins %\u0026gt;% count(island,sex) %\u0026gt;% group_by(island) %\u0026gt;% mutate(Percentage = 100*n/sum(n)) %\u0026gt;% ggplot(aes(x = island,y = Percentage,fill=sex))+\rgeom_bar(stat=\u0026quot;identity\u0026quot;) + scale_fill_manual(values = c(\u0026quot;purple\u0026quot;,\u0026quot;cyan4\u0026quot;)) + coord_flip() +\rtheme(legend.position = \u0026quot;bottom\u0026quot;) +\rggtitle(\u0026quot;b\u0026quot;)\r(p1_species|p2_island)\rFigure 1: Distribution of (a) species and (d) island by gender.\rp3_length \u0026lt;- ggplot(penguins, aes(x=sex, y=bill_length_mm, fill=sex)) +\rgeom_boxplot() + scale_fill_manual(values = c(\u0026quot;purple\u0026quot;,\u0026quot;cyan4\u0026quot;)) + theme(legend.position = \u0026quot;bottom\u0026quot;) + ggtitle(\u0026quot;a\u0026quot;)\rp4_depth \u0026lt;- ggplot(penguins, aes(x=sex, y=bill_depth_mm, fill=sex)) +\rgeom_boxplot() + scale_fill_manual(values = c(\u0026quot;purple\u0026quot;,\u0026quot;cyan4\u0026quot;)) + theme(legend.position = \u0026quot;bottom\u0026quot;) + ggtitle(\u0026quot;b\u0026quot;)\rp5_flipper \u0026lt;- ggplot(penguins, aes(x=sex, y=flipper_length_mm, fill=sex)) +\rgeom_boxplot() + scale_fill_manual(values = c(\u0026quot;purple\u0026quot;,\u0026quot;cyan4\u0026quot;)) + theme(legend.position = \u0026quot;bottom\u0026quot;) + ggtitle(\u0026quot;c\u0026quot;)\rp6_bmi \u0026lt;- ggplot(penguins, aes(x=sex, y=body_mass_g, fill=sex)) +\rgeom_boxplot() + scale_fill_manual(values = c(\u0026quot;purple\u0026quot;,\u0026quot;cyan4\u0026quot;)) + theme(legend.position = \u0026quot;bottom\u0026quot;) + ggtitle(\u0026quot;d\u0026quot;)\r(p3_length|p4_depth)/(p5_flipper|p6_bmi)\rFigure 2: Distribution of (a) bill length, (b) bill depth, (c) flipper length and (d) body mass index by gender.\rMissing values exploration\rvis_miss(penguins)\rRemove missing values\rpenguins_omit \u0026lt;- penguins %\u0026gt;%\rna.omit()\rvis_miss(penguins_omit)\rBuilding logistic regression\rThen, using the other variables in the dataset, Iâ€™ll create a logistic regression model to predict the gender of the palmer penguins. One goal of this work is to identify which variables significantly contribute to determining the gender of penguins. Before beginning to build the model, double-check that all qualitative variables have been saved as factors.\nfit \u0026lt;- glm(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, data=penguins_omit, family=\u0026quot;binomial\u0026quot;)\rsummary(fit)\rCall:\rglm(formula = sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, family = \u0026quot;binomial\u0026quot;, data = penguins_omit)\rDeviance Residuals: Min 1Q Median 3Q Max -3.4128 -0.2000 0.0022 0.1441 2.8235 Coefficients:\rEstimate Std. Error z value Pr(\u0026gt;|z|) (Intercept) -80.376672 12.329735 -6.519 7.08e-11 ***\rspeciesChinstrap -7.402697 1.662534 -4.453 8.48e-06 ***\rspeciesGentoo -8.427611 2.597027 -3.245 0.00117 ** islandDream 0.324158 0.809135 0.401 0.68870 islandTorgersen -0.507858 0.855746 -0.593 0.55287 bill_length_mm 0.614436 0.131968 4.656 3.22e-06 ***\rbill_depth_mm 1.646446 0.335798 4.903 9.43e-07 ***\rflipper_length_mm 0.026654 0.048307 0.552 0.58111 body_mass_g 0.005819 0.001087 5.352 8.71e-08 ***\r---\rSignif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r(Dispersion parameter for binomial family taken to be 1)\rNull deviance: 461.61 on 332 degrees of freedom\rResidual deviance: 126.05 on 324 degrees of freedom\rAIC: 144.05\rNumber of Fisher Scoring iterations: 7\rTo represent qualitative variables, R will build an indicator (dummy) variable using the lowest coded category as the reference group. For example,\n\\[Y=\\begin{cases}\r0, \u0026amp; \\text{if female}\\\\\r1, \u0026amp; \\text{if male}\r\\end{cases}\\]\nInterpretation of parameter estimates of logistic regression\rThe â€œEstimatesâ€ in the above output corresponds to the log-odds. The odd ratios can be obtained as follows:\nexp(coefficients(fit))\r(Intercept) speciesChinstrap speciesGentoo islandDream 1.238383e-35 6.096066e-04 2.187435e-04 1.382866e+00 islandTorgersen bill_length_mm bill_depth_mm flipper_length_mm 6.017832e-01 1.848613e+00 5.188507e+00 1.027012e+00 body_mass_g 1.005836e+00 \\[odd = \\frac{P(event)}{1-P(event)}\\]\nThe 95% confidence intervals for log-odds can be obtained as follows\nconfint.default(fit)\r2.5 % 97.5 %\r(Intercept) -1.045425e+02 -56.210836165\rspeciesChinstrap -1.066120e+01 -4.144190616\rspeciesGentoo -1.351769e+01 -3.337530854\rislandDream -1.261718e+00 1.910034317\rislandTorgersen -2.185089e+00 1.169372704\rbill_length_mm 3.557834e-01 0.873088085\rbill_depth_mm 9.882945e-01 2.304597483\rflipper_length_mm -6.802606e-02 0.121333507\rbody_mass_g 3.687778e-03 0.007949886\rThe 95% confidence intervals for odds are as follows\nexp(confint.default(fit))\r2.5 % 97.5 %\r(Intercept) 3.960644e-46 3.872077e-25\rspeciesChinstrap 2.343681e-05 1.585626e-02\rspeciesGentoo 1.346919e-06 3.552456e-02\rislandDream 2.831672e-01 6.753321e+00\rislandTorgersen 1.124677e-01 3.219972e+00\rbill_length_mm 1.427298e+00 2.394293e+00\rbill_depth_mm 2.686648e+00 1.002014e+01\rflipper_length_mm 9.342361e-01 1.129001e+00\rbody_mass_g 1.003695e+00 1.007982e+00\rWe can write the fitted logistic regression model as follows\n\\[\\hat{Y} = \\frac{1}{1+e^{-z}} = \\frac{1}{e^{-80.83 -7.40Chinstrap -8.42Gentoo +0.32Dream -0.50Torgersen + 0.61 bill\\_length\\_mm + 1.64 bill\\_depth\\_mm + 0.02 flipper\\_length\\_mm + 0.005 body\\_mass\\_g}}\\]\nWhere,\n\\[Chinstrap=\\begin{cases}\r1, \u0026amp; \\text{if Chinstrap}\\\\\r0, \u0026amp; \\text{otherwise}\r\\end{cases}\\]\n\\[Gentoo=\\begin{cases}\r1, \u0026amp; \\text{if Gentoo}\\\\\r0, \u0026amp; \\text{otherwise}\r\\end{cases}\\]\n\\[Dream=\\begin{cases}\r1, \u0026amp; \\text{if Dream}\\\\\r0, \u0026amp; \\text{otherwise}\r\\end{cases}\\]\n\\[Torgersen=\\begin{cases}\r1, \u0026amp; \\text{if Torgersen}\\\\\r0, \u0026amp; \\text{otherwise}\r\\end{cases}\\]\n\\[bill\\_length\\_mm = \\text{bill length (millimeters)},\\]\r\\[bill\\_depth\\_mm = \\text{bill depth (millimeters)},\\]\n\\[flipper\\_length\\_mm = \\text{flipper length (millimeters)},\\]\n\\[body\\_mass\\_g = \\text{body mass (grams)}.\\]\nInterpretation of parameter estimates\rThe variables species, bill length (mm), bill depth (mm) and body mass (g) significantly contribute to the model.\nWith all other factors held constant, this fitted model predicts that the odds of discovering a male penguin on Dream island are 1.38 times higher than on Biscoe island.\nFor each one-unit increase in bill depth, the odds of detecting a male increased 5.18 times (95 percent CI 2.68â€“10.02).\nModel Evaluation: Next Post! Model evaluation should be done before interpreting the model.\n","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649635200,"objectID":"fb0c45a128c60e6edb4aac13c10182ff","permalink":"https://thiyanga.netlify.app/post/logisticregression/","publishdate":"2022-04-11T00:00:00Z","relpermalink":"/post/logisticregression/","section":"post","summary":"Logistic regression is a widely used modelling approach, however little is known about the modelling processes and interpretation of model outputs. This post demonstrates how to build a logistic model with R and how to interpret the results. ","tags":["R","tidyverse","ggplot2","visdat","patchwork","plotly"],"title":"Logistic Regression: Model Building and Interpretation","type":"post"},{"authors":null,"categories":["R","tidyverse","ggplot2","scatterplot"],"content":"\rTo enlarge a section of data in your ggplots, use the facet_zoom function in the ggforce package. To illustrate I am using the gapminder dataset in gapminder package.\nLoad necessary\rlibrary(tidyverse)\rlibrary(RColorBrewer)\rlibrary(ggforce)\rlibrary(gapminder)\rSet the theme for plots\rtheme_set(theme_bw())\rZoom according to a continuous scale variable\rzoom the Y axis\nggplot(gapminder, aes(y=lifeExp, x=gdpPercap)) + geom_point() + coord_fixed() + facet_zoom(ylim = c(60, 80)) zoom the X axis\nggplot(gapminder, aes(y=lifeExp, x=gdpPercap)) + geom_point() + coord_fixed() + facet_zoom(xlim = c(0, 10000)) zoom the X axis and the Y axis\nggplot(gapminder, aes(y=lifeExp, x=gdpPercap)) + geom_point() + coord_fixed() + facet_zoom(xlim = c(0, 10000), ylim=c(60, 80)) Zoom according to a qualitative variable\rzoom the Y axis\nggplot(gapminder, aes(y=lifeExp, x=gdpPercap, col=continent)) + geom_point() + coord_fixed() + scale_color_brewer(palette = \u0026quot;Dark2\u0026quot;) +\rfacet_zoom(y = continent == \u0026#39;Oceania\u0026#39;) zoom the X axis\nggplot(gapminder, aes(y=lifeExp, x=gdpPercap, col=continent)) + geom_point() + coord_fixed() + scale_color_brewer(palette = \u0026quot;Dark2\u0026quot;) +\rfacet_zoom(x = continent == \u0026#39;Oceania\u0026#39;) zoom the X axis and the Y axis\nggplot(gapminder, aes(y=lifeExp, x=gdpPercap, col=continent)) + geom_point() + coord_fixed() + scale_color_brewer(palette = \u0026quot;Dark2\u0026quot;) +\rfacet_zoom(xy = continent == \u0026#39;Oceania\u0026#39;) ggplot(gapminder, aes(y=lifeExp, x=gdpPercap, col=continent)) + geom_point() + coord_fixed() + scale_color_brewer(palette = \u0026quot;Dark2\u0026quot;) +\rfacet_zoom(xy = continent == \u0026#39;Oceania\u0026#39;, split = TRUE) ","date":1648425600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648425600,"objectID":"ef8bb48917ff0f52f053c2395231a78d","permalink":"https://thiyanga.netlify.app/post/ggforce/","publishdate":"2022-03-28T00:00:00Z","relpermalink":"/post/ggforce/","section":"post","summary":"You can use facet_zoom from the ggforce package to zoom out graphs instead of using your mouse (Contextual zoom).","tags":["R","tidyverse","ggplot2"],"title":"Zoom Your Plots with ggforce","type":"post"},{"authors":null,"categories":["R","tidyverse","ggplot2","scatterplot"],"content":"\rWith the ggplot2 package, youâ€™ve got full control over the axes labels in charts. Here we are going to look at some of the most commonly needed formatting options in order to make your graph aesthetically pleasing.\nComma-separated labels\rcomma_format function in scales can be used to add comma separated labels. To illustrate this I use African names data set in TidyTuesday.\nlibrary(tidyverse)\rlibrary(scales) ## read data\rafrican_names \u0026lt;- readr::read_csv(\u0026quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-06-16/african_names.csv\u0026quot;)\r## plot\rafrican_names %\u0026gt;%\rggplot(aes(year_arrival)) +\rgeom_histogram(bins = 20, fill = \u0026quot;darkslateblue\u0026quot;, alpha = 0.7, col=\u0026quot;white\u0026quot;) +\rscale_y_continuous(labels = scales::comma_format()) Change label angles, horizontal justification and vertical justification\rAngles only\nThe ggplot2 package element text can be used to alter the label angles as well as the horizontal and vertical justifications.\nlibrary(palmerpenguins)\rpenguins %\u0026gt;%\rggplot(aes(x=species, fill=species)) + geom_bar() +\rscale_fill_manual(values=c(\u0026quot;#1b9e77\u0026quot;, \u0026quot;#d95f02\u0026quot;, \u0026quot;#7570b3\u0026quot;)) + theme(axis.text.x=element_text(angle=30))\rAngles, horizontal justification and vertical justification\npenguins %\u0026gt;%\rggplot(aes(x=species, fill=species)) + geom_bar() + scale_fill_manual(values=c(\u0026quot;#1b9e77\u0026quot;, \u0026quot;#d95f02\u0026quot;, \u0026quot;#7570b3\u0026quot;)) + theme(axis.text.x=element_text(angle=30, vjust=.8, hjust=0.8))\r","date":1648339200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648339200,"objectID":"d9a21007adb8737e27fc537a12cefb96","permalink":"https://thiyanga.netlify.app/post/plotaxis/","publishdate":"2022-03-27T00:00:00Z","relpermalink":"/post/plotaxis/","section":"post","summary":"With the ggplot2 package, you've got full control over the axes labels in charts. Here we are going to look at some of the most commonly needed formatting options in order to make your graph aesthetically pleasing","tags":["R","tidyverse","ggplot2"],"title":"Formatting axis labels in ggplot","type":"post"},{"authors":null,"categories":null,"content":"\n","date":1644969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644969600,"objectID":"deed4433f1cf1a5e62abb932ae37c79e","permalink":"https://thiyanga.netlify.app/talk/nigeria/","publishdate":"2022-02-16T00:00:00Z","relpermalink":"/talk/nigeria/","section":"talk","summary":"","tags":null,"title":"RMarkdown: Create insightful reports in R","type":"talk"},{"authors":null,"categories":null,"content":"The Why R? Foundation held its Why R? 2021 Conference - the fifth meeting of Central-Eastern-European in December 2021. I was honored to be asked by this esteemed group to provide a keynote address on Feature-based Time Series Forecasting and join with forecasting and prediction panel discussion.\nAbstract\nMany applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making. However, large scale time series data present numerous challenges in modelling and implementation due to the high dimensionality. It is unlikely that a single method will consistently provide better forecasts across all time series. On the other hand, selecting individual forecast models when the number of series is very large can be extremely challenging. In this talk, I will present a general framework for forecast model selection using meta-learning. We call this framework FFORMS (Feature-based FORecast Model Selection). The underlying approach involves computing a vector of features from the time series which are then used to select the forecasting model. The model selection process is carried out using a classification algorithm â€“ we use the time series features as inputs, and the best forecasting algorithm as the output. Furthermore, we explore what is happening under the hood of the FFORMS framework and thereby gain an understanding of what features lead to the different choices of forecast models and how different features influence the predicted outcome. The proposed algorithm is implemented in the R package seer, which is available on CRAN at https://CRAN.R-project.org/package=seer.\nSeer package: https://github.com/thiyangt/seer\n","date":1639094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639094400,"objectID":"5d571a41de6ab39a8e53d22c5cfa933d","permalink":"https://thiyanga.netlify.app/talk/whyr-talk/","publishdate":"2021-12-10T00:00:00Z","relpermalink":"/talk/whyr-talk/","section":"talk","summary":"The Why R? Foundation held its Why R? 2021 Conference - the fifth meeting of Central-Eastern-European in December 2021. I was honored to be asked by this esteemed group to provide a keynote address on Feature-based Time Series Forecasting and join with forecasting and prediction panel discussion.\nAbstract\nMany applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making.","tags":null,"title":"Why R? 2021: Keynote","type":"talk"},{"authors":null,"categories":null,"content":"\rClick [here](https://thiyangt.github.io/coviddashboard/) to view the dashboard.\rThis dashboard provides an overview of the COVID-19 pandemic in Sri Lanka.\nAll input data (related to the local situation) for the dashboard is pulled from COVID-19 daily situation reports published by Epidemiology Unit, Ministry of Health and Indigenous Medical Services, Sri Lanka through covid19srilanka package in R. Sri Lanka maps are created based on ceylon package in R.\nOur paper is available at https://arxiv.org/pdf/2205.07286.pdf\nReproducible code is available at https://github.com/thiyangt/coviddashboard\nCite the work as follows\nTalagala, T. S; De Alwis R. S (2021, December 6). Covid-19 Dashboard Visualisation: Sri Lanka https://thiyangt.github.io/coviddashboard/\n","date":1638748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638748800,"objectID":"103f5fbd1231817f39def65f553dde15","permalink":"https://thiyanga.netlify.app/post/covid19srilankadb/","publishdate":"2021-12-06T00:00:00Z","relpermalink":"/post/covid19srilankadb/","section":"post","summary":"The 2019 Novel Coronavirus COVID-19 (2019-nCoV) Data in Sri Lanka","tags":null,"title":"Coronavirus Dashboard - Sri Lanka","type":"post"},{"authors":null,"categories":null,"content":"","date":1634774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634774400,"objectID":"2bdb5d3ce2e362ef838419877dcb035b","permalink":"https://thiyanga.netlify.app/project/covid19srilanka/","publishdate":"2021-10-21T00:00:00Z","relpermalink":"/project/covid19srilanka/","section":"project","summary":"A tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic in Sri Lanka","tags":["Demo"],"title":"Data of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic in Sri Lanka","type":"project"},{"authors":null,"categories":null,"content":"\nThe covid19srilanka package provides a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic in Sri Lanka\nPackage installation You can install the development version from GitHub with:\n# install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#34;thiyangt/covid19srilanka\u0026#34;) Snapshot of Avaliable Datasets covid.cases covid.cases provides Covid-19 Cases by Type (Confirmed, Recovered, Death).\nlibrary(covid19srilanka) data(\u0026#34;covid.cases\u0026#34;) dplyr::glimpse(covid.cases) ## Rows: 2,200\r## Columns: 3\r## $ Date \u0026lt;date\u0026gt; 2020-03-29, 2020-03-29, 2020-03-29, 2020-03-29, 2020-03-30, 202â€¦\r## $ Type \u0026lt;chr\u0026gt; \u0026#34;Confirmed\u0026#34;, \u0026#34;Recovered\u0026#34;, \u0026#34;Deaths\u0026#34;, \u0026#34;Active\u0026#34;, \u0026#34;Confirmed\u0026#34;, \u0026#34;Recoâ€¦\r## $ Count \u0026lt;dbl\u0026gt; 115, 10, 1, 104, 120, 11, 1, 108, 122, 16, 2, 104, 143, 18, 2, 1â€¦ head(covid.cases) ## # A tibble: 6 Ã— 3\r## Date Type Count\r## \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 2020-03-29 Confirmed 115\r## 2 2020-03-29 Recovered 10\r## 3 2020-03-29 Deaths 1\r## 4 2020-03-29 Active 104\r## 5 2020-03-30 Confirmed 120\r## 6 2020-03-30 Recovered 11 district.wise.cases district.wise.cases provides daily summary of the Coronavirus (COVID-19) cases by province.\ndata(\u0026#34;district.wise.cases\u0026#34;) dplyr::glimpse(district.wise.cases) ## Rows: 832\r## Columns: 3\r## $ Date \u0026lt;date\u0026gt; 2021-08-01, 2021-08-01, 2021-08-01, 2021-08-01, 2021-08-01, â€¦\r## $ District \u0026lt;chr\u0026gt; \u0026#34;Colombo\u0026#34;, \u0026#34;Gampaha\u0026#34;, \u0026#34;Kalutara\u0026#34;, \u0026#34;Kandy\u0026#34;, \u0026#34;Kurunagala\u0026#34;, \u0026#34;Galâ€¦\r## $ Count \u0026lt;dbl\u0026gt; 71267, 56085, 33300, 14576, 15327, 14841, 12267, 7778, 5694, â€¦ head(district.wise.cases) ## # A tibble: 6 Ã— 3\r## Date District Count\r## \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 2021-08-01 Colombo 71267\r## 2 2021-08-01 Gampaha 56085\r## 3 2021-08-01 Kalutara 33300\r## 4 2021-08-01 Kandy 14576\r## 5 2021-08-01 Kurunagala 15327\r## 6 2021-08-01 Galle 14841 vaccination vaccination provides daily summary of vaccination details\ndata(\u0026#34;vaccination\u0026#34;) dplyr::glimpse(vaccination) ## Rows: 471\r## Columns: 4\r## $ Date \u0026lt;date\u0026gt; 2021-04-29, 2021-04-29, 2021-04-30, 2021-04-30, 2021-05â€¦\r## $ Vaccine \u0026lt;chr\u0026gt; \u0026#34;Covishield Vaccine\u0026#34;, \u0026#34;Sinopharm Vaccine\u0026#34;, \u0026#34;Covishield Vâ€¦\r## $ `first dose` \u0026lt;dbl\u0026gt; 925242, 2469, 925242, 2865, 925242, 2865, 925242, 2865, â€¦\r## $ `Second dose` \u0026lt;dbl\u0026gt; 3445, 2435, 22919, 2435, 60757, 2435, 85653, 2435, 94436â€¦ head(vaccination) ## # A tibble: 6 Ã— 4\r## Date Vaccine `first dose` `Second dose`\r## \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 2021-04-29 Covishield Vaccine 925242 3445\r## 2 2021-04-29 Sinopharm Vaccine 2469 2435\r## 3 2021-04-30 Covishield Vaccine 925242 22919\r## 4 2021-04-30 Sinopharm Vaccine 2865 2435\r## 5 2021-05-01 Covishield Vaccine 925242 60757\r## 6 2021-05-01 Sinopharm Vaccine 2865 2435 Please cite the package as follows\nThiyanga S. Talagala, covid19srilanka: a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic in Sri Lanka , (2021), GitHub repository, https://github.com/thiyangt/covid19srilanka\n","date":1634688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634688000,"objectID":"3e17633318f41186d032f363a9330c71","permalink":"https://thiyanga.netlify.app/post/covid19srilanka/","publishdate":"2021-10-20T00:00:00Z","relpermalink":"/post/covid19srilanka/","section":"post","summary":"The 2019 Novel Coronavirus COVID-19 (2019-nCoV) Data in Sri Lanka","tags":null,"title":"Covid-19/ Coronavirus data in Sri Lanka","type":"post"},{"authors":null,"categories":["ggplot2"],"content":"\rLOcal regrESSion (LOESS) or LOcally WEighted Scatter-plot Smoother (LOWESS)\rLOESS or LOWESS is a nonparametric technique to fit a smooth curve through points in a scatter plot. This approach uses locally estimated linear regression at its core.\nThe following code illustrates how to include a loess line using the ggplot2 package.\nlibrary(ggplot2)\rset.seed(1)\rx \u0026lt;- rnorm(60)\ry \u0026lt;- c(rnorm(40), 10, rnorm(19))\rdf \u0026lt;- data.frame(x=x, y=y)\r## Without weights\rggplot(data=df, aes(x=x, y=y)) + geom_point() + geom_smooth(method=loess, legend=FALSE)\rFurthermore your can plot loess smoothing weighting the observations as follows:\nweights \u0026lt;- c(rep(1, 40), 20, rep(1, 19))\rdf$weights \u0026lt;- weights\rggplot(data=df, aes(x=x, y=y, size=weights, weight=weights)) + geom_point() + geom_smooth(method=loess, legend=TRUE)\r","date":1628294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628294400,"objectID":"360aa1f73f9382e69c8058a029efad18","permalink":"https://thiyanga.netlify.app/post/blog/","publishdate":"2021-08-07T00:00:00Z","relpermalink":"/post/blog/","section":"post","summary":"LOcal regrESSion (LOESS) or LOcally WEighted Scatter-plot Smoother (LOWESS)\rLOESS or LOWESS is a nonparametric technique to fit a smooth curve through points in a scatter plot. This approach uses locally estimated linear regression at its core.\nThe following code illustrates how to include a loess line using the ggplot2 package.\nlibrary(ggplot2)\rset.seed(1)\rx \u0026lt;- rnorm(60)\ry \u0026lt;- c(rnorm(40), 10, rnorm(19))\rdf \u0026lt;- data.frame(x=x, y=y)\r## Without weights\rggplot(data=df, aes(x=x, y=y)) + geom_point() + geom_smooth(method=loess, legend=FALSE)\rFurthermore your can plot loess smoothing weighting the observations as follows:","tags":["R","ggplot2"],"title":"Weighted LOESS (LOcal regrESSion) ","type":"post"},{"authors":null,"categories":null,"content":"Algorithm for leaves classification MEDIPI (MEDIicinal Plant Identification) algorithm Medicinal plants are usually identified by practitioners based on years of experience through sensory or olfactory senses. The other method of recognizing these plants involves Laboratory- based testing, which requires trained skills, data interpretation which is costly and time-intensive. Automatic ways to identify medicinal plants are useful especially for those that are lacking experience in herbal recognition. We introduce a computationally efficient new algorithm for medicinal plant classification. We refer to our medicinal plant classification algorithm as MEDIPI : MEDIicinal Plant Identification. MEDIPI contains two main phases (i) The offline phase, and (ii) The online phase. The algorithm operates on a set of interpretable features computed from the leaf images. The offline phase of the algorithm contains 4 main steps: i) image processing, ii) feature extraction, iii) train a algorithm. Figure 1 provides an overview of our algorithm. Figure 2 provides a selected set of features we use in the algorithm. The image processing steps are shown in Figure 3.\nFigure 1: Overview of MEDIPI algorithm\nFigure 2: Leaf image features\nFigure 3: Image processing workflow\nBenchmark dataset for plant leaves classification Researchers usually struggle and spend a lot of time establishing a database by gathering many leaf samples as raw data. By sharing our database we provide a training/test database to other researchers to develop new algorithms or to evaluate their algorithms. Furthermore, data sharing encourages more connections and collaboration between scientists, which leads to better decision-making.\nR Software Package MedLEA: Medicinal LEAf The MedLEA package provides two datasets.\ni) A dataset of morphological and structural features of 471 medicinal plant leaves. The features of each species are recorded by manually viewing the medicinal plant repository available at (http://www.instituteofayurveda.org/plants/). For more information visit at https://github.com/SMART-Research/MedLEA.\nFigure 4: Some morphological characteristics of profiles\nii) Leaf image data set: A database of leaf images of medicinal plants in Sri Lanka is not yet available. Hence, through this research, we establish a repository of medicinal plant images. This repository contains 1099 leaf images of 31 species. There are 29-45 images per species.\nFigure 5: Few samples from the MedLEA images\nYou can get access to the data set via the MedLEA package.\ninstall.packages(\u0026#34;MedLEA\u0026#34;) Research outputs Papers\nLakshika, J. P., \u0026amp; Talagala, T. S. (2021). Computer-aided Interpretable Features for Leaf Image Classification. arXiv preprint arXiv:2106.08077.\nSoftware\nJayani P. G. Lakshika and Thiyanga S. Talagala (2021). MedLEA: Morphological and Structural Features of Medicinal Leaves. R package version 1.0.1. https://CRAN.R-project.org/package=MedLEA\nDo you want a new data package for teaching? MedLEA package provides morphological and structural features of 471 medicinal plant leaves and 1099 leaf images of 31 species and 29-45 images per species. https://t.co/y14wvvMBH8 #rstats #DataVisualization #dataviz #MachineLearning pic.twitter.com/rYpyj16rTs\n\u0026mdash; Thiyanga Talagala (@thiyangt) April 11, 2021 Conference talks\nClick here\nResearch reproducibility\nR codes and data to reproduce the results in the paper \u0026ldquo;Computer-aided Interpretable Features for Leaf Image Classification\u0026rdquo; available at https://github.com/SMART-Research/leaffeatures_paper\n","date":1627171200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627171200,"objectID":"fdae8087757c1ed86b7d6db5bec077fb","permalink":"https://thiyanga.netlify.app/project/medlea/","publishdate":"2021-07-25T00:00:00Z","relpermalink":"/project/medlea/","section":"project","summary":"MEDIPI, a statistical machine learning algorithm for medicinal plant identification and a leaf image database for plant classification.","tags":["R","Python","OpenCV","Data Mining","Pattern Recognition","Machine Learning"],"title":"Statistical Machine Learning for  Medicinal Plant Identification","type":"project"},{"authors":null,"categories":null,"content":"Abstract The field of time series forecasting has been evolving rapidly with advances in techniques for modelling and forecasting. However, choosing the right technique for a given series is at the heart of forecasting research. This process is challenging because certain forecasting techniques will perform best on some series while different alternative will perform best on other series. Certainly, each forecasting technique has its own territory and dominance. Discovering the conditions under which a forecasting technique will function well and under which not is useful in identifying model territory and dominance. The forecast submissions of the top 25 participants of the M4-competition are used for the analysis. Evaluating forecasting submission only using global measures such as forecasting error measure collapse all local information and does not allow to identify local differences of those methodologies. We explore the relationships between features of the methodologies used to generate forecasts, features of the resulting forecasts and features of the time series to identify model territories and their characteristics. Taking these local information into account can have benefit in developing new methods and shed some light for further development in the field of forecasting.\n","date":1624924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624924800,"objectID":"9c1432c3f68785502b59cdd5ead41e3a","permalink":"https://thiyanga.netlify.app/talk/isf21-talk/","publishdate":"2021-06-29T00:00:00Z","relpermalink":"/talk/isf21-talk/","section":"talk","summary":"Abstract The field of time series forecasting has been evolving rapidly with advances in techniques for modelling and forecasting. However, choosing the right technique for a given series is at the heart of forecasting research. This process is challenging because certain forecasting techniques will perform best on some series while different alternative will perform best on other series. Certainly, each forecasting technique has its own territory and dominance. Discovering the conditions under which a forecasting technique will function well and under which not is useful in identifying model territory and dominance.","tags":null,"title":"Forecasting Model Territories","type":"talk"},{"authors":null,"categories":null,"content":"","date":1624492800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624492800,"objectID":"503c104a29f99ec65df06bc4c8bef5dc","permalink":"https://thiyanga.netlify.app/talk/norway21-talk/","publishdate":"2021-06-24T00:00:00Z","relpermalink":"/talk/norway21-talk/","section":"talk","summary":"","tags":null,"title":"Large-Scale Time Series Forecasting","type":"talk"},{"authors":null,"categories":null,"content":"\rLetâ€™s see how to format your model outputs with parameters package in R by LÃ¼decke et al. (2020).\nFit a simple linear regression model\r#install.packages(\u0026quot;parameters\u0026quot;)\rlibrary(parameters)\rlibrary(magrittr)\rlibrary(gt)\rlibrary(see)\rmodel \u0026lt;- lm(Volume ~ Height + Girth, data=trees)\rReporting model parameter estimates\rmodel %\u0026gt;% model_parameters()\rParameter | Coefficient | SE | 95% CI | t(28) | p\r--------------------------------------------------------------------\r(Intercept) | -57.99 | 8.64 | [-75.68, -40.29] | -6.71 | \u0026lt; .001\rHeight | 0.34 | 0.13 | [ 0.07, 0.61] | 2.61 | 0.014 Girth | 4.71 | 0.26 | [ 4.17, 5.25] | 17.82 | \u0026lt; .001\rmodel %\u0026gt;% model_parameters() %\u0026gt;% print_md()\rParameter\rCoefficient\rSE\r95% CI\rt(28)\rp\r(Intercept)\r-57.99\r8.64\r(-75.68, -40.29)\r-6.71\r\u0026lt; .001\rHeight\r0.34\r0.13\r(0.07, 0.61)\r2.61\r0.014\rGirth\r4.71\r0.26\r(4.17, 5.25)\r17.82\r\u0026lt; .001\rmodel %\u0026gt;% model_parameters() %\u0026gt;% print_html()\rRegression Model\rParameter\rCoefficient\rSE\r95% CI\rt(28)\rp\r(Intercept)\r-57.99\r8.64\r(-75.68, -40.29)\r-6.71\r\u0026lt; .001\rHeight\r0.34\r0.13\r(0.07, 0.61)\r2.61\r0.014 Girth\r4.71\r0.26\r(4.17, 5.25)\r17.82\r\u0026lt; .001\rControl the number of decimal places\rmodel %\u0026gt;% model_parameters(digits=3) %\u0026gt;% print_html()\rRegression Model\rParameter\rCoefficient\rSE\r95% CI\rt(28)\rp\r(Intercept)\r-57.988\r8.638\r(-75.68, -40.29)\r-6.713\r\u0026lt; .001\rHeight\r0.339\r0.130\r(0.07, 0.61)\r2.607\r0.014 Girth\r4.708\r0.264\r(4.17, 5.25)\r17.816\r\u0026lt; .001\rVisualise model parameter estimates\rmodel %\u0026gt;% model_parameters(digits=3) %\u0026gt;% plot()\rReporting ANOVA table\rmodel %\u0026gt;% aov() %\u0026gt;% model_parameters() %\u0026gt;% print_html()\rRegression Model\rParameter\rSum_Squares\rdf\rMean_Square\rF\rp\rHeight\r2901.19\r1\r2901.19\r192.53\r\u0026lt; .001\rGirth\r4782.97\r1\r4782.97\r317.41\r\u0026lt; .001\rResiduals\r421.92\r28\r15.07\rReferences\rLÃ¼decke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, and Dominique Makowski. 2020. â€œParameters: Extracting, Computing and Exploring the Parameters of Statistical Models Using R.â€ Journal of Open Source Software 5 (53): 2445. https://doi.org/10.21105/joss.02445.\n","date":1614297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614297600,"objectID":"8cb09fcb0d603757711c95e6093e2589","permalink":"https://thiyanga.netlify.app/post/regoutputs/","publishdate":"2021-02-26T00:00:00Z","relpermalink":"/post/regoutputs/","section":"post","summary":"Letâ€™s see how to format your model outputs with parameters package in R by LÃ¼decke et al. (2020).\nFit a simple linear regression model\r#install.packages(\u0026quot;parameters\u0026quot;)\rlibrary(parameters)\rlibrary(magrittr)\rlibrary(gt)\rlibrary(see)\rmodel \u0026lt;- lm(Volume ~ Height + Girth, data=trees)\rReporting model parameter estimates\rmodel %\u0026gt;% model_parameters()\rParameter | Coefficient | SE | 95% CI | t(28) | p\r--------------------------------------------------------------------\r(Intercept) | -57.99 | 8.64 | [-75.68, -40.29] | -6.71 | \u0026lt; .","tags":["R"],"title":"Reporting your model outputs","type":"post"},{"authors":null,"categories":null,"content":"It is important to maintain a calendar in order to budget your time well. In this post, I will show you some basic functionalities of calendR package in R. You can find more information here.\nLoad package library(calendR) 1. Load calendar - 2021 calendR(year = 2021, # Set the year start = \u0026#34;M\u0026#34;, # Set the first day of the calendar week as Monday (optional argument) special.days = \u0026#34;weekend\u0026#34;, # Colour weekends (optional argument), text.size = 4, special.col = \u0026#34;#b2df8a\u0026#34;) # background colour for weekends (optional arguments) 2. Mark events events \u0026lt;- rep(NA, 365) # Event dates events[100:200] \u0026lt;- \u0026#34;2nd semester\u0026#34; events[213:240] \u0026lt;- \u0026#34;Examination\u0026#34; events[300:310] \u0026lt;- \u0026#34;Conference\u0026#34; events[359] \u0026lt;- \u0026#34;Christmas\u0026#34; calendR(year = 2021, special.days = events, start = \u0026#34;M\u0026#34;, special.col = c(\u0026#34;#1b9e77\u0026#34;, \u0026#34;#d95f02\u0026#34;, \u0026#34;#7570b3\u0026#34;, \u0026#34;#e7298a\u0026#34;), text.size = 4, legend.pos = \u0026#34;right\u0026#34;) 3. Monthly plan calendR(year = 2021, month = 2, text = c(\u0026#34;Exam\u0026#34;, \u0026#34;Exam\u0026#34;, # Event labels \u0026#34;RLadies\u0026#34;), text.pos = c(18, 20, 23), # Events dates texts text.size = 4.5, # Font size of the labels text.col = \u0026#34;#1b9e77\u0026#34;) Warning in text != \u0026#34;\u0026#34; \u0026amp;\u0026amp; is.null(text.pos): \u0026#39;length(x) = 3 \u0026gt; 1\u0026#39; in coercion to\r\u0026#39;logical(1)\u0026#39; Warning in text == \u0026#34;\u0026#34; \u0026amp;\u0026amp; !is.null(text.pos): \u0026#39;length(x) = 3 \u0026gt; 1\u0026#39; in coercion to\r\u0026#39;logical(1)\u0026#39; ","date":1612915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612915200,"objectID":"da72ccb145d2c868388a0c9ecfaa27a3","permalink":"https://thiyanga.netlify.app/post/calendar/","publishdate":"2021-02-10T00:00:00Z","relpermalink":"/post/calendar/","section":"post","summary":"Maintaining a calendar to organize your events allows for having more smooth and productive day. In this post, I will show you some basic functionalities in CalendaR package.","tags":null,"title":"Organize your priorities using CalendR package in R","type":"post"},{"authors":null,"categories":null,"content":"\rHow often do you fix the aspect ratio?\rWhen creating scatterplots, how often do you fix the aspect ratio? #RStats #tidyverse #TidyTuesday #Python #ggplot2\râ€” Thiyanga Talagala (@thiyangt) August 9, 2020\rAspect ratio\rThe aspect ratio of a plot is the ratio of its height-to-width . The aspect ratio we choose for our graph plays a significant role. The graphs below plot exactly the same data points but they have different aspect ratios.\nlibrary(tidyverse)\rlibrary(patchwork)\rx \u0026lt;- 1:100\ry \u0026lt;- x\rdf \u0026lt;- data.frame(x=x, y=y)\rp1 \u0026lt;- ggplot(df, aes(x=x, y=y)) + geom_point() + coord_fixed(ratio=2) + ggtitle(\u0026quot;Aspect ratio = 2\u0026quot;)\rp2 \u0026lt;- ggplot(df, aes(x=x, y=y)) + geom_point() + coord_fixed(ratio=0.5) + ggtitle(\u0026quot;Aspect ratio = 0.5\u0026quot;)\rp3 \u0026lt;- ggplot(df, aes(x=x, y=y)) + geom_point() + coord_fixed(ratio=1) + ggtitle(\u0026quot;Aspect ratio = 1\u0026quot;)\rp1|p2|p3\rThe aspect-ratio of a plot can make an influence on the readerâ€™s mind.\rHere is an example. I generate a set of random points inside a unit circle. The equation of the unit circle center at (0, 0) is: \\(x^2+y^2=1\\).\nset.seed(2020)\rx \u0026lt;- runif(10000, -1, 1)\ry \u0026lt;- runif(10000, -1, 1)\rfx \u0026lt;- x^2 + y^2\rcoly \u0026lt;- ifelse(fx \u0026lt;= 1, 1, 0)\rcoly \u0026lt;- as.factor(coly)\rcircle.points \u0026lt;- data.frame(x=x, y=y, coly=coly)\rhead(circle.points)\rx y coly\r1 0.29380568 -0.7572887 1\r2 -0.21154848 0.2479973 1\r3 0.23700363 0.4911537 1\r4 -0.04621773 0.3838934 1\r5 -0.72780563 0.8263328 0\r6 -0.86523123 -0.3060675 1\rWithout fixing aspect ratio\rggplot(circle.points, aes(x=x, y=y, col=coly)) + geom_point() +\rscale_colour_manual(values = c(\u0026quot;#e7298a\u0026quot;, \u0026quot;#1b9e77\u0026quot;)) +\rtheme(legend.position = \u0026quot;none\u0026quot;) According to the plot above it seems that the region is bounded by a ellipse. However, our points are not generated from an elliptical region.\nAspect ratio is fixed\rggplot(circle.points, aes(x=x, y=y, col=coly)) + geom_point() +\rscale_colour_manual(values = c(\u0026quot;#e7298a\u0026quot;, \u0026quot;#1b9e77\u0026quot;)) + coord_equal() +\rggtitle(\u0026quot;Figure 2: Aspect ratio is fixed.\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;) When you create the plot by preserving the aspect ratio the region is bounded by a circle.\n","date":1608595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608595200,"objectID":"b7369e7358c7e87f4c51a8525a983655","permalink":"https://thiyanga.netlify.app/post/ratio/","publishdate":"2020-12-22T00:00:00Z","relpermalink":"/post/ratio/","section":"post","summary":"Aspect ratio: what it is and why it is. How often do you fix aspect ratio?","tags":null,"title":"Ratio matters: change the way you see things!","type":"post"},{"authors":null,"categories":["R","tidyverse","ggplot2","scatterplot"],"content":"\rStep 1: Load Libraries\rlibrary(tidyverse)\rStep 2: Dataset\rset.seed(20201215)\rdf \u0026lt;- tibble::tibble(x=rnorm(100), y=rnorm(100))\rNow we are going to work on our scatterplot.\nStep 3: First draw a scatterplot with your full data\rggplot(df, aes(x=x, y=y)) + geom_point() + coord_equal()\rStep 4: Store the points that you need to highlight in a new data.frame or tibble.\rSuppose I want to highlight 5th, 10th and 15th points.\ndf2 \u0026lt;- df[c(5, 10, 15), ]\rdf2\r# A tibble: 3 Ã— 2\rx y\r\u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r1 0.646 -3.30 2 2.54 -0.732\r3 -0.383 0.855\rStep 5: Now you need to inform above points to the ggplot through another geom_point layer.\rggplot(df, aes(x=x, y=y)) + geom_point() + coord_equal() + geom_point(data=df2, aes(x=x, y=y), colour=\u0026quot;red\u0026quot;)\rWe can change the size by passing a value to size argument.\nggplot(df, aes(x=x, y=y)) + geom_point() + coord_equal() + geom_point(data=df2, aes(x=x, y=y), colour=\u0026quot;red\u0026quot;, size=5)\rWe can circle around the points by using the following command.\nggplot(df, aes(x=x, y=y)) + geom_point() + coord_equal() + geom_point(data=df2, aes(x=x, y=y), pch=21, fill=NA, size=4, colour=\u0026quot;red\u0026quot;, stroke=1)\r","date":1607990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607990400,"objectID":"eabaa0c6f5dce5fb115805349a6b94c4","permalink":"https://thiyanga.netlify.app/post/scatterplot/","publishdate":"2020-12-15T00:00:00Z","relpermalink":"/post/scatterplot/","section":"post","summary":"Highlight selected points in the scatterplot","tags":["R","tidyverse","ggplot2","scatterplot"],"title":"Highlight data points in a scatterplot","type":"post"},{"authors":null,"categories":null,"content":"Abstract\nA Tool to Detect Potential Data Leaks in Forecasting Competitions Forecasting competitions are of increasing importance as a mean to learn best practices and gain knowledge. Data leakage is one of the most common issues that can often be found in competitions. Data leaks can happen when the training data contains information about the test data. There are a variety of different ways that data leaks can occur with time series data. For example: i) randomly chosen blocks of time series are concatenated to form a new time series, ii) scale-shifts, iii) repeating patterns in time series, iv) white noise is added in the original time series to form a new time series, etc. This work introduces a novel tool to detect these data leaks. The tsdataleaks package provides simple and computationally efficient algorithm to exploit data leaks in time series data. I will demonstrate the package design and its power to detect data leakages using recent forecasting competitions data.\nKey words: Time series, R software, Tools, Visualization\n","date":1603756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603756800,"objectID":"eeb26d12465add722969914c59333fc1","permalink":"https://thiyanga.netlify.app/talk/isf20-talk/","publishdate":"2020-10-27T00:00:00Z","relpermalink":"/talk/isf20-talk/","section":"talk","summary":"Abstract\nA Tool to Detect Potential Data Leaks in Forecasting Competitions Forecasting competitions are of increasing importance as a mean to learn best practices and gain knowledge. Data leakage is one of the most common issues that can often be found in competitions. Data leaks can happen when the training data contains information about the test data. There are a variety of different ways that data leaks can occur with time series data.","tags":null,"title":"A Tool to Detect Potential Data Leaks in Forecasting Competitions","type":"talk"},{"authors":null,"categories":["R"],"content":"\rSpotting the problem\rFirst, I create a small dataset for the demonstration. The following dataset represents the Happiness index for five countries.\nhappy \u0026lt;- data.frame(\rcountry = c(\u0026quot;Finland\u0026quot;, \u0026quot;Norway\u0026quot;, \u0026quot;Denmark\u0026quot;, \u0026quot;Iceland\u0026quot;, \u0026quot;Netherlands\u0026quot;),\rscore = c(7.76, 7.60, 7.55, 7.49, 7.48))\rhappy\rcountry score\r1 Finland 7.76\r2 Norway 7.60\r3 Denmark 7.55\r4 Iceland 7.49\r5 Netherlands 7.48\rSave the dataset as shown below.\nsave(happy, file=\u0026quot;happyindex.rda\u0026quot;)\rLetâ€™s load the dataset with,\nload(\u0026quot;happyindex.rda\u0026quot;)\rhappyindex\rThe following error message pops up,\nError: object â€˜happyindexâ€™ not found\nTackling the problem\rloadHappy \u0026lt;- load(\u0026quot;happyindex.rda\u0026quot;)\rhappyDataloaded \u0026lt;- get(loadHappy)\rhappyDataloaded\r","date":1602633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602633600,"objectID":"39bd4fadb96f0e55405ca45da4e754c9","permalink":"https://thiyanga.netlify.app/post/loaddatasets/","publishdate":"2020-10-14T00:00:00Z","relpermalink":"/post/loaddatasets/","section":"post","summary":"Read data files","tags":["R"],"title":"Import data into R: Overwritten object names","type":"post"},{"authors":null,"categories":["R"],"content":"\rTo view list of data sets available in a particular package or a group of packages.\rvcdExtra::datasets(c(\u0026quot;ggplot2\u0026quot;, \u0026quot;forecast\u0026quot;))\rLoading package: ggplot2 Loading package: forecast Package Item class dim\r1 ggplot2 diamonds data.frame 53940x10\r2 ggplot2 economics data.frame 574x6\r3 ggplot2 economics_long data.frame 2870x4\r4 ggplot2 faithfuld data.frame 5625x3\r5 ggplot2 luv_colours data.frame 657x4\r6 ggplot2 midwest data.frame 437x28\r7 ggplot2 mpg data.frame 234x11\r8 ggplot2 msleep data.frame 83x11\r9 ggplot2 presidential data.frame 11x4\r10 ggplot2 seals data.frame 1155x4\r11 ggplot2 txhousing data.frame 8602x9\r12 forecast gas ts 476\r13 forecast gold ts 1108\r14 forecast taylor ts 4032\r15 forecast wineind ts 176\r16 forecast woolyrnq ts 119\rTitle\r1 Prices of over 50,000 round cut diamonds\r2 US economic time series\r3 US economic time series\r4 2d density estimate of Old Faithful data\r5 \u0026#39;colors()\u0026#39; in Luv space\r6 Midwest demographics\r7 Fuel economy data from 1999 to 2008 for 38 popular models of cars\r8 An updated and expanded version of the mammals sleep dataset\r9 Terms of 11 presidents from Eisenhower to Obama\r10 Vector field of seal movements\r11 Housing sales in TX\r12 Australian monthly gas production\r13 Daily morning gold prices\r14 Half-hourly electricity demand\r15 Australian total wine sales\r16 Quarterly production of woollen yarn in Australia\rTo view data sets in package datasets.\rdata() This opens a file called â€œR data setsâ€ in the Code-Editor window as below.\nTo list the data sets in all available packages\rdata(package = .packages(all.available = TRUE)).\nThis opens a file called â€œR data setsâ€ in the Code- Editor widow, listing datasets as\nData sets in package â€˜alr4â€™:\r...\rData sets in package â€˜asbioâ€™:\r...\r.\r.\r.\r","date":1598832000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598832000,"objectID":"e055284bd74cc8d66d7d9eeb3a9fd57b","permalink":"https://thiyanga.netlify.app/post/datasets/","publishdate":"2020-08-31T00:00:00Z","relpermalink":"/post/datasets/","section":"post","summary":"How to view datasets in a particular package, or or list the available data sets? ","tags":["R","ggplot","fable"],"title":"Working with built-in data sets in R","type":"post"},{"authors":null,"categories":null,"content":"Checks whether your package name is taken or available !!\ninstall.packages(\u0026#34;available\u0026#34;) library(available) available(\u0026#34;seer\u0026#34;) Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:\rcannot open URL \u0026#39;http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES\u0026#39; â”€â”€ seer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\rName valid: âœ”\rAvailable on CRAN: âœ– Available on Bioconductor: âœ–\rAvailable on GitHub: âœ– Abbreviations: http://www.abbreviations.com/seer\rWikipedia: https://en.wikipedia.org/wiki/seer\rWiktionary: https://en.wiktionary.org/wiki/seer\rSentiment:??? This means the name seer is taken in both CRAN and GitHub.\n","date":1594166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166400,"objectID":"0f8d7b6333659f46d859e776990a9bea","permalink":"https://thiyanga.netlify.app/post/available/","publishdate":"2020-07-08T00:00:00Z","relpermalink":"/post/available/","section":"post","summary":"Checks whether your package name is taken or available !!\ninstall.packages(\u0026#34;available\u0026#34;) library(available) available(\u0026#34;seer\u0026#34;) Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:\rcannot open URL \u0026#39;http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES\u0026#39; â”€â”€ seer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\rName valid: âœ”\rAvailable on CRAN: âœ– Available on Bioconductor: âœ–\rAvailable on GitHub: âœ– Abbreviations: http://www.abbreviations.com/seer\rWikipedia: https://en.wikipedia.org/wiki/seer\rWiktionary: https://en.wiktionary.org/wiki/seer\rSentiment:??? This means the name seer is taken in both CRAN and GitHub.","tags":null,"title":"Small things matter!","type":"post"},{"authors":null,"categories":null,"content":"\rThe most common problem while learning Statistics is that studentsâ€™ lack of understanding of the basic terminologies, notations, definitions and concepts. Think of Statistics as building blocks, and you need a solid foundation to move forward. Here, I explain five common terms in Statistics: i) Parameter, ii) Statistic, iii) Random Variable, iv) Estimator, v) Estimate and their notations.\nI will start with the definition of Population and Sample.\nA population is a complete collection of individuals/ objects that we are interested in. A sample is a subset of a population.\nParameter\rA parameter is a descriptive measure(numerical value) of the population. Parameters are usually denoted by Greek letters.\nExamples of parameters:\n\\(\\mu\\) - population mean\n\\(\\sigma^2\\) - population variance\nStatistic\rA statistic is a descriptive measure of a sample. For example, sample mean, sample standard deviation, etc. We will talk about the notations under estimator and estimate.\nRandom Variable\rBefore introducing random variable, let me very shortly recall what is a random experiment and what is a sample space.\nA random experiment is a physical situation whose outcome cannot be predicted with certainty until it is observed. A random experiment can be repeated as many times as we want under the same conditions (leading to different outcomes). Each one of them a trial. Thus, a trial is a particular performance of a random experiment.\nA Sample space is a set of all possible outcomes of a random experiment. In this blog post I use \\(\\Omega\\) to denote a sample space.\nExample 1:\nRandom Experiment: Tossing of a coin.\nSample Space: \\(\\Omega = \\{H, T\\}\\)\nlibrary(prob) tosscoin(1)\rtoss1\r1 H\r2 T\rExample 2:\nRandom Experiment: Toss a coin three times.\nSample Space: \\(\\Omega = \\{(H, H, H), (H, H, T), (H, T, H), (T, H, H), (H, T, T), (T, H, T), (T, T, H), (T, T, T)\\}\\)\ntosscoin(3)\rtoss1 toss2 toss3\r1 H H H\r2 T H H\r3 H T H\r4 T T H\r5 H H T\r6 T H T\r7 H T T\r8 T T T\rDefinition: Random Variable\nLet \\((\\Omega, \\mathscr{F}, \\mathbb{P})\\) be a probability space. Random variable is a function \\(X: \\Omega \\rightarrow \\mathbb{R}\\) such that \\(\\forall B \\in \\mathcal{B}( \\mathbb{R} ): X^{-1}(B) \\in \\mathscr{F}\\).\nYou need Measure Theory knowledge to understand the above definition.\nLoosely speaking a Random variable is a function from the sample space to the real numbers. There are two types of random variables: i) Discrete random variable and ii) Continuous random variable. We use Roman capital letters to denote random variables (\\(X\\), \\(Y\\), \\(Z\\), \\(U\\), \\(T\\), etc.). However, as soon as a variable \\(X\\) is observed, the observed values are represented by the corresponding simple Roman letter.\nThe notation \\(X(\\omega)\\) denotes the numerical value of the random variable X, when the outcome of the experiment is some particular \\(\\omega\\).\nAn example will help you to understand how this works. To start with, letâ€™s consider a simple experiment with two possible outcomes: PCR test result of a randomly selected individual.\nThe random variable \\(X\\) can be defined as follows:\nSolution 1.1\nSample space\n\\[\\Omega = \\{Positive, Negative\\}\\]\nRandom variable\n\\[\rX(\\omega)= \\begin{cases}\r0,\u0026amp; \\text{if } \\omega = Negative\\\\\r1, \u0026amp; \\text{if } \\omega = Positive\r\\end{cases}\r\\]\nSolution 1.2\nSimply drop \\(\\omega\\) and define the random variable as follows:\n\\[\rX= \\begin{cases}\r0,\u0026amp; \\text{if the test result is negative. } \\\\\r1, \u0026amp; \\text{if the test result is positive.}\r\\end{cases}\r\\]\nLetâ€™s consider another experiment. The experiment consists in selecting a random undergraduate student in the University during a period of one week, and measuring their height.\nThe random variable \\(Y\\) can be defined as follows:\n\\[\\Omega = \\{ \\omega: \\omega \u0026gt; 0\\}\\]\n\\[Y(\\omega) = \\omega, \\text{ } \\omega \\in \\Omega. \\]\nor\n\\[Y = \\text{Height in cm.}\\]\nNotations for Random Variables and Observed Data (in Sampling)\rSuppose you have a random variable \\(X\\). Suppose we repeat the random experiment \\(n\\) times. Then the resulting random variables are denoted by \\(X_1, X_2, ..., X_n\\). All \\(X_i\\)â€™s have the same distribution as \\(X\\). The random variables \\(X_1, X_2, ..., X_n\\) are collectively referred to as a random sample.\nLetâ€™s try to understand the concept with an example.\n\\[\rX_i= \\begin{cases}\r0,\u0026amp; \\text{if the test result of the } i^{th} \\text { is negaive } \\\\\r1, \u0026amp; \\text{if the test result of the } i^{th} \\text { is positive, }\r\\end{cases}\r\\]\nwhere \\(i = 1, 2, 3, 4, 5.\\)\nWe performed the PCR test on randomly selected 5 individuals. We called this sample 1. The results are \\(x_1=1, x_2=0, x_3=0, x_4=1, x_5=1\\).\nPrior to obtaining \\(x_1, x_2, x_3, x_4, x_5\\), there is uncertainty about the values of each \\(x_i\\). Because of this\runcertainty, before the results becomes available we view each observation as a random\rvariable and denote the sample by \\(X_1, X_2, X_3, X_4, X_5\\).\nWe again performed the PCR test on another randomly selected 5 individuals. We called this sample 2. Now results are \\(x_1=0, x_2=0, x_3=0, x_4=1, x_5=0\\).\nYou can see observable values for \\(X_1, X_2, X_3, X_4, X_5\\) vary from sample to sample.\nEstimator and Estimate\rDistinction between the terms Estimator and Estimate is important.\nLet \\(X_1, X_2, ..., X_n\\) be a random sample from a distribution function \\(f_X(x)\\) that depends on a unknown parameter \\(\\theta\\).\nAn estimator is a statistic, \\(T = f(X_1, ..., X_n)\\), that is used to estimate the unknown unknown parameter, \\(\\theta\\), based on an observed sample of \\(x_1, x_2, ..., x_n\\). The \\(t=f(x_1, x_2, ..., x_n)\\) is an estimate of \\(\\theta\\).\nEstimator: An estimator is always a random variable.\n\\(\\hat{\\theta} = T = f(X_1, ..., X_n)\\)\nEstimate: An estimate is a constant.\n\\(\\hat{\\theta} = t = f(x_1, ..., x_n)\\)\nNote that we use \\(\\hat{\\theta}\\) for both estimator and estimate.\nEstimator is a function of observable random variables that is used to estimate an unknown parameter \\(\\theta\\). The corresponding estimate is obtained by substituting the observed values to the estimator. You can also think of an estimator as the rule (equation) that is used to compute an estimate. For example, the sample mean, \\(\\bar{X}\\), is an estimator that is used to estimate the population mean, \\(\\mu\\).\nBelow example is useful to understand the concepts.\nLetâ€™s say you wanted to know the mean height of undergraduates in a certain university with a population of 1000 undergraduates. You take a random sample of 10 students and measure their height. The observed values are (in cm) 150, 155, 160, 161, 162, 152, 140, 141, 150, 155. Suppose you want to use sample mean to estimate the population mean.\nThe parameter we want to estimate is, \\(\\mu\\), population mean (mean height of the students in the university.).\nThere are infinitely many possible estimators for \\(\\mu\\). For example, sample mean, sample median. In this example we use sample mean to estimate \\(\\mu\\). Now, letâ€™s write the estimator using the notations.\nTo do this, we first define random variables \\(X_1, X_2, X_3, ..., X_{10}\\) as follows: \\(X_1\\) is the height of the \\(1^{st}\\) chosen person, \\(X_2\\) be the height of the \\(2^{nd}\\) chosen person,â€¦. In general, \\(X_i\\) is the height of the \\(i^{th}\\) student chosen from the population.\nNow we can write the estimator as\n\\[\\hat{\\mu} = \\bar{X}=\\frac{X_1 + X_2 + X_3 + ... + X_{10}}{10}.\\]\nThe estimate is\n\\[\\hat{\\mu}=152.6\\text{ cm}.\\]\nmean(c(150, 155, 160, 161, 162, 152, 140, 141, 150, 155))\r[1] 152.6\rIf you are not given the observed values of \\(X_1, X_2, X_3, ..., X_{10}\\), you can write the estimate as\n\\[\\hat{\\mu} = \\frac{x_1 + x_2 + x_3 + ... + x_{10}}{10}.\\]\nThe observed value of the estimator varies from sample to sample.\nUsage\rWriting distributions\r\\[X \\sim Bin(10, 0.6)\\]\n\\[f_X(x) = P(X=x) = {10\\choose x} 0.6^x 0.4^{(10-x)}\\]\n\\[f_X(5) = P(X=5) = {10\\choose 5} 0.6^5 0.4^{(10-5)} = 0.37\\]\npbinom(5, 10, 0.6)\r[1] 0.3668967\rCalculation of expectations\r\\[E(\\text{Estimator}) = \\text{Parameter}\\]\n\\[E(\\bar{X}) = \\mu\\]\nThis work is\rlicensed under a Creative Commons Attribution 4.0 International\rLicense.\n","date":1593820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593820800,"objectID":"28af02174a7bbd23b46a22c223833d3c","permalink":"https://thiyanga.netlify.app/post/statterms1/","publishdate":"2020-07-04T00:00:00Z","relpermalink":"/post/statterms1/","section":"post","summary":"The most common problem while learning Statistics is that studentsâ€™ lack of understanding of the basic terminologies, notations, definitions and concepts. Think of Statistics as building blocks, and you need a solid foundation to move forward. Here, I explain five common terms in Statistics: i) Parameter, ii) Statistic, iii) Random Variable, iv) Estimator, v) Estimate and their notations.\nI will start with the definition of Population and Sample.\nA population is a complete collection of individuals/ objects that we are interested in.","tags":null,"title":"Parameter, Statistic, Random Variable, Estimator and Estimate","type":"post"},{"authors":null,"categories":["Mathematics","Nature","STEM","Science","Women in STEM"],"content":"\rNature is my biggest inspiration for my love and passion for mathematics. It is amazing to see how these leaves follow geometry to ensure the surface is optimized for the absorption of sunlight. Indeed, nature is a good Mathematician. All its presentations are well calculated and designed. I see a great artist or a designer inside every Mathematician. Maths will teach you how to hold your brush, how to mix your paints and how to manage your tools for a great design.\nEnjoy the spirit of Mathematics!\nâ€œNature is my biggest inspiration for my love and passion for mathematicsâ€ - meet Dr Thiyanga Talagala @thiyangt - a former ACEMS student @MonashEBS and now a lecturer at @usjp - watch her #WomenInMaths day video: https://t.co/wPwAcyVunm #WomenInSTEM @MonashBusiness #may12wim pic.twitter.com/xkWtOb4Rzu\râ€” ğ˜¼ğ˜¾ğ™€ğ™ˆğ™ (@ACEMathStats) May 11, 2020\rAcknowledgement:\nAustralian Mathematical Society\nACEMS: Australian Research Council Centre of Excellence For Mathematical and Statistical Frontiers\nTim Macuga from Australian Research Council Centre of Excellence For Mathematical and Statistical Frontiers\n","date":1589328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589328000,"objectID":"ee910fd77d392b41eb2bb0b534ab3598","permalink":"https://thiyanga.netlify.app/post/mathsday2020/","publishdate":"2020-05-13T00:00:00Z","relpermalink":"/post/mathsday2020/","section":"post","summary":"Nature is my biggest inspiration for my love and passion for mathematics.","tags":["Mathematics","Nature","STEM","Science","Women in STEM"],"title":"Happy Women in Maths Day - 12 May 2020","type":"post"},{"authors":null,"categories":null,"content":"Dataset 1 Consumers\u0026rsquo; use of Food Labels Food industry is one of the fastest moving industrial sectors. The glamorous and glittering retail shops and supermarkets are expanding very fast all over the country. The majority of food is pre-packed and presented to the consumer in a labelled container. This study was conducted to evaluate the consumers\u0026rsquo; level of knowledge and use of information provided on food labels in making purchasing decisions. A structured questionnaire-based survey was used for the purpose of the study. This is a cross sectional study done over a period of five months from October, 2010 to March, 2011 with an average of seven interviews being conducted each week. The survey was conducted at supermarkets, retail shops of various sizes in five towns: Colombo 02, Kottawa, Maharagama, Nugegoda and Horana in Sri Lanka. A total of 586 respondents were considered for the study. The dataset and the questionnaire used in this studey can be downloaded from the following links. Please see the questionnaire for the column name description.\nDataset: foodlabel.csv\nQuestionnaire: Consumers\u0026rsquo; awareness and use of food label information\nDatasets in ggplot2 vcdExtra::datasets(\u0026#34;ggplot2\u0026#34;) ","date":1587945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587945600,"objectID":"14d3c170913d26174b91d02eadcd3690","permalink":"https://thiyanga.netlify.app/project/datasets/","publishdate":"2020-04-27T00:00:00Z","relpermalink":"/project/datasets/","section":"project","summary":"Data sets for teaching data analysis.","tags":["Demo"],"title":"Teaching Statistics","type":"project"},{"authors":null,"categories":["R","shiny","plotly"],"content":"Visit here: https://statisticsmart.shinyapps.io/coronaSLDashboard/#section-summary\nCode The code behind this dashboard is available on GitHub.\nData The raw data is pulled from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository (through corona package in R) and Covid-19 Situation reports published by Epidemiology Unit, Ministry of Health and Indigenous Medical Services, Sri Lanka.\nUpdate The map data is as of Sunday March 22, 2020 and the dashboard has been updated on Friday March 27, 2020.\nTo explore Global trend use Rami Krispin\u0026rsquo;s dashboard Visit: https://ramikrispin.github.io/coronavirus_dashboard/\n","date":1585094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585094400,"objectID":"b770e535c7a51754b159d562e35a76af","permalink":"https://thiyanga.netlify.app/post/covid19/","publishdate":"2020-03-25T00:00:00Z","relpermalink":"/post/covid19/","section":"post","summary":"Dashboard to monitor COVID-19 situation in Sri Lanka. This dashboard is built with R using the R Makrdown framework and was adapted from â€œcoronavirus_dashboardâ€ by Rami Krispin.","tags":["R","shiny","plotly"],"title":"Dashboard to monitor COVID-19 situation in Sri Lanka","type":"post"},{"authors":null,"categories":null,"content":"","date":1576713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576713600,"objectID":"50d915ce7d2050b866480e5d0af3f138","permalink":"https://thiyanga.netlify.app/project/rladies/","publishdate":"2019-12-19T00:00:00Z","relpermalink":"/project/rladies/","section":"project","summary":"R-Ladies is a worldwide organization whose mission is to promote diversity in the R community.","tags":["Demo"],"title":"R-Ladies Colombo","type":"project"},{"authors":null,"categories":null,"content":"Abstract\nThis work presents two feature-based forecasting algorithms for large-scale time series forecasting. The algorithms involve computing a range of features of the time series which are then used to select the forecasting model. The forecasting model selection process is carried out using a pre-trained classifier. In our first algorithm we use a random forest algorithm to train the classifier. We call this framework FFORMS (Feature-based FORecast Model Selection). The second algorithm use efficient Bayesian multivariate surface regression approach to estimate forecast error for each method, and then using the minimum predicted error to select a forecasting model. Both algorithms have been evaluated using time series from the M4 competition, and is shown to yield accurate forecasts comparable to several benchmarks and other commonly used automated approaches in the time series forecasting literature. The methods are made available in the seer and fformpp packages in R.\nkeywords: Meta-learning, classification, surface regression\n","date":1562284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562284800,"objectID":"af8c5c25ef74d00311b839d5dad2d118","permalink":"https://thiyanga.netlify.app/talk/user19-talk/","publishdate":"2019-07-05T00:00:00Z","relpermalink":"/talk/user19-talk/","section":"talk","summary":"Abstract\nThis work presents two feature-based forecasting algorithms for large-scale time series forecasting. The algorithms involve computing a range of features of the time series which are then used to select the forecasting model. The forecasting model selection process is carried out using a pre-trained classifier. In our first algorithm we use a random forest algorithm to train the classifier. We call this framework FFORMS (Feature-based FORecast Model Selection). The second algorithm use efficient Bayesian multivariate surface regression approach to estimate forecast error for each method, and then using the minimum predicted error to select a forecasting model.","tags":null,"title":"Feature-based Time Series Forecasting","type":"talk"},{"authors":null,"categories":null,"content":"Abstract\nPeeking inside FFORMS: Feature-based FORecast Model Selection Thiyanga S. Talagala$^1$, Rob J. Hyndman$^1$, George Athanasopoulos$^1$\n$^1$Department of Econometrics and Business Statistics, Monash University, Australia\nFeatures of time series are useful in identifying suitable forecast models. Talagala, Hyndman \u0026amp; Athanasopoulos (2018) proposed a classification framework, called FFORMS (Feature-based FORecast Model Selection), which selects forecast models based on features calculated from the time series. The FFORMS framework builds a mapping that relates the features of a time series to the â€œbestâ€ forecast model using the random forest algorithm. In this paper we explore what is happening under the hood of the FFORMS framework and thereby gain an understanding of what features lead to the different choices of forecast models and how different features influence the predicted outcome. This is accomplished using model-agnostic machine learning interpretability approaches. Partial-dependency plots are used to visualize both main and interaction effects of features. The results of this study provide a valuable insight into how different features and their interactions affect the choice of forecast model selection. This gives a more refined picture of the relationship between features and the choice of forecast model which is particularly valuable for ongoing research in the field of feature-based time series analysis.\nKeywords: forecasting, time series, machine learning interpretability, black-box models, LIME\nReferences Talagala, TS, RJ Hyndman \u0026amp; G Athanasopoulos (2018). Meta-learning how to forecast time series. Working paper 6/18. Monash University, Department of Econometrics and Business Statistics\n","date":1560211200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560211200,"objectID":"71cd3124761c0328036aa141606bdbee","permalink":"https://thiyanga.netlify.app/talk/isf19-talk/","publishdate":"2019-06-11T00:00:00Z","relpermalink":"/talk/isf19-talk/","section":"talk","summary":"Abstract\nPeeking inside FFORMS: Feature-based FORecast Model Selection Thiyanga S. Talagala$^1$, Rob J. Hyndman$^1$, George Athanasopoulos$^1$\n$^1$Department of Econometrics and Business Statistics, Monash University, Australia\nFeatures of time series are useful in identifying suitable forecast models. Talagala, Hyndman \u0026amp; Athanasopoulos (2018) proposed a classification framework, called FFORMS (Feature-based FORecast Model Selection), which selects forecast models based on features calculated from the time series. The FFORMS framework builds a mapping that relates the features of a time series to the â€œbestâ€ forecast model using the random forest algorithm.","tags":null,"title":"Peeking inside FFORMS: Feature-based FORecast Model Selection","type":"talk"},{"authors":null,"categories":["dplyr"],"content":"\rPackages\nlibrary(tidyverse)\rLoad iris data set\ndata(\u0026quot;iris\u0026quot;)\rhead(iris)\r## Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## 1 5.1 3.5 1.4 0.2 setosa\r## 2 4.9 3.0 1.4 0.2 setosa\r## 3 4.7 3.2 1.3 0.2 setosa\r## 4 4.6 3.1 1.5 0.2 setosa\r## 5 5.0 3.6 1.4 0.2 setosa\r## 6 5.4 3.9 1.7 0.4 setosa\rsummarise: to summarize only a single column\riris %\u0026gt;% group_by(Species) %\u0026gt;% summarise(mean(Sepal.Length))\r## `summarise()` ungrouping output (override with `.groups` argument)\r## # A tibble: 3 x 2\r## Species `mean(Sepal.Length)`\r## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 setosa 5.01\r## 2 versicolor 5.94\r## 3 virginica 6.59\rsummarise_all: to summarize all columns\riris %\u0026gt;% group_by(Species) %\u0026gt;% summarise_all(.funs = c(mean=\u0026quot;mean\u0026quot;))\r## # A tibble: 3 x 5\r## Species Sepal.Length_mean Sepal.Width_mean Petal.Length_meâ€¦ Petal.Width_mean\r## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 setosa 5.01 3.43 1.46 0.246\r## 2 versicolâ€¦ 5.94 2.77 4.26 1.33 ## 3 virginica 6.59 2.97 5.55 2.03\rsummarise_at: to summarize only certain columns\riris %\u0026gt;% group_by(Species) %\u0026gt;% summarise_at(\r.vars = vars(Sepal.Length, Sepal.Width),\r.funs = c(mean=\u0026quot;mean\u0026quot;))\r## # A tibble: 3 x 3\r## Species Sepal.Length_mean Sepal.Width_mean\r## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 setosa 5.01 3.43\r## 2 versicolor 5.94 2.77\r## 3 virginica 6.59 2.97\rsummarise_if\riris %\u0026gt;% group_by(Species) %\u0026gt;% summarise_if(.predicate = function(x) is.numeric(x),\r.funs = funs(mean=\u0026quot;mean\u0026quot;))\r## Warning: `funs()` is deprecated as of dplyr 0.8.0.\r## Please use a list of either functions or lambdas: ## ## # Simple named list: ## list(mean = mean, median = median)\r## ## # Auto named with `tibble::lst()`: ## tibble::lst(mean, median)\r## ## # Using lambdas\r## list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\r## This warning is displayed once every 8 hours.\r## Call `lifecycle::last_warnings()` to see where this warning was generated.\r## # A tibble: 3 x 5\r## Species Sepal.Length_mean Sepal.Width_mean Petal.Length_meâ€¦ Petal.Width_mean\r## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 setosa 5.01 3.43 1.46 0.246\r## 2 versicolâ€¦ 5.94 2.77 4.26 1.33 ## 3 virginica 6.59 2.97 5.55 2.03\rpass multiple functions\niris %\u0026gt;% group_by(Species) %\u0026gt;% summarise_if(.predicate = function(x) is.numeric(x),\r.funs = funs(mean=\u0026quot;mean\u0026quot;, Sd=\u0026quot;sd\u0026quot;))\r## # A tibble: 3 x 9\r## Species Sepal.Length_meâ€¦ Sepal.Width_mean Petal.Length_meâ€¦ Petal.Width_mean\r## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 setosa 5.01 3.43 1.46 0.246\r## 2 versicâ€¦ 5.94 2.77 4.26 1.33 ## 3 virginâ€¦ 6.59 2.97 5.55 2.03 ## # â€¦ with 4 more variables: Sepal.Length_Sd \u0026lt;dbl\u0026gt;, Sepal.Width_Sd \u0026lt;dbl\u0026gt;,\r## # Petal.Length_Sd \u0026lt;dbl\u0026gt;, Petal.Width_Sd \u0026lt;dbl\u0026gt;\r","date":1558137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558137600,"objectID":"2184788d8c1b820cb4a3887072f53140","permalink":"https://thiyanga.netlify.app/post/dplyr/","publishdate":"2019-05-18T00:00:00Z","relpermalink":"/post/dplyr/","section":"post","summary":"Summarizing variables with dplyr","tags":["R","dplyr"],"title":"Summarizing with dplyr","type":"post"},{"authors":["Thiyanga S. Talagala"],"categories":null,"content":"\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\rSupplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://thiyanga.netlify.app/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":null,"categories":["R","tidyverse","gganimate"],"content":"\rinstall packages\rTo install multiple packages with a single call to install.packages, pass the names of the packages as a character vector to the install.packages() function.\ninstall.packages(c(\u0026quot;gganimate\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;gapminder\u0026quot;))\rload packages\rOnce you have the packages installed, you can make their contents available to use in your current R session by running,\nlapply(c(\u0026quot;gganimate\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;gapminder\u0026quot;), require, character.only = TRUE)\r## [[1]]\r## [1] TRUE\r## ## [[2]]\r## [1] TRUE\r## ## [[3]]\r## [1] TRUE\rcheck and install missing packages\rlist.of.packages \u0026lt;- c(\u0026quot;gganimate\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;gapminder\u0026quot;)\rnew.packages \u0026lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,\u0026quot;Package\u0026quot;])]\rif(length(new.packages)) install.packages(new.packages)\rFor other alternatives see\rlittler\rlibrary(littler)\rinstall.r EIAdata gdata ggmap ggplot2 ipak\ripak \u0026lt;- function(pkg){\rnew.pkg \u0026lt;- pkg[!(pkg %in% installed.packages()[, \u0026quot;Package\u0026quot;])]\rif (length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)\rsapply(pkg, require, character.only = TRUE)\r}\r# usage\rpackages \u0026lt;- c(\u0026quot;gganimate\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;gapminder\u0026quot;)\ripak(packages)\r## gganimate tidyverse gapminder ## TRUE TRUE TRUE\reasypackages\r","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553212800,"objectID":"e9aed67f73f88a04797b48235d695908","permalink":"https://thiyanga.netlify.app/post/multiplepkg/","publishdate":"2019-03-22T00:00:00Z","relpermalink":"/post/multiplepkg/","section":"post","summary":"Install multiple R packages at once/ check and install missing packages.","tags":["R","tidyverse","gganimate"],"title":"How to install and load multiple packages at once?","type":"post"},{"authors":null,"categories":null,"content":"Abstract\nThis work presents three feature-based algorithms for large-scale time series forecasting. The algorithms are developed based on meta-learning approach. In our first algorithm we use a random forest algorithm to identify the best forecasting model. We call this framework FFORMS (Feature-based FORecast Model Selection). In the second algorithm, FFORMA (Feature-based FORecast Model Averaging), we use gradient boosting to obtain the weights for forecast combinations. The third algorithm use efficient Bayesian multivariate surface regression approach to estimate forecast error for each method, and then using the minimum predicted error to select a forecasting model or to choose individual models for forecast combinations. The proposed algorithms perform well compared to several benchmarks and other commonly used approaches in large-scale forecasting.\n","date":1552435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552435200,"objectID":"c68ed0dd55537c2b8012a18a3b0168f3","permalink":"https://thiyanga.netlify.app/talk/beijingtalk19-talk/","publishdate":"2019-03-13T00:00:00Z","relpermalink":"/talk/beijingtalk19-talk/","section":"talk","summary":"Abstract\nThis work presents three feature-based algorithms for large-scale time series forecasting. The algorithms are developed based on meta-learning approach. In our first algorithm we use a random forest algorithm to identify the best forecasting model. We call this framework FFORMS (Feature-based FORecast Model Selection). In the second algorithm, FFORMA (Feature-based FORecast Model Averaging), we use gradient boosting to obtain the weights for forecast combinations. The third algorithm use efficient Bayesian multivariate surface regression approach to estimate forecast error for each method, and then using the minimum predicted error to select a forecasting model or to choose individual models for forecast combinations.","tags":null,"title":"Feature-based time series forecasting","type":"talk"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://thiyanga.netlify.app/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":["R","Rmarkdown"],"content":"\ralpha:\rbeta:\rgamma\rdelta\r\\alpha : \\(\\alpha\\)\r\\beta: \\(\\beta\\)\r\\gamma: \\(\\gamma\\)\r\\delta: \\(\\delta\\)\r\\Gamma: \\(\\Gamma\\)\r\\Delta: \\(\\Delta\\)\repsilon\rZeta\reta\rtheta\r\\epsilon: \\(\\epsilon\\)\r\\zeta: \\(\\zeta\\)\r\\eta: \\(\\eta\\)\r\\theta: \\(\\theta\\)\r\\varepsilon: \\(\\varepsilon\\)\r\\Theta: \\(\\Theta\\)\riota\rkappa\rlambda\rmu\r\\iota: \\(\\iota\\)\r\\kappa: \\(\\kappa\\)\r\\lambda: \\(\\lambda\\)\r\\mu: \\(\\mu\\)\rnu\rxi\rpi\rrho\r\\nu: \\(\\nu\\)\r\\xi: \\(\\xi\\)\r\\pi: \\(\\pi\\)\r\\rho: \\(\\rho\\)\r\\Xi: \\(\\Xi\\)\r\\Pi: \\(\\Pi\\)\rsigma\rupsilon\rphi\romicron\r\\sigma: \\(\\sigma\\)\r\\upsilon: \\(\\upsilon\\)\r\\phi: \\(\\phi\\)\r\\omicron: \\(\\omicron\\)\r\\Sigma: \\(\\Sigma\\)\r\\Phi: \\(\\Phi\\)\rtau\rchi\rpsi\rOmega\r\\tau: \\(\\tau\\)\r\\chi: \\(\\chi\\)\r\\psi: \\(\\psi\\)\r\\omega: \\(\\omega\\)\r\\Psi: \\(\\Psi\\)\r\\Omega: \\(\\Omega\\)\r","date":1548720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548720000,"objectID":"366ba74a62a81c39577622b6c92c2105","permalink":"https://thiyanga.netlify.app/post/greekletters/","publishdate":"2019-01-29T00:00:00Z","relpermalink":"/post/greekletters/","section":"post","summary":"Commands to type Greek letters on Rmarkdown or Latex","tags":["R","Rmarkdown"],"title":"Some useful Greek letters you might use on your reports","type":"post"},{"authors":null,"categories":["R","dplyr"],"content":"\rSometimes we need to view all the functions that are built into an R package.\rThis is done in the same way you would list variables in your workspace, using the ls function. Note that the package must be loaded before you run the ls command.\nUsage: Getting a list of functions inside the dplyr package\nlibrary(dplyr)\rls(\u0026quot;package:dplyr\u0026quot;)\r## [1] \u0026quot;%\u0026gt;%\u0026quot; \u0026quot;across\u0026quot; \u0026quot;add_count\u0026quot; ## [4] \u0026quot;add_count_\u0026quot; \u0026quot;add_row\u0026quot; \u0026quot;add_rownames\u0026quot; ## [7] \u0026quot;add_tally\u0026quot; \u0026quot;add_tally_\u0026quot; \u0026quot;all_equal\u0026quot; ## [10] \u0026quot;all_of\u0026quot; \u0026quot;all_vars\u0026quot; \u0026quot;anti_join\u0026quot; ## [13] \u0026quot;any_of\u0026quot; \u0026quot;any_vars\u0026quot; \u0026quot;arrange\u0026quot; ## [16] \u0026quot;arrange_\u0026quot; \u0026quot;arrange_all\u0026quot; \u0026quot;arrange_at\u0026quot; ## [19] \u0026quot;arrange_if\u0026quot; \u0026quot;as_data_frame\u0026quot; \u0026quot;as_label\u0026quot; ## [22] \u0026quot;as_tibble\u0026quot; \u0026quot;as.tbl\u0026quot; \u0026quot;auto_copy\u0026quot; ## [25] \u0026quot;band_instruments\u0026quot; \u0026quot;band_instruments2\u0026quot; \u0026quot;band_members\u0026quot; ## [28] \u0026quot;bench_tbls\u0026quot; \u0026quot;between\u0026quot; \u0026quot;bind_cols\u0026quot; ## [31] \u0026quot;bind_rows\u0026quot; \u0026quot;c_across\u0026quot; \u0026quot;case_when\u0026quot; ## [34] \u0026quot;changes\u0026quot; \u0026quot;check_dbplyr\u0026quot; \u0026quot;coalesce\u0026quot; ## [37] \u0026quot;collapse\u0026quot; \u0026quot;collect\u0026quot; \u0026quot;combine\u0026quot; ## [40] \u0026quot;common_by\u0026quot; \u0026quot;compare_tbls\u0026quot; \u0026quot;compare_tbls2\u0026quot; ## [43] \u0026quot;compute\u0026quot; \u0026quot;contains\u0026quot; \u0026quot;copy_to\u0026quot; ## [46] \u0026quot;count\u0026quot; \u0026quot;count_\u0026quot; \u0026quot;cumall\u0026quot; ## [49] \u0026quot;cumany\u0026quot; \u0026quot;cume_dist\u0026quot; \u0026quot;cummean\u0026quot; ## [52] \u0026quot;cur_column\u0026quot; \u0026quot;cur_data\u0026quot; \u0026quot;cur_data_all\u0026quot; ## [55] \u0026quot;cur_group\u0026quot; \u0026quot;cur_group_id\u0026quot; \u0026quot;cur_group_rows\u0026quot; ## [58] \u0026quot;current_vars\u0026quot; \u0026quot;data_frame\u0026quot; \u0026quot;data_frame_\u0026quot; ## [61] \u0026quot;db_analyze\u0026quot; \u0026quot;db_begin\u0026quot; \u0026quot;db_commit\u0026quot; ## [64] \u0026quot;db_create_index\u0026quot; \u0026quot;db_create_indexes\u0026quot; \u0026quot;db_create_table\u0026quot; ## [67] \u0026quot;db_data_type\u0026quot; \u0026quot;db_desc\u0026quot; \u0026quot;db_drop_table\u0026quot; ## [70] \u0026quot;db_explain\u0026quot; \u0026quot;db_has_table\u0026quot; \u0026quot;db_insert_into\u0026quot; ## [73] \u0026quot;db_list_tables\u0026quot; \u0026quot;db_query_fields\u0026quot; \u0026quot;db_query_rows\u0026quot; ## [76] \u0026quot;db_rollback\u0026quot; \u0026quot;db_save_query\u0026quot; \u0026quot;db_write_table\u0026quot; ## [79] \u0026quot;dense_rank\u0026quot; \u0026quot;desc\u0026quot; \u0026quot;dim_desc\u0026quot; ## [82] \u0026quot;distinct\u0026quot; \u0026quot;distinct_\u0026quot; \u0026quot;distinct_all\u0026quot; ## [85] \u0026quot;distinct_at\u0026quot; \u0026quot;distinct_if\u0026quot; \u0026quot;distinct_prepare\u0026quot; ## [88] \u0026quot;do\u0026quot; \u0026quot;do_\u0026quot; \u0026quot;dplyr_col_modify\u0026quot; ## [91] \u0026quot;dplyr_reconstruct\u0026quot; \u0026quot;dplyr_row_slice\u0026quot; \u0026quot;ends_with\u0026quot; ## [94] \u0026quot;enexpr\u0026quot; \u0026quot;enexprs\u0026quot; \u0026quot;enquo\u0026quot; ## [97] \u0026quot;enquos\u0026quot; \u0026quot;ensym\u0026quot; \u0026quot;ensyms\u0026quot; ## [100] \u0026quot;eval_tbls\u0026quot; \u0026quot;eval_tbls2\u0026quot; \u0026quot;everything\u0026quot; ## [103] \u0026quot;explain\u0026quot; \u0026quot;expr\u0026quot; \u0026quot;failwith\u0026quot; ## [106] \u0026quot;filter\u0026quot; \u0026quot;filter_\u0026quot; \u0026quot;filter_all\u0026quot; ## [109] \u0026quot;filter_at\u0026quot; \u0026quot;filter_if\u0026quot; \u0026quot;first\u0026quot; ## [112] \u0026quot;frame_data\u0026quot; \u0026quot;full_join\u0026quot; \u0026quot;funs\u0026quot; ## [115] \u0026quot;funs_\u0026quot; \u0026quot;glimpse\u0026quot; \u0026quot;group_by\u0026quot; ## [118] \u0026quot;group_by_\u0026quot; \u0026quot;group_by_all\u0026quot; \u0026quot;group_by_at\u0026quot; ## [121] \u0026quot;group_by_drop_default\u0026quot; \u0026quot;group_by_if\u0026quot; \u0026quot;group_by_prepare\u0026quot; ## [124] \u0026quot;group_cols\u0026quot; \u0026quot;group_data\u0026quot; \u0026quot;group_indices\u0026quot; ## [127] \u0026quot;group_indices_\u0026quot; \u0026quot;group_keys\u0026quot; \u0026quot;group_map\u0026quot; ## [130] \u0026quot;group_modify\u0026quot; \u0026quot;group_nest\u0026quot; \u0026quot;group_rows\u0026quot; ## [133] \u0026quot;group_size\u0026quot; \u0026quot;group_split\u0026quot; \u0026quot;group_trim\u0026quot; ## [136] \u0026quot;group_vars\u0026quot; \u0026quot;group_walk\u0026quot; \u0026quot;grouped_df\u0026quot; ## [139] \u0026quot;groups\u0026quot; \u0026quot;id\u0026quot; \u0026quot;ident\u0026quot; ## [142] \u0026quot;if_else\u0026quot; \u0026quot;inner_join\u0026quot; \u0026quot;intersect\u0026quot; ## [145] \u0026quot;is_grouped_df\u0026quot; \u0026quot;is.grouped_df\u0026quot; \u0026quot;is.src\u0026quot; ## [148] \u0026quot;is.tbl\u0026quot; \u0026quot;lag\u0026quot; \u0026quot;last\u0026quot; ## [151] \u0026quot;last_col\u0026quot; \u0026quot;lead\u0026quot; \u0026quot;left_join\u0026quot; ## [154] \u0026quot;location\u0026quot; \u0026quot;lst\u0026quot; \u0026quot;lst_\u0026quot; ## [157] \u0026quot;make_tbl\u0026quot; \u0026quot;matches\u0026quot; \u0026quot;min_rank\u0026quot; ## [160] \u0026quot;mutate\u0026quot; \u0026quot;mutate_\u0026quot; \u0026quot;mutate_all\u0026quot; ## [163] \u0026quot;mutate_at\u0026quot; \u0026quot;mutate_each\u0026quot; \u0026quot;mutate_each_\u0026quot; ## [166] \u0026quot;mutate_if\u0026quot; \u0026quot;n\u0026quot; \u0026quot;n_distinct\u0026quot; ## [169] \u0026quot;n_groups\u0026quot; \u0026quot;na_if\u0026quot; \u0026quot;near\u0026quot; ## [172] \u0026quot;nest_by\u0026quot; \u0026quot;nest_join\u0026quot; \u0026quot;new_grouped_df\u0026quot; ## [175] \u0026quot;nth\u0026quot; \u0026quot;ntile\u0026quot; \u0026quot;num_range\u0026quot; ## [178] \u0026quot;one_of\u0026quot; \u0026quot;order_by\u0026quot; \u0026quot;percent_rank\u0026quot; ## [181] \u0026quot;progress_estimated\u0026quot; \u0026quot;pull\u0026quot; \u0026quot;quo\u0026quot; ## [184] \u0026quot;quo_name\u0026quot; \u0026quot;quos\u0026quot; \u0026quot;recode\u0026quot; ## [187] \u0026quot;recode_factor\u0026quot; \u0026quot;relocate\u0026quot; \u0026quot;rename\u0026quot; ## [190] \u0026quot;rename_\u0026quot; \u0026quot;rename_all\u0026quot; \u0026quot;rename_at\u0026quot; ## [193] \u0026quot;rename_if\u0026quot; \u0026quot;rename_vars\u0026quot; \u0026quot;rename_vars_\u0026quot; ## [196] \u0026quot;rename_with\u0026quot; \u0026quot;right_join\u0026quot; \u0026quot;row_number\u0026quot; ## [199] \u0026quot;rows_delete\u0026quot; \u0026quot;rows_insert\u0026quot; \u0026quot;rows_patch\u0026quot; ## [202] \u0026quot;rows_update\u0026quot; \u0026quot;rows_upsert\u0026quot; \u0026quot;rowwise\u0026quot; ## [205] \u0026quot;same_src\u0026quot; \u0026quot;sample_frac\u0026quot; \u0026quot;sample_n\u0026quot; ## [208] \u0026quot;select\u0026quot; \u0026quot;select_\u0026quot; \u0026quot;select_all\u0026quot; ## [211] \u0026quot;select_at\u0026quot; \u0026quot;select_if\u0026quot; \u0026quot;select_var\u0026quot; ## [214] \u0026quot;select_vars\u0026quot; \u0026quot;select_vars_\u0026quot; \u0026quot;semi_join\u0026quot; ## [217] \u0026quot;setdiff\u0026quot; \u0026quot;setequal\u0026quot; \u0026quot;show_query\u0026quot; ## [220] \u0026quot;slice\u0026quot; \u0026quot;slice_\u0026quot; \u0026quot;slice_head\u0026quot; ## [223] \u0026quot;slice_max\u0026quot; \u0026quot;slice_min\u0026quot; \u0026quot;slice_sample\u0026quot; ## [226] \u0026quot;slice_tail\u0026quot; \u0026quot;sql\u0026quot; \u0026quot;sql_escape_ident\u0026quot; ## [229] \u0026quot;sql_escape_string\u0026quot; \u0026quot;sql_join\u0026quot; \u0026quot;sql_select\u0026quot; ## [232] \u0026quot;sql_semi_join\u0026quot; \u0026quot;sql_set_op\u0026quot; \u0026quot;sql_subquery\u0026quot; ## [235] \u0026quot;sql_translate_env\u0026quot; \u0026quot;src\u0026quot; \u0026quot;src_df\u0026quot; ## [238] \u0026quot;src_local\u0026quot; \u0026quot;src_mysql\u0026quot; \u0026quot;src_postgres\u0026quot; ## [241] \u0026quot;src_sqlite\u0026quot; \u0026quot;src_tbls\u0026quot; \u0026quot;starts_with\u0026quot; ## [244] \u0026quot;starwars\u0026quot; \u0026quot;storms\u0026quot; \u0026quot;summarise\u0026quot; ## [247] \u0026quot;summarise_\u0026quot; \u0026quot;summarise_all\u0026quot; \u0026quot;summarise_at\u0026quot; ## [250] \u0026quot;summarise_each\u0026quot; \u0026quot;summarise_each_\u0026quot; \u0026quot;summarise_if\u0026quot; ## [253] \u0026quot;summarize\u0026quot; \u0026quot;summarize_\u0026quot; \u0026quot;summarize_all\u0026quot; ## [256] \u0026quot;summarize_at\u0026quot; \u0026quot;summarize_each\u0026quot; \u0026quot;summarize_each_\u0026quot; ## [259] \u0026quot;summarize_if\u0026quot; \u0026quot;sym\u0026quot; \u0026quot;syms\u0026quot; ## [262] \u0026quot;tally\u0026quot; \u0026quot;tally_\u0026quot; \u0026quot;tbl\u0026quot; ## [265] \u0026quot;tbl_df\u0026quot; \u0026quot;tbl_nongroup_vars\u0026quot; \u0026quot;tbl_ptype\u0026quot; ## [268] \u0026quot;tbl_sum\u0026quot; \u0026quot;tbl_vars\u0026quot; \u0026quot;tibble\u0026quot; ## [271] \u0026quot;top_frac\u0026quot; \u0026quot;top_n\u0026quot; \u0026quot;transmute\u0026quot; ## [274] \u0026quot;transmute_\u0026quot; \u0026quot;transmute_all\u0026quot; \u0026quot;transmute_at\u0026quot; ## [277] \u0026quot;transmute_if\u0026quot; \u0026quot;tribble\u0026quot; \u0026quot;trunc_mat\u0026quot; ## [280] \u0026quot;type_sum\u0026quot; \u0026quot;ungroup\u0026quot; \u0026quot;union\u0026quot; ## [283] \u0026quot;union_all\u0026quot; \u0026quot;validate_grouped_df\u0026quot; \u0026quot;vars\u0026quot; ## [286] \u0026quot;with_groups\u0026quot; \u0026quot;with_order\u0026quot; \u0026quot;wrap_dbplyr_obj\u0026quot;\r","date":1538697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538697600,"objectID":"bde5482c31ba3daddffaeeb0e02e40fb","permalink":"https://thiyanga.netlify.app/post/packageinfo/","publishdate":"2018-10-05T00:00:00Z","relpermalink":"/post/packageinfo/","section":"post","summary":"Sometimes we need to view all the functions that are built into an R package.","tags":["R","dplyr"],"title":"What's in a package?","type":"post"},{"authors":null,"categories":["ggplot2"],"content":"Boxplot is probably one of the most common type of graphics. This will show how to customize boxplots.\nYou will learn,\nhow to change the order of labels\nhow to change the colours\nhow to flip coordinates\nStep 1: we create a simple data set.\nGender \u0026lt;- rep(c(\u0026#34;Male\u0026#34;, \u0026#34;Female\u0026#34;), times = 3, each = 4) Quality \u0026lt;- rep(c(\u0026#34;Taste\u0026#34;, \u0026#34;Color of package\u0026#34;, \u0026#34;Capacity\u0026#34;), times = 1, each = 8) Accepted \u0026lt;- seq(0, 100, by = 100/23) DF \u0026lt;- data.frame(Gender, Quality, Accepted) head(DF) ## Gender Quality Accepted\r## 1 Male Taste 0.000000\r## 2 Male Taste 4.347826\r## 3 Male Taste 8.695652\r## 4 Male Taste 13.043478\r## 5 Female Taste 17.391304\r## 6 Female Taste 21.739130 Step 2: Generate a simple boxplot with ggplot\nlibrary(ggplot2) ggplot(DF, aes(x = Quality, y = Accepted, fill = Gender)) + geom_boxplot() Step 3: Change the colours, legend position and x-axis order\nggplot(DF, aes(x = Quality, y = Accepted, fill = Gender)) + geom_boxplot() + scale_fill_manual(values = c(\u0026#34;green\u0026#34;, \u0026#34;orange\u0026#34;)) + xlab(\u0026#34;\u0026#34;) + theme(legend.position = \u0026#34;top\u0026#34;, legend.title = element_blank()) + scale_x_discrete(limits=c(\u0026#34;Taste\u0026#34;, \u0026#34;Color of package\u0026#34;, \u0026#34;Capacity\u0026#34;)) Step 4: Change the plotting order: first you have to include factor code to set the order of the levels.\nDF$Gender_factor \u0026lt;- factor(DF$Gender, levels=c(\u0026#34;Male\u0026#34;, \u0026#34;Female\u0026#34;)) ggplot(DF, aes(x = Quality, y = Accepted, fill = Gender_factor)) + geom_boxplot() + scale_fill_manual(values = c(\u0026#34;green\u0026#34;, \u0026#34;orange\u0026#34;)) + xlab(\u0026#34;\u0026#34;) + theme(legend.position = \u0026#34;top\u0026#34;, legend.title = element_blank()) + scale_x_discrete(limits=c(\u0026#34;Taste\u0026#34;, \u0026#34;Color of package\u0026#34;, \u0026#34;Capacity\u0026#34;)) Step 5: Horizontal bar chart: coord_flip()\nggplot(DF, aes(x = Quality, y = Accepted, fill = Gender)) + geom_boxplot() + scale_fill_manual(values = c(\u0026#34;green\u0026#34;, \u0026#34;orange\u0026#34;)) + xlab(\u0026#34;\u0026#34;) + theme(legend.position = \u0026#34;top\u0026#34;, legend.title = element_blank()) + coord_flip()+ scale_x_discrete(limits=c(\u0026#34;Taste\u0026#34;, \u0026#34;Color of package\u0026#34;, \u0026#34;Capacity\u0026#34;)) step 6: Change the legend order similar to plot order: under themes fill=guide_legend(reverse=FALSE)\nggplot(DF, aes(x = Quality, y = Accepted, fill = Gender)) + geom_boxplot() + scale_fill_manual(values = c(\u0026#34;green\u0026#34;, \u0026#34;orange\u0026#34;)) + xlab(\u0026#34;\u0026#34;) + theme(legend.position = \u0026#34;top\u0026#34;, legend.title = element_blank()) + guides(fill=guide_legend(reverse=TRUE)) + coord_flip()+ scale_x_discrete(limits=c(\u0026#34;Taste\u0026#34;, \u0026#34;Color of package\u0026#34;, \u0026#34;Capacity\u0026#34;)) ","date":1536105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536105600,"objectID":"0f848b6907da4da88dcefe0322ea7441","permalink":"https://thiyanga.netlify.app/post/blog/","publishdate":"2018-09-05T00:00:00Z","relpermalink":"/post/blog/","section":"post","summary":"Boxplot is probably one of the most common type of graphics. This will show how to customize boxplots.","tags":["R","ggplot2"],"title":"Customizing boxplots with ggplot2","type":"post"},{"authors":null,"categories":null,"content":"Working on this..\n","date":1533686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533686400,"objectID":"8c3f1d8fe352dc1260f12152b785396e","permalink":"https://thiyanga.netlify.app/post/parallelcomputing/","publishdate":"2018-08-08T00:00:00Z","relpermalink":"/post/parallelcomputing/","section":"post","summary":"Working on this..","tags":[],"title":"Parallel computing with R","type":"post"},{"authors":null,"categories":null,"content":"coming up soon!\n","date":1533600000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533600000,"objectID":"0544e9fe6dc4756a98072e0a4dca1b8e","permalink":"https://thiyanga.netlify.app/post/datatypes/","publishdate":"2018-08-07T00:00:00Z","relpermalink":"/post/datatypes/","section":"post","summary":"coming up soon!","tags":[],"title":"Data Types in R","type":"post"},{"authors":null,"categories":null,"content":"The background pictures are of free copyright from https://pixabay.com/en/photos/presentation/.\nAssociated R package: seer\n","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533081600,"objectID":"e92016f7160966baa922bf6dcf76c69f","permalink":"https://thiyanga.netlify.app/talk/jsm18-talk/","publishdate":"2018-08-01T00:00:00Z","relpermalink":"/talk/jsm18-talk/","section":"talk","summary":"https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=330245","tags":null,"title":"A classification framework for forecast-model selection","type":"talk"},{"authors":null,"categories":null,"content":"Abstract\nThe seer package provides a novel framework for forecast model selection using time series features. We call this framework FFORMS (Feature-based FORecast Model Selection). The underlying approach involves computing a vector of features from the time series which are then used to select the forecasting model. The model selection process is carried out using a classification algorithm \u0026ndash; we use the time series features as inputs, and the best forecasting algorithm as the output. The classification algorithm can be built in advance of the forecasting exercise (so it is an â€œofflineâ€ procedure). Then, when we have a new time series to forecast, we can quickly compute its features, use the pre-trained classification algorithm to identify the best forecasting model, and produce the required forecasts. Thus, the â€œonlineâ€ part of our algorithm requires only feature computation, and the application of a single forecasting model, with no need to estimate large numbers of models within a class, or to carry out a computationally-intensive cross-validation procedure. This framework is compared against several benchmarks and other commonly used forecasting methods.\nLink to git repository: seer\n","date":1531440000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531440000,"objectID":"55dccf4c5a29dd82879bd4f918a420a2","permalink":"https://thiyanga.netlify.app/talk/user18-talk/","publishdate":"2018-07-13T00:00:00Z","relpermalink":"/talk/user18-talk/","section":"talk","summary":"Abstract\nThe seer package provides a novel framework for forecast model selection using time series features. We call this framework FFORMS (Feature-based FORecast Model Selection). The underlying approach involves computing a vector of features from the time series which are then used to select the forecasting model. The model selection process is carried out using a classification algorithm \u0026ndash; we use the time series features as inputs, and the best forecasting algorithm as the output.","tags":null,"title":"seer: R package for feature-based forecast model selection","type":"talk"},{"authors":null,"categories":null,"content":"Abstract\nA crucial task in time series forecasting is the identification of the most suitable forecasting method. We present a general framework for forecast model selection using meta-learning. A Random Forest is used to predict the best forecasting method using only time series features. The proposed framework has been evaluated using time series from the M1 and M3 competitions, and is shown to yield accurate forecasts comparable to several benchmarks and other commonly used automated approaches of time series forecasting. A key advantage of our algorithm is that the time-consuming part of building the random forest can be handled in advance of the forecasting task.\n","date":1528502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528502400,"objectID":"299ac0d759174f6116404efa6267869a","permalink":"https://thiyanga.netlify.app/talk/isf18-talk/","publishdate":"2018-06-09T00:00:00Z","relpermalink":"/talk/isf18-talk/","section":"talk","summary":"Abstract\nA crucial task in time series forecasting is the identification of the most suitable forecasting method. We present a general framework for forecast model selection using meta-learning. A Random Forest is used to predict the best forecasting method using only time series features. The proposed framework has been evaluated using time series from the M1 and M3 competitions, and is shown to yield accurate forecasts comparable to several benchmarks and other commonly used automated approaches of time series forecasting.","tags":null,"title":"Meta-learning how to forecast time series","type":"talk"},{"authors":null,"categories":null,"content":"","date":1518393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518393600,"objectID":"99fad8d2730a91524d4a348202ea3b47","permalink":"https://thiyanga.netlify.app/talk/japan18-talk/","publishdate":"2018-02-12T00:00:00Z","relpermalink":"/talk/japan18-talk/","section":"talk","summary":"","tags":null,"title":"Analysing large collections of time series","type":"talk"},{"authors":null,"categories":null,"content":"Abstract\nMany applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making. However, large scale time series data present numerous challenges in modelling and implementation due to the high dimensionality. It is unlikely that a single method will consistently provides better forecasts across all time series. On the other hand, selecting individual forecast models when the number of series is very large can be extremely challenging. In this paper we propose a classification framework which selects forecast models based on features calculated from the time series. A Random Forest approach is used to develop the classifier. The proposed framework is tested using the M3 data and is compared against several benchmarks and other commonly used approaches of forecasting.\n","date":1498435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498435200,"objectID":"e9693cefbfbe4b5fc9d03b6ee5b201ff","permalink":"https://thiyanga.netlify.app/talk/isf17-talk/","publishdate":"2017-06-26T00:00:00Z","relpermalink":"/talk/isf17-talk/","section":"talk","summary":"Abstract\nMany applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making. However, large scale time series data present numerous challenges in modelling and implementation due to the high dimensionality. It is unlikely that a single method will consistently provides better forecasts across all time series. On the other hand, selecting individual forecast models when the number of series is very large can be extremely challenging.","tags":null,"title":"Feature-based model selection for time series forecasting","type":"talk"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"c7ba5016f60dbd4bb60ee207effd5b93","permalink":"https://thiyanga.netlify.app/talk/ssa17-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/ssa17-talk/","section":"talk","summary":"","tags":null,"title":"Feature-based model selection for time series forecasting","type":"talk"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"fcda67318c59693ce49660d71b6fdf6f","permalink":"https://thiyanga.netlify.app/talk/ysc17-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/ysc17-talk/","section":"talk","summary":"","tags":null,"title":"Feature-based model selection for time series forecasting","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e6c4171b3bda35c314832458341d0a1a","permalink":"https://thiyanga.netlify.app/project/timeseries/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/timeseries/","section":"project","summary":"Computationally efficient forecasting methods for large-scale real-time applications","tags":["Demo"],"title":"Large-Scale Time Series Forecasting","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"5b7dc0394d1ea428e0024d4ead7f0b16","permalink":"https://thiyanga.netlify.app/project/hellor/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/hellor/","section":"project","summary":"The course website for my teaching unit STA 326 2.0 Programming and Data Analysis with R","tags":["Demo"],"title":"Programming and Data Analysis with R","type":"project"},{"authors":["Thiyanga S. Talagala","Robert Ford"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\rSupplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://thiyanga.netlify.app/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Thiyanga S. Talagala","Robert Ford"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\rSupplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://thiyanga.netlify.app/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]