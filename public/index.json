[{"authors":["admin"],"categories":null,"content":"I am a Senior Lecturer in the Department of Statistics, Faculty of Applied Sciences at the University of Sri Jayewardenepura. I received my PhD in statistics from Monash University, Australia in 2019. My thesis advisors were Professor Rob J Hyndman and Professor George Athanasopoulos.\nI am also an Associate Investigator of the Australian Research Council (ARC) Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS).\nI enjoy solving general data science problems from three different angles: theoretical, computational, applied. On this website you will find some of my work and interests in statistics and data analysis. My research focuses on developing new statistical machine learning tools to help both practitioners and theoreticians make more open, explainable and reproducible data-driven discoveries. I am also interested in R programming language.\nPriyanga Dilini Talagala PhD in Statistics, Monash University, Australia is my sister.\n","date":1554595200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Senior Lecturer in the Department of Statistics, Faculty of Applied Sciences at the University of Sri Jayewardenepura. I received my PhD in statistics from Monash University, Australia in 2019. My thesis advisors were Professor Rob J Hyndman and Professor George Athanasopoulos.\nI am also an Associate Investigator of the Australian Research Council (ARC) Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS).\nI enjoy solving general data science problems from three different angles: theoretical, computational, applied.","tags":null,"title":"Thiyanga S. Talagala","type":"authors"},{"authors":null,"categories":null,"content":"STA 331 2.0 Stochastic Processes BSc (Hons) Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 2\nCommencement date: 28 July 2020\nCourse meeting time: Tuesday, 1.00pm - 3.00pm\nLocation: Online/ Department of Statistics, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Tuesday 3:00pm – 4:00pm. Email me for other times.\nE-mail is the best way to get in contact with me—I will respond to all course-related e-mails within 24 hours.\n","date":1595894400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1595894400,"objectID":"9c0788947d26d9a05e0fbb26729f15b0","permalink":"/courses/sta33120_stochastic_processes_2020/","publishdate":"2020-07-28T00:00:00Z","relpermalink":"/courses/sta33120_stochastic_processes_2020/","section":"courses","summary":"STA 331 2.0 Stochastic Processes BSc (Hons) Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 2\nCommencement date: 28 July 2020\nCourse meeting time: Tuesday, 1.00pm - 3.00pm\nLocation: Online/ Department of Statistics, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Tuesday 3:00pm – 4:00pm.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"STA 506 2.0 Linear Regression Analysis Postgraduate Certificate Program in Applied Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 1\nCommencement date: 29 August 2020\nCourse meeting time: Saturday, 2.00pm - 4.00pm\nLocation: Online/ LCS 2, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nSoftware: R programming language\nContact Information Lecturer-in-charge: Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Saturday 4:00pm – 5:00pm. Email me for other times.\nE-mail is the best way to get in contact with me—I will respond to all course-related e-mails within 24 hours.\n","date":1594339200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1594339200,"objectID":"2316a50c2857ebd9e6743a52e272832e","permalink":"/courses/regression2020/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/courses/regression2020/","section":"courses","summary":"STA 506 2.0 Linear Regression Analysis Postgraduate Certificate Program in Applied Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 1\nCommencement date: 29 August 2020\nCourse meeting time: Saturday, 2.00pm - 4.00pm\nLocation: Online/ LCS 2, Faculty of Applied Sciences, USJ\nPlease enrol in LMS for up-to-date information and announcements.\nSoftware: R programming language\nContact Information Lecturer-in-charge: Dr Thiyanga S Talagala","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"STA 517 3.0 Programming and Statistical Computing with R MSc in Applied Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 1\nCommencement date: 15 August 2020\nCourse meeting time: Sunday, 10.15am - 1.15pm\nLocation: Online/ Stat Lab 1, Faculty of Applied Sciences, USJ\nPlease enrol in Google classroom and LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala\nEmail: ttalagala@sjp.ac.lk\nOffice hours: Sunday 1.15pm – 2:15pm. Email me for other times.\nE-mail is the best way to get in contact with me—I will respond to all course-related e-mails within 24 hours.\n","date":1594339200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1594339200,"objectID":"f08e411187c6e9f4f47b869608e89e00","permalink":"/courses/rmsc2020/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/courses/rmsc2020/","section":"courses","summary":"STA 517 3.0 Programming and Statistical Computing with R MSc in Applied Statistics, Department of Statistics, University of Sri Jayewardenepura.\nCourse information Course outline: here\nYear and Semester: 2020 - Semester 1\nCommencement date: 15 August 2020\nCourse meeting time: Sunday, 10.15am - 1.15pm\nLocation: Online/ Stat Lab 1, Faculty of Applied Sciences, USJ\nPlease enrol in Google classroom and LMS for up-to-date information and announcements.\nContact Information Dr Thiyanga S Talagala","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"Here is your road map for the course!\nWeek 1  Introduction  Week 2 - 3  Markov Chains  📚 Individual Assignment - week 3\nWeek 4  Classification of states  Week 5  Limiting Probabilities  Week ( 1 September 2020 ) Holiday\nWeek 6  Continuous Parameter Markov Chains  Week 7 - 8 Week 7 📚 In-class assignment\nWeek 7 - 8   Poisson Process (cont.), Interarrival and Waiting Time Distributions\n  Assignment discussion.\n  Week 9  Poisson Process (cont.), Splitting of a Poisson process, Compound Poisson processes  Week 10 Ion Switching| Kaggle competition\nWeek 11  Nonhomogeneous Poisson Processes  Week 12 - 14   Birth and death process - Introduction, Pure Birth Process\n  Partial Differential Equations\n  Pure Death Process\n  Assignment 3: Please go the LMS (Due date: 24 Nov 2020)\n  Week 15 Revision\n END\n ","date":1595804400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595804400,"objectID":"e12b40334feab19bbc61f3993d464904","permalink":"/courses/sta33120_stochastic_processes_2020/contentr_stochastic/","publishdate":"2020-07-27T00:00:00+01:00","relpermalink":"/courses/sta33120_stochastic_processes_2020/contentr_stochastic/","section":"courses","summary":"Here is your road map for the course!\nWeek 1  Introduction  Week 2 - 3  Markov Chains  📚 Individual Assignment - week 3\nWeek 4  Classification of states  Week 5  Limiting Probabilities  Week ( 1 September 2020 ) Holiday\nWeek 6  Continuous Parameter Markov Chains  Week 7 - 8 Week 7 📚 In-class assignment\nWeek 7 - 8   Poisson Process (cont.","tags":null,"title":"STA 331 2.0 Stochastic Processes","type":"docs"},{"authors":null,"categories":null,"content":"Here is your road map for the course!\n Week 1-4: lectures (online)\n Week 1   Introduction to regression analysis\n  Simple linear regression\n  Terminologies\n  Correlation\n       📚Slides 📒 [Reading-Ch1 Introduction to Linear Regression Analysis] 📊 Data Sets - anscombe 📎 Problems - Install R and R studio 🔖Answers    Week 2 - 3   Simple linear regression (cont.)\n  Simple linear regression model\n  Least-squares estimation of the parameters\n       📚Slides 📒 [Reading-Ch2/2.2.2 Introduction to Linear Regression Analysis] 📊 Data Sets - alr3::heights 📎 Problems 🔖Answers - Discussions    Week 4   Simple linear regression (cont.)\n  Model adequacy checking\n  Introduction\n  Residual Analysis\n       📚Slides 📒 Reading - Ch1 (2.6) and Ch4 (4.2.3) 📊 Data Sets 📎 Problems 🔖Answers     Week 5-6: Discussion/practical (in class)\n Week 5 - 6   Coefficient of determination\n  Hypothesis testing on the slope and intercept\n  Interval estimation in simple linear regression\n  Prediction of new observations: point estimates and prediction intervals\n  Regression through the origin\n  Regression analysis with R\n  Problem discussion and Regression Analysis with R\n  Regression analysis with other software (Python, Minitab, SPSS, Excel) 📚\n     📚 1. Slides 2. Basics of R Programming 📒 Reading - Ch1 and Ch2 (2.3, 2.4) 📊 Data Set - house.csv 📎 Problems  Tutorial 2 🔖 Additional problems - Ch2 Problems: 2.1 - 2.17    *\n Week 7 - 8: lectures (online)\n Week 7 R for Reproducible Scientific Analysis - Visit Google Classroom\nAssignment due: 19 Oct 2020\nMid Exam: Cancelled due to Covid-19 Outbreak\nWeek 8   Multiple linear regression\n  Introduction\n  Estimation of the model parameters\n  Residual analysis\n       📚 Slides 📒 Reading - Ch3 📊 Data Sets - heart.data.csv 📎 Problems 🔖Answers    Week 9   ANOVA\n  Test of significance of regression\n  Tests on individual regression coefficients\n       📚 Slides 📒 Reading - here 📊 Data Sets - heart.data.csv and alr3::heights 📎 Problems - Quiz Google Classroom 🔖Answers    Week 10   Confidence intervals in multiple regression\n  Confidence intervals on the regression coefficients\n  Confidence interval estimation of the mean response\n    Prediction of new observations\n  Mid Evaluation Assignment - Visit LMS/ Google Classroom (1 Nov 2020) 📝 Assignment deadline: 15 Nov 2020\nSpecial considerations email me on or before 8 Nov 2020\n   📚 Slides 📒 Reading - Chapter 3, Montgomery, Peck, Vining 📊 Data Sets 📎 Problems 🔖Answers    Week 11   Transformations\n  Variance-stabilization transformations\n  Transformations to linearize the model\n  Analytical methods for selecting a transformation\n    Detection and treatment of outliers\n  Diagnostics for leverage and influence\n  Importance of detecting influential observations\n  Leverage\n  Measures of influence\n  Treatment of influential observations\n       📚Slides 📒 Reading - Section 3.3, Montgomery, Peck, Vining 📊 Data Sets - coconut.csv salarydata.csv 📎 Problems 🔖Answers    Week 12   Regression with qualitative variables\n  Indicator/ Dummy variables\n  Indicator variable with more than two levels\n  More than one indicator variable\n  Interaction term involving dummy variables\n    Variable selection procedures\n  Introduction\n  All possible regressions\n  Forward selection procedure\n  Backward elimination procedure\n  Stepwise method\n       📚Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖Answers     Week 13-14: Discussion/practical (in class)\n Week 13   Multicollinearity\n  Introduction\n  Multocollinearity diagnostics\n  Treatments for dealing with multicollinearity\n       📚Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖Answers    Week 14   Bootstrapping in regression\n  Introduction to bootstrap sampling\n  Bootstrap sampling in regression\n  Bootsrap confidence intervals\n       📚Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖Answers     Week 15: Revision (in class)\n Week 15: Revision   Current state-of-art techniques in regression analysis and statistical modelling\n  Open problems\n  Recap\n     📚Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖Answers     Week 16-18: Study leave and Final Examination\n Week 16: Study leave Week 17-18: Final exam  END\n ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"d970c4b18ab5d5a91afd734ef95f973b","permalink":"/courses/regression2020/contentreg/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/regression2020/contentreg/","section":"courses","summary":"Here is your road map for the course!\n Week 1-4: lectures (online)\n Week 1   Introduction to regression analysis\n  Simple linear regression\n  Terminologies\n  Correlation\n       📚Slides 📒 [Reading-Ch1 Introduction to Linear Regression Analysis] 📊 Data Sets - anscombe 📎 Problems - Install R and R studio 🔖Answers    Week 2 - 3   Simple linear regression (cont.","tags":null,"title":"Schedule and Lectorials","type":"docs"},{"authors":null,"categories":null,"content":"Here is your road map for the course!\nWeek 0 Help - R and R Studio Download and Install\n📗\n Week 1-4: lectures (online)\n Week 1  Introduction and basics of R programming     📚Slides 📒 Reading-2.1, 2.2, 5.1 📊 Data Sets 📎 Problems 🔖Answers    Week 2  Data structures (Matrices, Arrays, List, Data frames, Factors)     📚Slides 📒 Reading-5.3, 5.8 📊 Cheat sheet 📎 Problems 🔖 Answers    Week 3  Built-in functions in R     📚Slides 📒 Reading-Section 2.3 📊 Data Sets - iris 📎 Problems - EDA on iris 🔖Answers - In class discussion (13 Sep 2020)    Week 4  Writing functions in R and control structures     📚Slides 📒 Reading-Section 2.3 📊 Data Sets 📎 Problems 🔖Answers    💻\nWeek 5  Introduction to the tidyverse, pipe operator and data import and export     📚 Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖Answers    Week 6  Reproducible reporting with R Markdown     📚 Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖Answers    Week 7: mid exam (in class)  Week 8-12: lectures (online): Covid-19 outbreak\n Week 8  Data wrangling with tidyr     📚 Slides 📒 Reading -R4DS Ch12 📊 Cheat sheet 📎 Problems 🔖Answers     Data wrangling with dplyr  | 📚 Slides | 📒 Reading -R4DS Ch12 | 📊 Cheat sheet\t| 📎 Problems | 🔖 Answers |\nWeek 9  The grammar of graphics     📚 Slides 📒 Reading 📊 Data Sets - Details 📎 Problems\t- Perform EDA on palmerpenguins using ggplot2 🔖Answers    Load palmerpenguins using,\nlibrary(palmerpenguins) data(package = \u0026#39;palmerpenguins\u0026#39;) Week 10  Statistical modelling - Regression Analysis     📚 Slides 📒 Reading 📊 Data Sets -\tihouse.csv 📎 Problems - i 🔖Answers    Week 11  Methods of generating random numbers     📚 Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖 Answers    Week 12  Functional programming with R     📚Slides - part 1 Slides - part 2 📒 Reading 📊 Cheat sheet 📎 Problems 🔖 Answers     Week 13-14: Discussion/practical (in class)\n Week 13  Hypothesis testing     📚Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖 Answers     The method of Monte Carlo     📚Slides 📒 Reading 📊 Data Sets 📎 Problems - Questions given in the note. 🔖Answers     Assignment (20 marks): Details visit google classroom or LMS.  Week 14  Bootstrap and Jackknife     📚Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖Answers     Week 15: Revision (in class)\n Week 15: Revision  Recap     📚Slides 📒 Reading 📊 Data Sets 📎 Problems 🔖Answers     Week 16-18: Study leave and Final Examination\n Week 16: Study leave Week 17-18: Final exam  END\n ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"5441d486ec4b5f6f38fe81b1ec82b3d5","permalink":"/courses/rmsc2020/contentr/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/rmsc2020/contentr/","section":"courses","summary":"Here is your road map for the course!\nWeek 0 Help - R and R Studio Download and Install\n📗\n Week 1-4: lectures (online)\n Week 1  Introduction and basics of R programming     📚Slides 📒 Reading-2.1, 2.2, 5.1 📊 Data Sets 📎 Problems 🔖Answers    Week 2  Data structures (Matrices, Arrays, List, Data frames, Factors)     📚Slides 📒 Reading-5.","tags":null,"title":"Schedule and Lectorials","type":"docs"},{"authors":null,"categories":null,"content":"Abstract\nA Tool to Detect Potential Data Leaks in Forecasting Competitions Forecasting competitions are of increasing importance as a mean to learn best practices and gain knowledge. Data leakage is one of the most common issues that can often be found in competitions. Data leaks can happen when the training data contains information about the test data. There are a variety of different ways that data leaks can occur with time series data. For example: i) randomly chosen blocks of time series are concatenated to form a new time series, ii) scale-shifts, iii) repeating patterns in time series, iv) white noise is added in the original time series to form a new time series, etc. This work introduces a novel tool to detect these data leaks. The tsdataleaks package provides simple and computationally efficient algorithm to exploit data leaks in time series data. I will demonstrate the package design and its power to detect data leakages using recent forecasting competitions data.\nKey words: Time series, R software, Tools, Visualization\n","date":1603737000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603737000,"objectID":"eeb26d12465add722969914c59333fc1","permalink":"/talk/isf20-talk/","publishdate":"2020-10-27T00:00:00+05:30","relpermalink":"/talk/isf20-talk/","section":"talk","summary":"Abstract\nA Tool to Detect Potential Data Leaks in Forecasting Competitions Forecasting competitions are of increasing importance as a mean to learn best practices and gain knowledge. Data leakage is one of the most common issues that can often be found in competitions. Data leaks can happen when the training data contains information about the test data. There are a variety of different ways that data leaks can occur with time series data.","tags":null,"title":"A Tool to Detect Potential Data Leaks in Forecasting Competitions","type":"talk"},{"authors":null,"categories":["R"],"content":" Spotting the problem First, I create a small dataset for the demonstration. The following dataset represents the Happiness index for five countries.\nhappy \u0026lt;- data.frame( country = c(\u0026quot;Finland\u0026quot;, \u0026quot;Norway\u0026quot;, \u0026quot;Denmark\u0026quot;, \u0026quot;Iceland\u0026quot;, \u0026quot;Netherlands\u0026quot;), score = c(7.76, 7.60, 7.55, 7.49, 7.48)) happy  country score 1 Finland 7.76 2 Norway 7.60 3 Denmark 7.55 4 Iceland 7.49 5 Netherlands 7.48 Save the dataset as shown below.\nsave(happy, file=\u0026quot;happyindex.rda\u0026quot;)  Let’s load the dataset with,\nload(\u0026quot;happyindex.rda\u0026quot;) happyindex The following error message pops up,\n Error: object ‘happyindex’ not found\n  Tackling the problem loadHappy \u0026lt;- load(\u0026quot;happyindex.rda\u0026quot;) happyDataloaded \u0026lt;- get(loadHappy) happyDataloaded  ","date":1602633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602633600,"objectID":"39bd4fadb96f0e55405ca45da4e754c9","permalink":"/post/loaddatasets/","publishdate":"2020-10-14T00:00:00Z","relpermalink":"/post/loaddatasets/","section":"post","summary":"Read data files","tags":["R"],"title":"Import data into R: Overwritten object names","type":"post"},{"authors":null,"categories":["R"],"content":" To view list of data sets available in a particular package or a group of packages. vcdExtra::datasets(c(\u0026quot;ggplot2\u0026quot;, \u0026quot;forecast\u0026quot;)) Loading package: ggplot2 Loading package: forecast   Package Item class dim 1 ggplot2 diamonds data.frame 53940x10 2 ggplot2 economics data.frame 574x6 3 ggplot2 economics_long data.frame 2870x4 4 ggplot2 faithfuld data.frame 5625x3 5 ggplot2 luv_colours data.frame 657x4 6 ggplot2 midwest data.frame 437x28 7 ggplot2 mpg data.frame 234x11 8 ggplot2 msleep data.frame 83x11 9 ggplot2 presidential data.frame 11x4 10 ggplot2 seals data.frame 1155x4 11 ggplot2 txhousing data.frame 8602x9 12 forecast gas ts 476 13 forecast gold ts 1108 14 forecast taylor ts 4032 15 forecast wineind ts 176 16 forecast woolyrnq ts 119 Title 1 Prices of over 50,000 round cut diamonds 2 US economic time series 3 US economic time series 4 2d density estimate of Old Faithful data 5 \u0026#39;colors()\u0026#39; in Luv space 6 Midwest demographics 7 Fuel economy data from 1999 to 2008 for 38 popular models of cars 8 An updated and expanded version of the mammals sleep dataset 9 Terms of 11 presidents from Eisenhower to Obama 10 Vector field of seal movements 11 Housing sales in TX 12 Australian monthly gas production 13 Daily morning gold prices 14 Half-hourly electricity demand 15 Australian total wine sales 16 Quarterly production of woollen yarn in Australia  To view data sets in package datasets. data()  This opens a file called “R data sets” in the Code-Editor window as below.\n To list the data sets in all available packages data(package = .packages(all.available = TRUE)).\nThis opens a file called “R data sets” in the Code- Editor widow, listing datasets as\nData sets in package ‘alr4’: ... Data sets in package ‘asbio’: ... . . .   ","date":1598832000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598832000,"objectID":"e055284bd74cc8d66d7d9eeb3a9fd57b","permalink":"/post/datasets/","publishdate":"2020-08-31T00:00:00Z","relpermalink":"/post/datasets/","section":"post","summary":"How to view datasets in a particular package, or or list the available data sets? ","tags":["R","ggplot","fable"],"title":"Working with built-in data sets in R","type":"post"},{"authors":null,"categories":null,"content":" Checks whether your package name is taken or available !!\ninstall.packages(\u0026quot;available\u0026quot;) library(available) available(\u0026quot;seer\u0026quot;) ── seer ──────────────────────────────────────────────────────────────── Name valid: ✔ Available on CRAN: ✖ Available on Bioconductor: ✔ Available on GitHub: ✖ Abbreviations: http://www.abbreviations.com/seer Wikipedia: https://en.wikipedia.org/wiki/seer Wiktionary: https://en.wiktionary.org/wiki/seer Urban Dictionary: someone who is able to see [the past], present, and future. also known as an [oracle] or a [prophet]. http://seer.urbanup.com/7101409 Sentiment:??? This means the name seer is taken in both CRAN and GitHub.\n","date":1594166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166400,"objectID":"d30849fff7f7139813050dbcd57e9b1a","permalink":"/post/available/","publishdate":"2020-07-08T00:00:00Z","relpermalink":"/post/available/","section":"post","summary":"Checks whether your package name is taken or available !!\ninstall.packages(\u0026quot;available\u0026quot;) library(available) available(\u0026quot;seer\u0026quot;) ── seer ──────────────────────────────────────────────────────────────── Name valid: ✔ Available on CRAN: ✖ Available on Bioconductor: ✔ Available on GitHub: ✖ Abbreviations: http://www.abbreviations.com/seer Wikipedia: https://en.wikipedia.org/wiki/seer Wiktionary: https://en.wiktionary.org/wiki/seer Urban Dictionary: someone who is able to see [the past], present, and future. also known as an [oracle] or a [prophet]. http://seer.urbanup.com/7101409 Sentiment:??? This means the name seer is taken in both CRAN and GitHub.","tags":null,"title":"Small things matter!","type":"post"},{"authors":null,"categories":null,"content":" The most common problem while learning Statistics is that students’ lack of understanding of the basic terminologies, notations, definitions and concepts. Think of Statistics as building blocks, and you need a solid foundation to move forward. Here, I explain five common terms in Statistics: i) Parameter, ii) Statistic, iii) Random Variable, iv) Estimator, v) Estimate and their notations.\nI will start with the definition of Population and Sample.\nA population is a complete collection of individuals/ objects that we are interested in. A sample is a subset of a population.\nParameter A parameter is a descriptive measure(numerical value) of the population. Parameters are usually denoted by Greek letters.\nExamples of parameters:\n \\(\\mu\\) - population mean\n  \\(\\sigma^2\\) - population variance\n  Statistic A statistic is a descriptive measure of a sample. For example, sample mean, sample standard deviation, etc. We will talk about the notations under estimator and estimate.\n Random Variable Before introducing random variable, let me very shortly recall what is a random experiment and what is a sample space.\nA random experiment is a physical situation whose outcome cannot be predicted with certainty until it is observed. A random experiment can be repeated as many times as we want under the same conditions (leading to different outcomes). Each one of them a trial. Thus, a trial is a particular performance of a random experiment.\nA Sample space is a set of all possible outcomes of a random experiment. In this blog post I use \\(\\Omega\\) to denote a sample space.\nExample 1:\nRandom Experiment: Tossing of a coin.\nSample Space: \\(\\Omega = \\{H, T\\}\\)\nlibrary(prob) tosscoin(1)  toss1 1 H 2 T Example 2:\nRandom Experiment: Toss a coin three times.\nSample Space: \\(\\Omega = \\{(H, H, H), (H, H, T), (H, T, H), (T, H, H), (H, T, T), (T, H, T), (T, T, H), (T, T, T)\\}\\)\ntosscoin(3)  toss1 toss2 toss3 1 H H H 2 T H H 3 H T H 4 T T H 5 H H T 6 T H T 7 H T T 8 T T T Definition: Random Variable\nLet \\((\\Omega, \\mathscr{F}, \\mathbb{P})\\) be a probability space. Random variable is a function \\(X: \\Omega \\rightarrow \\mathbb{R}\\) such that \\(\\forall B \\in \\mathcal{B}( \\mathbb{R} ): X^{-1}(B) \\in \\mathscr{F}\\).\nYou need Measure Theory knowledge to understand the above definition.\nLoosely speaking a Random variable is a function from the sample space to the real numbers. There are two types of random variables: i) Discrete random variable and ii) Continuous random variable. We use Roman capital letters to denote random variables (\\(X\\), \\(Y\\), \\(Z\\), \\(U\\), \\(T\\), etc.). However, as soon as a variable \\(X\\) is observed, the observed values are represented by the corresponding simple Roman letter.\nThe notation \\(X(\\omega)\\) denotes the numerical value of the random variable X, when the outcome of the experiment is some particular \\(\\omega\\).\nAn example will help you to understand how this works. To start with, let’s consider a simple experiment with two possible outcomes: PCR test result of a randomly selected individual.\nThe random variable \\(X\\) can be defined as follows:\nSolution 1.1\nSample space\n\\[\\Omega = \\{Positive, Negative\\}\\]\nRandom variable\n\\[ X(\\omega)= \\begin{cases} 0,\u0026amp; \\text{if } \\omega = Negative\\\\ 1, \u0026amp; \\text{if } \\omega = Positive \\end{cases} \\]\nSolution 1.2\nSimply drop \\(\\omega\\) and define the random variable as follows:\n\\[ X= \\begin{cases} 0,\u0026amp; \\text{if the test result is negative. } \\\\ 1, \u0026amp; \\text{if the test result is positive.} \\end{cases} \\]\nLet’s consider another experiment. The experiment consists in selecting a random undergraduate student in the University during a period of one week, and measuring their height.\nThe random variable \\(Y\\) can be defined as follows:\n\\[\\Omega = \\{ \\omega: \\omega \u0026gt; 0\\}\\]\n\\[Y(\\omega) = \\omega, \\text{ } \\omega \\in \\Omega. \\]\nor\n\\[Y = \\text{Height in cm.}\\]\n Notations for Random Variables and Observed Data (in Sampling) Suppose you have a random variable \\(X\\). Suppose we repeat the random experiment \\(n\\) times. Then the resulting random variables are denoted by \\(X_1, X_2, ..., X_n\\). All \\(X_i\\)’s have the same distribution as \\(X\\). The random variables \\(X_1, X_2, ..., X_n\\) are collectively referred to as a random sample.\nLet’s try to understand the concept with an example.\n\\[ X_i= \\begin{cases} 0,\u0026amp; \\text{if the test result of the } i^{th} \\text { is negaive } \\\\ 1, \u0026amp; \\text{if the test result of the } i^{th} \\text { is positive, } \\end{cases} \\]\nwhere \\(i = 1, 2, 3, 4, 5.\\)\nWe performed the PCR test on randomly selected 5 individuals. We called this sample 1. The results are \\(x_1=1, x_2=0, x_3=0, x_4=1, x_5=1\\).\nPrior to obtaining \\(x_1, x_2, x_3, x_4, x_5\\), there is uncertainty about the values of each \\(x_i\\). Because of this uncertainty, before the results becomes available we view each observation as a random variable and denote the sample by \\(X_1, X_2, X_3, X_4, X_5\\).\nWe again performed the PCR test on another randomly selected 5 individuals. We called this sample 2. Now results are \\(x_1=0, x_2=0, x_3=0, x_4=1, x_5=0\\).\nYou can see observable values for \\(X_1, X_2, X_3, X_4, X_5\\) vary from sample to sample.\n Estimator and Estimate Distinction between the terms Estimator and Estimate is important.\nLet \\(X_1, X_2, ..., X_n\\) be a random sample from a distribution function \\(f_X(x)\\) that depends on a unknown parameter \\(\\theta\\).\nAn estimator is a statistic, \\(T = f(X_1, ..., X_n)\\), that is used to estimate the unknown unknown parameter, \\(\\theta\\), based on an observed sample of \\(x_1, x_2, ..., x_n\\). The \\(t=f(x_1, x_2, ..., x_n)\\) is an estimate of \\(\\theta\\).\nEstimator: An estimator is always a random variable.\n\\(\\hat{\\theta} = T = f(X_1, ..., X_n)\\)\nEstimate: An estimate is a constant.\n\\(\\hat{\\theta} = t = f(x_1, ..., x_n)\\)\nNote that we use \\(\\hat{\\theta}\\) for both estimator and estimate.\nEstimator is a function of observable random variables that is used to estimate an unknown parameter \\(\\theta\\). The corresponding estimate is obtained by substituting the observed values to the estimator. You can also think of an estimator as the rule (equation) that is used to compute an estimate. For example, the sample mean, \\(\\bar{X}\\), is an estimator that is used to estimate the population mean, \\(\\mu\\).\nBelow example is useful to understand the concepts.\nLet’s say you wanted to know the mean height of undergraduates in a certain university with a population of 1000 undergraduates. You take a random sample of 10 students and measure their height. The observed values are (in cm) 150, 155, 160, 161, 162, 152, 140, 141, 150, 155. Suppose you want to use sample mean to estimate the population mean.\nThe parameter we want to estimate is, \\(\\mu\\), population mean (mean height of the students in the university.).\nThere are infinitely many possible estimators for \\(\\mu\\). For example, sample mean, sample median. In this example we use sample mean to estimate \\(\\mu\\). Now, let’s write the estimator using the notations.\nTo do this, we first define random variables \\(X_1, X_2, X_3, ..., X_{10}\\) as follows: \\(X_1\\) is the height of the \\(1^{st}\\) chosen person, \\(X_2\\) be the height of the \\(2^{nd}\\) chosen person,…. In general, \\(X_i\\) is the height of the \\(i^{th}\\) student chosen from the population.\nNow we can write the estimator as\n\\[\\hat{\\mu} = \\bar{X}=\\frac{X_1 + X_2 + X_3 + ... + X_{10}}{10}.\\]\nThe estimate is\n\\[\\hat{\\mu}=152.6\\text{ cm}.\\]\nmean(c(150, 155, 160, 161, 162, 152, 140, 141, 150, 155)) [1] 152.6 If you are not given the observed values of \\(X_1, X_2, X_3, ..., X_{10}\\), you can write the estimate as\n\\[\\hat{\\mu} = \\frac{x_1 + x_2 + x_3 + ... + x_{10}}{10}.\\]\nThe observed value of the estimator varies from sample to sample.\n Usage Writing distributions  \\[X \\sim Bin(10, 0.6)\\]\n\\[f_X(x) = P(X=x) = {10\\choose x} 0.6^x 0.4^{(10-x)}\\]\n\\[f_X(5) = P(X=5) = {10\\choose 5} 0.6^5 0.4^{(10-5)} = 0.37\\]\npbinom(5, 10, 0.6) [1] 0.3668967 Calculation of expectations  \\[E(\\text{Estimator}) = \\text{Parameter}\\]\n\\[E(\\bar{X}) = \\mu\\]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n ","date":1593820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593820800,"objectID":"28af02174a7bbd23b46a22c223833d3c","permalink":"/post/statterms1/","publishdate":"2020-07-04T00:00:00Z","relpermalink":"/post/statterms1/","section":"post","summary":"The most common problem while learning Statistics is that students’ lack of understanding of the basic terminologies, notations, definitions and concepts. Think of Statistics as building blocks, and you need a solid foundation to move forward. Here, I explain five common terms in Statistics: i) Parameter, ii) Statistic, iii) Random Variable, iv) Estimator, v) Estimate and their notations.\nI will start with the definition of Population and Sample.\nA population is a complete collection of individuals/ objects that we are interested in.","tags":null,"title":"Parameter, Statistic, Random Variable, Estimator and Estimate","type":"post"},{"authors":null,"categories":["Mathematics","Nature","STEM","Science","Women in STEM"],"content":" Nature is my biggest inspiration for my love and passion for mathematics. It is amazing to see how these leaves follow geometry to ensure the surface is optimized for the absorption of sunlight. Indeed, nature is a good Mathematician. All its presentations are well calculated and designed. I see a great artist or a designer inside every Mathematician. Maths will teach you how to hold your brush, how to mix your paints and how to manage your tools for a great design.\nEnjoy the spirit of Mathematics!\n“Nature is my biggest inspiration for my love and passion for mathematics” - meet Dr Thiyanga Talagala @thiyangt - a former ACEMS student @MonashEBS and now a lecturer at @usjp - watch her #WomenInMaths day video: https://t.co/wPwAcyVunm #WomenInSTEM @MonashBusiness #may12wim pic.twitter.com/xkWtOb4Rzu — 𝘼𝘾𝙀𝙈𝙎 (@ACEMathStats) May 11, 2020   Acknowledgement:\nAustralian Mathematical Society\nACEMS: Australian Research Council Centre of Excellence For Mathematical and Statistical Frontiers\nTim Macuga from Australian Research Council Centre of Excellence For Mathematical and Statistical Frontiers\n","date":1589328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589328000,"objectID":"ee910fd77d392b41eb2bb0b534ab3598","permalink":"/post/mathsday2020/","publishdate":"2020-05-13T00:00:00Z","relpermalink":"/post/mathsday2020/","section":"post","summary":"Nature is my biggest inspiration for my love and passion for mathematics.","tags":["Mathematics","Nature","STEM","Science","Women in STEM"],"title":"Happy Women in Maths Day - 12 May 2020","type":"post"},{"authors":null,"categories":null,"content":"Dataset 1 Consumers\u0026rsquo; use of Food Labels Food industry is one of the fastest moving industrial sectors. The glamorous and glittering retail shops and supermarkets are expanding very fast all over the country. The majority of food is pre-packed and presented to the consumer in a labelled container. This study was conducted to evaluate the consumers\u0026rsquo; level of knowledge and use of information provided on food labels in making purchasing decisions. A structured questionnaire-based survey was used for the purpose of the study. This is a cross sectional study done over a period of five months from October, 2010 to March, 2011 with an average of seven interviews being conducted each week. The survey was conducted at supermarkets, retail shops of various sizes in five towns: Colombo 02, Kottawa, Maharagama, Nugegoda and Horana in Sri Lanka. A total of 586 respondents were considered for the study. The dataset and the questionnaire used in this studey can be downloaded from the following links. Please see the questionnaire for the column name description.\nDataset: foodlabel.csv\nQuestionnaire: Consumers\u0026rsquo; awareness and use of food label information\n","date":1587945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587945600,"objectID":"14d3c170913d26174b91d02eadcd3690","permalink":"/project/datasets/","publishdate":"2020-04-27T00:00:00Z","relpermalink":"/project/datasets/","section":"project","summary":"Data sets for teaching data analysis.","tags":["Demo"],"title":"Teaching Statistics","type":"project"},{"authors":null,"categories":["R","shiny","plotly"],"content":" Visit here: https://statisticsmart.shinyapps.io/coronaSLDashboard/#section-summary\n Code The code behind this dashboard is available on GitHub.\n Data The raw data is pulled from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository (through corona package in R) and Covid-19 Situation reports published by Epidemiology Unit, Ministry of Health and Indigenous Medical Services, Sri Lanka.\n Update The map data is as of Sunday March 22, 2020 and the dashboard has been updated on Friday March 27, 2020.\n To explore Global trend use Rami Krispin’s dashboard Visit: https://ramikrispin.github.io/coronavirus_dashboard/\n  ","date":1585094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585094400,"objectID":"b0baea41e94eb0a90af9f2fb95f2c0aa","permalink":"/post/covid19/","publishdate":"2020-03-25T00:00:00Z","relpermalink":"/post/covid19/","section":"post","summary":"Dashboard to monitor COVID-19 situation in Sri Lanka. This dashboard is built with R using the R Makrdown framework and was adapted from “coronavirus_dashboard” by Rami Krispin.","tags":["R","shiny","plotly"],"title":"Dashboard to monitor COVID-19 situation in Sri Lanka","type":"post"},{"authors":null,"categories":null,"content":"","date":1576713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576713600,"objectID":"50d915ce7d2050b866480e5d0af3f138","permalink":"/project/rladies/","publishdate":"2019-12-19T00:00:00Z","relpermalink":"/project/rladies/","section":"project","summary":"R-Ladies is a worldwide organization whose mission is to promote diversity in the R community.","tags":["Demo"],"title":"R-Ladies Colombo","type":"project"},{"authors":null,"categories":null,"content":"Abstract\nThis work presents two feature-based forecasting algorithms for large-scale time series forecasting. The algorithms involve computing a range of features of the time series which are then used to select the forecasting model. The forecasting model selection process is carried out using a pre-trained classifier. In our first algorithm we use a random forest algorithm to train the classifier. We call this framework FFORMS (Feature-based FORecast Model Selection). The second algorithm use efficient Bayesian multivariate surface regression approach to estimate forecast error for each method, and then using the minimum predicted error to select a forecasting model. Both algorithms have been evaluated using time series from the M4 competition, and is shown to yield accurate forecasts comparable to several benchmarks and other commonly used automated approaches in the time series forecasting literature. The methods are made available in the seer and fformpp packages in R.\nkeywords: Meta-learning, classification, surface regression\n","date":1562265000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562265000,"objectID":"af8c5c25ef74d00311b839d5dad2d118","permalink":"/talk/user19-talk/","publishdate":"2019-07-05T00:00:00+05:30","relpermalink":"/talk/user19-talk/","section":"talk","summary":"Abstract\nThis work presents two feature-based forecasting algorithms for large-scale time series forecasting. The algorithms involve computing a range of features of the time series which are then used to select the forecasting model. The forecasting model selection process is carried out using a pre-trained classifier. In our first algorithm we use a random forest algorithm to train the classifier. We call this framework FFORMS (Feature-based FORecast Model Selection). The second algorithm use efficient Bayesian multivariate surface regression approach to estimate forecast error for each method, and then using the minimum predicted error to select a forecasting model.","tags":null,"title":"Feature-based Time Series Forecasting","type":"talk"},{"authors":null,"categories":null,"content":"Abstract\nPeeking inside FFORMS: Feature-based FORecast Model Selection Thiyanga S. Talagala$^1$, Rob J. Hyndman$^1$, George Athanasopoulos$^1$\n$^1$Department of Econometrics and Business Statistics, Monash University, Australia\nFeatures of time series are useful in identifying suitable forecast models. Talagala, Hyndman \u0026amp; Athanasopoulos (2018) proposed a classification framework, called FFORMS (Feature-based FORecast Model Selection), which selects forecast models based on features calculated from the time series. The FFORMS framework builds a mapping that relates the features of a time series to the “best” forecast model using the random forest algorithm. In this paper we explore what is happening under the hood of the FFORMS framework and thereby gain an understanding of what features lead to the different choices of forecast models and how different features influence the predicted outcome. This is accomplished using model-agnostic machine learning interpretability approaches. Partial-dependency plots are used to visualize both main and interaction effects of features. The results of this study provide a valuable insight into how different features and their interactions affect the choice of forecast model selection. This gives a more refined picture of the relationship between features and the choice of forecast model which is particularly valuable for ongoing research in the field of feature-based time series analysis.\nKeywords: forecasting, time series, machine learning interpretability, black-box models, LIME\nReferences Talagala, TS, RJ Hyndman \u0026amp; G Athanasopoulos (2018). Meta-learning how to forecast time series. Working paper 6/18. Monash University, Department of Econometrics and Business Statistics\n","date":1560191400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560191400,"objectID":"71cd3124761c0328036aa141606bdbee","permalink":"/talk/isf19-talk/","publishdate":"2019-06-11T00:00:00+05:30","relpermalink":"/talk/isf19-talk/","section":"talk","summary":"Abstract\nPeeking inside FFORMS: Feature-based FORecast Model Selection Thiyanga S. Talagala$^1$, Rob J. Hyndman$^1$, George Athanasopoulos$^1$\n$^1$Department of Econometrics and Business Statistics, Monash University, Australia\nFeatures of time series are useful in identifying suitable forecast models. Talagala, Hyndman \u0026amp; Athanasopoulos (2018) proposed a classification framework, called FFORMS (Feature-based FORecast Model Selection), which selects forecast models based on features calculated from the time series. The FFORMS framework builds a mapping that relates the features of a time series to the “best” forecast model using the random forest algorithm.","tags":null,"title":"Peeking inside FFORMS: Feature-based FORecast Model Selection","type":"talk"},{"authors":null,"categories":["dplyr"],"content":" Packages\nlibrary(tidyverse) Load iris data set\ndata(\u0026quot;iris\u0026quot;) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa summarise: to summarize only a single column iris %\u0026gt;% group_by(Species) %\u0026gt;% summarise(mean(Sepal.Length)) ## # A tibble: 3 x 2 ## Species `mean(Sepal.Length)` ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa 5.01 ## 2 versicolor 5.94 ## 3 virginica 6.59  summarise_all: to summarize all columns iris %\u0026gt;% group_by(Species) %\u0026gt;% summarise_all(.funs = c(mean=\u0026quot;mean\u0026quot;)) ## # A tibble: 3 x 5 ## Species Sepal.Length_me… Sepal.Width_mean Petal.Length_me… ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa 5.01 3.43 1.46 ## 2 versic… 5.94 2.77 4.26 ## 3 virgin… 6.59 2.97 5.55 ## # … with 1 more variable: Petal.Width_mean \u0026lt;dbl\u0026gt;  summarise_at: to summarize only certain columns iris %\u0026gt;% group_by(Species) %\u0026gt;% summarise_at( .vars = vars(Sepal.Length, Sepal.Width), .funs = c(mean=\u0026quot;mean\u0026quot;)) ## # A tibble: 3 x 3 ## Species Sepal.Length_mean Sepal.Width_mean ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa 5.01 3.43 ## 2 versicolor 5.94 2.77 ## 3 virginica 6.59 2.97  summarise_if iris %\u0026gt;% group_by(Species) %\u0026gt;% summarise_if(.predicate = function(x) is.numeric(x), .funs = funs(mean=\u0026quot;mean\u0026quot;)) ## Warning: funs() is soft deprecated as of dplyr 0.8.0 ## Please use a list of either functions or lambdas: ## ## # Simple named list: ## list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: ## tibble::lst(mean, median) ## ## # Using lambdas ## list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## This warning is displayed once per session. ## # A tibble: 3 x 5 ## Species Sepal.Length_me… Sepal.Width_mean Petal.Length_me… ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa 5.01 3.43 1.46 ## 2 versic… 5.94 2.77 4.26 ## 3 virgin… 6.59 2.97 5.55 ## # … with 1 more variable: Petal.Width_mean \u0026lt;dbl\u0026gt; pass multiple functions\niris %\u0026gt;% group_by(Species) %\u0026gt;% summarise_if(.predicate = function(x) is.numeric(x), .funs = funs(mean=\u0026quot;mean\u0026quot;, Sd=\u0026quot;sd\u0026quot;)) ## # A tibble: 3 x 9 ## Species Sepal.Length_me… Sepal.Width_mean Petal.Length_me… ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa 5.01 3.43 1.46 ## 2 versic… 5.94 2.77 4.26 ## 3 virgin… 6.59 2.97 5.55 ## # … with 5 more variables: Petal.Width_mean \u0026lt;dbl\u0026gt;, Sepal.Length_Sd \u0026lt;dbl\u0026gt;, ## # Sepal.Width_Sd \u0026lt;dbl\u0026gt;, Petal.Length_Sd \u0026lt;dbl\u0026gt;, Petal.Width_Sd \u0026lt;dbl\u0026gt;  ","date":1558137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558137600,"objectID":"2184788d8c1b820cb4a3887072f53140","permalink":"/post/dplyr/","publishdate":"2019-05-18T00:00:00Z","relpermalink":"/post/dplyr/","section":"post","summary":"Summarizing variables with dplyr","tags":["R","dplyr"],"title":"Summarizing with dplyr","type":"post"},{"authors":["Thiyanga S. Talagala"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":null,"categories":["R","tidyverse","gganimate"],"content":" h2 { /* Header 2 */ font-size: 22px; color: DarkBlue; }  install packages To install multiple packages with a single call to install.packages, pass the names of the packages as a character vector to the install.packages() function.\ninstall.packages(c(\u0026quot;gganimate\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;gapminder\u0026quot;))  load packages Once you have the packages installed, you can make their contents available to use in your current R session by running,\nlapply(c(\u0026quot;gganimate\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;gapminder\u0026quot;), require, character.only = TRUE) ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE  check and install missing packages list.of.packages \u0026lt;- c(\u0026quot;gganimate\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;gapminder\u0026quot;) new.packages \u0026lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,\u0026quot;Package\u0026quot;])] if(length(new.packages)) install.packages(new.packages)  For other alternatives see littler  library(littler) install.r EIAdata gdata ggmap ggplot2  ipak  ipak \u0026lt;- function(pkg){ new.pkg \u0026lt;- pkg[!(pkg %in% installed.packages()[, \u0026quot;Package\u0026quot;])] if (length(new.pkg)) install.packages(new.pkg, dependencies = TRUE) sapply(pkg, require, character.only = TRUE) } # usage packages \u0026lt;- c(\u0026quot;gganimate\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;gapminder\u0026quot;) ipak(packages) ## gganimate tidyverse gapminder ## TRUE TRUE TRUE easypackages   ","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553212800,"objectID":"e9aed67f73f88a04797b48235d695908","permalink":"/post/multiplepkg/","publishdate":"2019-03-22T00:00:00Z","relpermalink":"/post/multiplepkg/","section":"post","summary":"Install multiple R packages at once/ check and install missing packages.","tags":["R","tidyverse","gganimate"],"title":"How to install and load multiple packages at once?","type":"post"},{"authors":null,"categories":null,"content":"Abstract\nThis work presents three feature-based algorithms for large-scale time series forecasting. The algorithms are developed based on meta-learning approach. In our first algorithm we use a random forest algorithm to identify the best forecasting model. We call this framework FFORMS (Feature-based FORecast Model Selection). In the second algorithm, FFORMA (Feature-based FORecast Model Averaging), we use gradient boosting to obtain the weights for forecast combinations. The third algorithm use efficient Bayesian multivariate surface regression approach to estimate forecast error for each method, and then using the minimum predicted error to select a forecasting model or to choose individual models for forecast combinations. The proposed algorithms perform well compared to several benchmarks and other commonly used approaches in large-scale forecasting.\n","date":1552415400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552415400,"objectID":"c68ed0dd55537c2b8012a18a3b0168f3","permalink":"/talk/beijingtalk19-talk/","publishdate":"2019-03-13T00:00:00+05:30","relpermalink":"/talk/beijingtalk19-talk/","section":"talk","summary":"Abstract\nThis work presents three feature-based algorithms for large-scale time series forecasting. The algorithms are developed based on meta-learning approach. In our first algorithm we use a random forest algorithm to identify the best forecasting model. We call this framework FFORMS (Feature-based FORecast Model Selection). In the second algorithm, FFORMA (Feature-based FORecast Model Averaging), we use gradient boosting to obtain the weights for forecast combinations. The third algorithm use efficient Bayesian multivariate surface regression approach to estimate forecast error for each method, and then using the minimum predicted error to select a forecasting model or to choose individual models for forecast combinations.","tags":null,"title":"Feature-based time series forecasting","type":"talk"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three  A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":["R","Rmarkdown"],"content":"   alpha: beta: gamma delta   \\alpha : \\(\\alpha\\) \\beta: \\(\\beta\\) \\gamma: \\(\\gamma\\) \\delta: \\(\\delta\\)     \\Gamma: \\(\\Gamma\\) \\Delta: \\(\\Delta\\)   epsilon Zeta eta theta   \\epsilon: \\(\\epsilon\\) \\zeta: \\(\\zeta\\) \\eta: \\(\\eta\\) \\theta: \\(\\theta\\)   \\varepsilon: \\(\\varepsilon\\)   \\Theta: \\(\\Theta\\)   iota kappa lambda mu   \\iota: \\(\\iota\\) \\kappa: \\(\\kappa\\) \\lambda: \\(\\lambda\\) \\mu: \\(\\mu\\)   nu xi pi rho   \\nu: \\(\\nu\\) \\xi: \\(\\xi\\) \\pi: \\(\\pi\\) \\rho: \\(\\rho\\)    \\Xi: \\(\\Xi\\) \\Pi: \\(\\Pi\\)    sigma upsilon phi omicron   \\sigma: \\(\\sigma\\) \\upsilon: \\(\\upsilon\\) \\phi: \\(\\phi\\) \\omicron: \\(\\omicron\\)   \\Sigma: \\(\\Sigma\\)  \\Phi: \\(\\Phi\\)    tau chi psi Omega   \\tau: \\(\\tau\\) \\chi: \\(\\chi\\) \\psi: \\(\\psi\\) \\omega: \\(\\omega\\)     \\Psi: \\(\\Psi\\) \\Omega: \\(\\Omega\\)     ","date":1548720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548720000,"objectID":"366ba74a62a81c39577622b6c92c2105","permalink":"/post/greekletters/","publishdate":"2019-01-29T00:00:00Z","relpermalink":"/post/greekletters/","section":"post","summary":"Commands to type Greek letters on Rmarkdown or Latex","tags":["R","Rmarkdown"],"title":"Some useful Greek letters you might use on your reports","type":"post"},{"authors":null,"categories":["R","dplyr"],"content":" Sometimes we need to view all the functions that are built into an R package. This is done in the same way you would list variables in your workspace, using the ls function. Note that the package must be loaded before you run the ls command.\nUsage: Getting a list of functions inside the dplyr package\nlibrary(dplyr) ls(\u0026quot;package:dplyr\u0026quot;) ## [1] \u0026quot;%\u0026gt;%\u0026quot; \u0026quot;add_count\u0026quot; ## [3] \u0026quot;add_count_\u0026quot; \u0026quot;add_row\u0026quot; ## [5] \u0026quot;add_rownames\u0026quot; \u0026quot;add_tally\u0026quot; ## [7] \u0026quot;add_tally_\u0026quot; \u0026quot;all_equal\u0026quot; ## [9] \u0026quot;all_vars\u0026quot; \u0026quot;anti_join\u0026quot; ## [11] \u0026quot;any_vars\u0026quot; \u0026quot;arrange\u0026quot; ## [13] \u0026quot;arrange_\u0026quot; \u0026quot;arrange_all\u0026quot; ## [15] \u0026quot;arrange_at\u0026quot; \u0026quot;arrange_if\u0026quot; ## [17] \u0026quot;as_data_frame\u0026quot; \u0026quot;as_label\u0026quot; ## [19] \u0026quot;as_tibble\u0026quot; \u0026quot;as.tbl\u0026quot; ## [21] \u0026quot;as.tbl_cube\u0026quot; \u0026quot;auto_copy\u0026quot; ## [23] \u0026quot;band_instruments\u0026quot; \u0026quot;band_instruments2\u0026quot; ## [25] \u0026quot;band_members\u0026quot; \u0026quot;bench_tbls\u0026quot; ## [27] \u0026quot;between\u0026quot; \u0026quot;bind_cols\u0026quot; ## [29] \u0026quot;bind_rows\u0026quot; \u0026quot;case_when\u0026quot; ## [31] \u0026quot;changes\u0026quot; \u0026quot;check_dbplyr\u0026quot; ## [33] \u0026quot;coalesce\u0026quot; \u0026quot;collapse\u0026quot; ## [35] \u0026quot;collect\u0026quot; \u0026quot;combine\u0026quot; ## [37] \u0026quot;common_by\u0026quot; \u0026quot;compare_tbls\u0026quot; ## [39] \u0026quot;compare_tbls2\u0026quot; \u0026quot;compute\u0026quot; ## [41] \u0026quot;contains\u0026quot; \u0026quot;copy_to\u0026quot; ## [43] \u0026quot;count\u0026quot; \u0026quot;count_\u0026quot; ## [45] \u0026quot;cumall\u0026quot; \u0026quot;cumany\u0026quot; ## [47] \u0026quot;cume_dist\u0026quot; \u0026quot;cummean\u0026quot; ## [49] \u0026quot;current_vars\u0026quot; \u0026quot;data_frame\u0026quot; ## [51] \u0026quot;data_frame_\u0026quot; \u0026quot;db_analyze\u0026quot; ## [53] \u0026quot;db_begin\u0026quot; \u0026quot;db_commit\u0026quot; ## [55] \u0026quot;db_create_index\u0026quot; \u0026quot;db_create_indexes\u0026quot; ## [57] \u0026quot;db_create_table\u0026quot; \u0026quot;db_data_type\u0026quot; ## [59] \u0026quot;db_desc\u0026quot; \u0026quot;db_drop_table\u0026quot; ## [61] \u0026quot;db_explain\u0026quot; \u0026quot;db_has_table\u0026quot; ## [63] \u0026quot;db_insert_into\u0026quot; \u0026quot;db_list_tables\u0026quot; ## [65] \u0026quot;db_query_fields\u0026quot; \u0026quot;db_query_rows\u0026quot; ## [67] \u0026quot;db_rollback\u0026quot; \u0026quot;db_save_query\u0026quot; ## [69] \u0026quot;db_write_table\u0026quot; \u0026quot;dense_rank\u0026quot; ## [71] \u0026quot;desc\u0026quot; \u0026quot;dim_desc\u0026quot; ## [73] \u0026quot;distinct\u0026quot; \u0026quot;distinct_\u0026quot; ## [75] \u0026quot;distinct_all\u0026quot; \u0026quot;distinct_at\u0026quot; ## [77] \u0026quot;distinct_if\u0026quot; \u0026quot;distinct_prepare\u0026quot; ## [79] \u0026quot;do\u0026quot; \u0026quot;do_\u0026quot; ## [81] \u0026quot;dr_dplyr\u0026quot; \u0026quot;ends_with\u0026quot; ## [83] \u0026quot;enexpr\u0026quot; \u0026quot;enexprs\u0026quot; ## [85] \u0026quot;enquo\u0026quot; \u0026quot;enquos\u0026quot; ## [87] \u0026quot;ensym\u0026quot; \u0026quot;ensyms\u0026quot; ## [89] \u0026quot;eval_tbls\u0026quot; \u0026quot;eval_tbls2\u0026quot; ## [91] \u0026quot;everything\u0026quot; \u0026quot;explain\u0026quot; ## [93] \u0026quot;expr\u0026quot; \u0026quot;failwith\u0026quot; ## [95] \u0026quot;filter\u0026quot; \u0026quot;filter_\u0026quot; ## [97] \u0026quot;filter_all\u0026quot; \u0026quot;filter_at\u0026quot; ## [99] \u0026quot;filter_if\u0026quot; \u0026quot;first\u0026quot; ## [101] \u0026quot;frame_data\u0026quot; \u0026quot;full_join\u0026quot; ## [103] \u0026quot;funs\u0026quot; \u0026quot;funs_\u0026quot; ## [105] \u0026quot;glimpse\u0026quot; \u0026quot;group_by\u0026quot; ## [107] \u0026quot;group_by_\u0026quot; \u0026quot;group_by_all\u0026quot; ## [109] \u0026quot;group_by_at\u0026quot; \u0026quot;group_by_drop_default\u0026quot; ## [111] \u0026quot;group_by_if\u0026quot; \u0026quot;group_by_prepare\u0026quot; ## [113] \u0026quot;group_cols\u0026quot; \u0026quot;group_data\u0026quot; ## [115] \u0026quot;group_indices\u0026quot; \u0026quot;group_indices_\u0026quot; ## [117] \u0026quot;group_keys\u0026quot; \u0026quot;group_map\u0026quot; ## [119] \u0026quot;group_modify\u0026quot; \u0026quot;group_nest\u0026quot; ## [121] \u0026quot;group_rows\u0026quot; \u0026quot;group_size\u0026quot; ## [123] \u0026quot;group_split\u0026quot; \u0026quot;group_trim\u0026quot; ## [125] \u0026quot;group_vars\u0026quot; \u0026quot;group_walk\u0026quot; ## [127] \u0026quot;grouped_df\u0026quot; \u0026quot;groups\u0026quot; ## [129] \u0026quot;hybrid_call\u0026quot; \u0026quot;id\u0026quot; ## [131] \u0026quot;ident\u0026quot; \u0026quot;if_else\u0026quot; ## [133] \u0026quot;inner_join\u0026quot; \u0026quot;intersect\u0026quot; ## [135] \u0026quot;is_grouped_df\u0026quot; \u0026quot;is.grouped_df\u0026quot; ## [137] \u0026quot;is.src\u0026quot; \u0026quot;is.tbl\u0026quot; ## [139] \u0026quot;lag\u0026quot; \u0026quot;last\u0026quot; ## [141] \u0026quot;last_col\u0026quot; \u0026quot;lead\u0026quot; ## [143] \u0026quot;left_join\u0026quot; \u0026quot;location\u0026quot; ## [145] \u0026quot;lst\u0026quot; \u0026quot;lst_\u0026quot; ## [147] \u0026quot;make_tbl\u0026quot; \u0026quot;matches\u0026quot; ## [149] \u0026quot;min_rank\u0026quot; \u0026quot;mutate\u0026quot; ## [151] \u0026quot;mutate_\u0026quot; \u0026quot;mutate_all\u0026quot; ## [153] \u0026quot;mutate_at\u0026quot; \u0026quot;mutate_each\u0026quot; ## [155] \u0026quot;mutate_each_\u0026quot; \u0026quot;mutate_if\u0026quot; ## [157] \u0026quot;n\u0026quot; \u0026quot;n_distinct\u0026quot; ## [159] \u0026quot;n_groups\u0026quot; \u0026quot;na_if\u0026quot; ## [161] \u0026quot;nasa\u0026quot; \u0026quot;near\u0026quot; ## [163] \u0026quot;nest_join\u0026quot; \u0026quot;new_grouped_df\u0026quot; ## [165] \u0026quot;nth\u0026quot; \u0026quot;ntile\u0026quot; ## [167] \u0026quot;num_range\u0026quot; \u0026quot;one_of\u0026quot; ## [169] \u0026quot;order_by\u0026quot; \u0026quot;percent_rank\u0026quot; ## [171] \u0026quot;progress_estimated\u0026quot; \u0026quot;pull\u0026quot; ## [173] \u0026quot;quo\u0026quot; \u0026quot;quo_name\u0026quot; ## [175] \u0026quot;quos\u0026quot; \u0026quot;rbind_all\u0026quot; ## [177] \u0026quot;rbind_list\u0026quot; \u0026quot;recode\u0026quot; ## [179] \u0026quot;recode_factor\u0026quot; \u0026quot;rename\u0026quot; ## [181] \u0026quot;rename_\u0026quot; \u0026quot;rename_all\u0026quot; ## [183] \u0026quot;rename_at\u0026quot; \u0026quot;rename_if\u0026quot; ## [185] \u0026quot;rename_vars\u0026quot; \u0026quot;rename_vars_\u0026quot; ## [187] \u0026quot;right_join\u0026quot; \u0026quot;row_number\u0026quot; ## [189] \u0026quot;rowwise\u0026quot; \u0026quot;same_src\u0026quot; ## [191] \u0026quot;sample_frac\u0026quot; \u0026quot;sample_n\u0026quot; ## [193] \u0026quot;select\u0026quot; \u0026quot;select_\u0026quot; ## [195] \u0026quot;select_all\u0026quot; \u0026quot;select_at\u0026quot; ## [197] \u0026quot;select_if\u0026quot; \u0026quot;select_var\u0026quot; ## [199] \u0026quot;select_vars\u0026quot; \u0026quot;select_vars_\u0026quot; ## [201] \u0026quot;semi_join\u0026quot; \u0026quot;setdiff\u0026quot; ## [203] \u0026quot;setequal\u0026quot; \u0026quot;show_query\u0026quot; ## [205] \u0026quot;slice\u0026quot; \u0026quot;slice_\u0026quot; ## [207] \u0026quot;sql\u0026quot; \u0026quot;sql_escape_ident\u0026quot; ## [209] \u0026quot;sql_escape_string\u0026quot; \u0026quot;sql_join\u0026quot; ## [211] \u0026quot;sql_select\u0026quot; \u0026quot;sql_semi_join\u0026quot; ## [213] \u0026quot;sql_set_op\u0026quot; \u0026quot;sql_subquery\u0026quot; ## [215] \u0026quot;sql_translate_env\u0026quot; \u0026quot;src\u0026quot; ## [217] \u0026quot;src_df\u0026quot; \u0026quot;src_local\u0026quot; ## [219] \u0026quot;src_mysql\u0026quot; \u0026quot;src_postgres\u0026quot; ## [221] \u0026quot;src_sqlite\u0026quot; \u0026quot;src_tbls\u0026quot; ## [223] \u0026quot;starts_with\u0026quot; \u0026quot;starwars\u0026quot; ## [225] \u0026quot;storms\u0026quot; \u0026quot;summarise\u0026quot; ## [227] \u0026quot;summarise_\u0026quot; \u0026quot;summarise_all\u0026quot; ## [229] \u0026quot;summarise_at\u0026quot; \u0026quot;summarise_each\u0026quot; ## [231] \u0026quot;summarise_each_\u0026quot; \u0026quot;summarise_if\u0026quot; ## [233] \u0026quot;summarize\u0026quot; \u0026quot;summarize_\u0026quot; ## [235] \u0026quot;summarize_all\u0026quot; \u0026quot;summarize_at\u0026quot; ## [237] \u0026quot;summarize_each\u0026quot; \u0026quot;summarize_each_\u0026quot; ## [239] \u0026quot;summarize_if\u0026quot; \u0026quot;sym\u0026quot; ## [241] \u0026quot;syms\u0026quot; \u0026quot;tally\u0026quot; ## [243] \u0026quot;tally_\u0026quot; \u0026quot;tbl\u0026quot; ## [245] \u0026quot;tbl_cube\u0026quot; \u0026quot;tbl_df\u0026quot; ## [247] \u0026quot;tbl_nongroup_vars\u0026quot; \u0026quot;tbl_sum\u0026quot; ## [249] \u0026quot;tbl_vars\u0026quot; \u0026quot;tibble\u0026quot; ## [251] \u0026quot;top_frac\u0026quot; \u0026quot;top_n\u0026quot; ## [253] \u0026quot;transmute\u0026quot; \u0026quot;transmute_\u0026quot; ## [255] \u0026quot;transmute_all\u0026quot; \u0026quot;transmute_at\u0026quot; ## [257] \u0026quot;transmute_if\u0026quot; \u0026quot;tribble\u0026quot; ## [259] \u0026quot;trunc_mat\u0026quot; \u0026quot;type_sum\u0026quot; ## [261] \u0026quot;ungroup\u0026quot; \u0026quot;union\u0026quot; ## [263] \u0026quot;union_all\u0026quot; \u0026quot;validate_grouped_df\u0026quot; ## [265] \u0026quot;vars\u0026quot; \u0026quot;with_order\u0026quot; ## [267] \u0026quot;wrap_dbplyr_obj\u0026quot; ","date":1538697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538697600,"objectID":"bde5482c31ba3daddffaeeb0e02e40fb","permalink":"/post/packageinfo/","publishdate":"2018-10-05T00:00:00Z","relpermalink":"/post/packageinfo/","section":"post","summary":"Sometimes we need to view all the functions that are built into an R package.","tags":["R","dplyr"],"title":"What's in a package?","type":"post"},{"authors":null,"categories":["ggplot2"],"content":" Boxplot is probably one of the most common type of graphics. This will show how to customize boxplots.\nYou will learn,\n how to change the order of labels\n how to change the colours\n how to flip coordinates\n  Step 1: we create a simple data set.\nGender \u0026lt;- rep(c(\u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;), times = 3, each = 4) Quality \u0026lt;- rep(c(\u0026quot;Taste\u0026quot;, \u0026quot;Color of package\u0026quot;, \u0026quot;Capacity\u0026quot;), times = 1, each = 8) Accepted \u0026lt;- seq(0, 100, by = 100/23) DF \u0026lt;- data.frame(Gender, Quality, Accepted) head(DF) ## Gender Quality Accepted ## 1 Male Taste 0.000000 ## 2 Male Taste 4.347826 ## 3 Male Taste 8.695652 ## 4 Male Taste 13.043478 ## 5 Female Taste 17.391304 ## 6 Female Taste 21.739130 Step 2: Generate a simple boxplot with ggplot\nlibrary(ggplot2) ggplot(DF, aes(x = Quality, y = Accepted, fill = Gender)) + geom_boxplot()  Step 3: Change the colours, legend position and x-axis order\nggplot(DF, aes(x = Quality, y = Accepted, fill = Gender)) + geom_boxplot() + scale_fill_manual(values = c(\u0026quot;green\u0026quot;, \u0026quot;orange\u0026quot;)) + xlab(\u0026quot;\u0026quot;) + theme(legend.position = \u0026quot;top\u0026quot;, legend.title = element_blank()) + scale_x_discrete(limits=c(\u0026quot;Taste\u0026quot;, \u0026quot;Color of package\u0026quot;, \u0026quot;Capacity\u0026quot;)) Step 4: Change the plotting order: first you have to include factor code to set the order of the levels.\nDF$Gender_factor \u0026lt;- factor(DF$Gender, levels=c(\u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;)) ggplot(DF, aes(x = Quality, y = Accepted, fill = Gender_factor)) + geom_boxplot() + scale_fill_manual(values = c(\u0026quot;green\u0026quot;, \u0026quot;orange\u0026quot;)) + xlab(\u0026quot;\u0026quot;) + theme(legend.position = \u0026quot;top\u0026quot;, legend.title = element_blank()) + scale_x_discrete(limits=c(\u0026quot;Taste\u0026quot;, \u0026quot;Color of package\u0026quot;, \u0026quot;Capacity\u0026quot;)) Step 5: Horizontal bar chart: coord_flip()\nggplot(DF, aes(x = Quality, y = Accepted, fill = Gender)) + geom_boxplot() + scale_fill_manual(values = c(\u0026quot;green\u0026quot;, \u0026quot;orange\u0026quot;)) + xlab(\u0026quot;\u0026quot;) + theme(legend.position = \u0026quot;top\u0026quot;, legend.title = element_blank()) + coord_flip()+ scale_x_discrete(limits=c(\u0026quot;Taste\u0026quot;, \u0026quot;Color of package\u0026quot;, \u0026quot;Capacity\u0026quot;)) step 6: Change the legend order similar to plot order: under themes fill=guide_legend(reverse=FALSE)\nggplot(DF, aes(x = Quality, y = Accepted, fill = Gender)) + geom_boxplot() + scale_fill_manual(values = c(\u0026quot;green\u0026quot;, \u0026quot;orange\u0026quot;)) + xlab(\u0026quot;\u0026quot;) + theme(legend.position = \u0026quot;top\u0026quot;, legend.title = element_blank()) + guides(fill=guide_legend(reverse=TRUE)) + coord_flip()+ scale_x_discrete(limits=c(\u0026quot;Taste\u0026quot;, \u0026quot;Color of package\u0026quot;, \u0026quot;Capacity\u0026quot;)) ","date":1536105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536105600,"objectID":"448a002415287871d904008f85fcf5ae","permalink":"/post/blog/","publishdate":"2018-09-05T00:00:00Z","relpermalink":"/post/blog/","section":"post","summary":"Boxplot is probably one of the most common type of graphics. This will show how to customize boxplots.","tags":["R","ggplot2"],"title":"Customizing boxplots with ggplot2","type":"post"},{"authors":null,"categories":null,"content":"Working on this..\n","date":1533666600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533666600,"objectID":"8c3f1d8fe352dc1260f12152b785396e","permalink":"/post/parallelcomputing/","publishdate":"2018-08-08T00:00:00+05:30","relpermalink":"/post/parallelcomputing/","section":"post","summary":"Working on this..","tags":[],"title":"Parallel computing with R","type":"post"},{"authors":null,"categories":null,"content":"coming up soon!\n","date":1533580200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533580200,"objectID":"0544e9fe6dc4756a98072e0a4dca1b8e","permalink":"/post/datatypes/","publishdate":"2018-08-07T00:00:00+05:30","relpermalink":"/post/datatypes/","section":"post","summary":"coming up soon!","tags":[],"title":"Data Types in R","type":"post"},{"authors":null,"categories":null,"content":"Abstract\nMany applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making. However, large scale time series data present numerous challenges in modelling and implementation due to the high dimensionality. It is unlikely that a single method will consistently provides better forecasts across all time series. On the other hand, selecting individual forecast models when the number of series is very large can be extremely challenging. In this paper we propose a classification framework which selects forecast models based on features calculated from the time series. A Random Forest approach is used to develop the classifier. The proposed framework is tested using the M3 data and is compared against several benchmarks and other commonly used approaches of forecasting.\n","date":1498415400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498415400,"objectID":"e9693cefbfbe4b5fc9d03b6ee5b201ff","permalink":"/talk/isf17-talk/","publishdate":"2017-06-26T00:00:00+05:30","relpermalink":"/talk/isf17-talk/","section":"talk","summary":"Abstract\nMany applications require a large number of time series to be forecast. Providing better forecasts for these time series is important in decision and policy making. However, large scale time series data present numerous challenges in modelling and implementation due to the high dimensionality. It is unlikely that a single method will consistently provides better forecasts across all time series. On the other hand, selecting individual forecast models when the number of series is very large can be extremely challenging.","tags":null,"title":"Feature-based model selection for time series forecasting","type":"talk"},{"authors":null,"categories":null,"content":"The background pictures are of free copyright from https://pixabay.com/en/photos/presentation/.\nAssociated R package: seer\n","date":1483209000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483209000,"objectID":"e92016f7160966baa922bf6dcf76c69f","permalink":"/talk/jsm18-talk/","publishdate":"2017-01-01T00:00:00+05:30","relpermalink":"/talk/jsm18-talk/","section":"talk","summary":"https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=330245","tags":null,"title":"A classification framework for forecast-model selection","type":"talk"},{"authors":null,"categories":null,"content":"","date":1483209000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483209000,"objectID":"99fad8d2730a91524d4a348202ea3b47","permalink":"/talk/japan18-talk/","publishdate":"2017-01-01T00:00:00+05:30","relpermalink":"/talk/japan18-talk/","section":"talk","summary":"","tags":null,"title":"Analysing large collections of time series","type":"talk"},{"authors":null,"categories":null,"content":"","date":1483209000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483209000,"objectID":"c7ba5016f60dbd4bb60ee207effd5b93","permalink":"/talk/ssa17-talk/","publishdate":"2017-01-01T00:00:00+05:30","relpermalink":"/talk/ssa17-talk/","section":"talk","summary":"","tags":null,"title":"Feature-based model selection for time series forecasting","type":"talk"},{"authors":null,"categories":null,"content":"","date":1483209000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483209000,"objectID":"fcda67318c59693ce49660d71b6fdf6f","permalink":"/talk/ysc17-talk/","publishdate":"2017-01-01T00:00:00+05:30","relpermalink":"/talk/ysc17-talk/","section":"talk","summary":"","tags":null,"title":"Feature-based model selection for time series forecasting","type":"talk"},{"authors":null,"categories":null,"content":"Abstract\nA crucial task in time series forecasting is the identification of the most suitable forecasting method. We present a general framework for forecast model selection using meta-learning. A Random Forest is used to predict the best forecasting method using only time series features. The proposed framework has been evaluated using time series from the M1 and M3 competitions, and is shown to yield accurate forecasts comparable to several benchmarks and other commonly used automated approaches of time series forecasting. A key advantage of our algorithm is that the time-consuming part of building the random forest can be handled in advance of the forecasting task.\n","date":1483209000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483209000,"objectID":"299ac0d759174f6116404efa6267869a","permalink":"/talk/isf18-talk/","publishdate":"2017-01-01T00:00:00+05:30","relpermalink":"/talk/isf18-talk/","section":"talk","summary":"Abstract\nA crucial task in time series forecasting is the identification of the most suitable forecasting method. We present a general framework for forecast model selection using meta-learning. A Random Forest is used to predict the best forecasting method using only time series features. The proposed framework has been evaluated using time series from the M1 and M3 competitions, and is shown to yield accurate forecasts comparable to several benchmarks and other commonly used automated approaches of time series forecasting.","tags":null,"title":"Meta-learning how to forecast time series","type":"talk"},{"authors":null,"categories":null,"content":"Abstract\nThe seer package provides a novel framework for forecast model selection using time series features. We call this framework FFORMS (Feature-based FORecast Model Selection). The underlying approach involves computing a vector of features from the time series which are then used to select the forecasting model. The model selection process is carried out using a classification algorithm \u0026ndash; we use the time series features as inputs, and the best forecasting algorithm as the output. The classification algorithm can be built in advance of the forecasting exercise (so it is an “offline” procedure). Then, when we have a new time series to forecast, we can quickly compute its features, use the pre-trained classification algorithm to identify the best forecasting model, and produce the required forecasts. Thus, the “online” part of our algorithm requires only feature computation, and the application of a single forecasting model, with no need to estimate large numbers of models within a class, or to carry out a computationally-intensive cross-validation procedure. This framework is compared against several benchmarks and other commonly used forecasting methods.\nLink to git repository: seer\n","date":1483209000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483209000,"objectID":"55dccf4c5a29dd82879bd4f918a420a2","permalink":"/talk/user18-talk/","publishdate":"2017-01-01T00:00:00+05:30","relpermalink":"/talk/user18-talk/","section":"talk","summary":"Abstract\nThe seer package provides a novel framework for forecast model selection using time series features. We call this framework FFORMS (Feature-based FORecast Model Selection). The underlying approach involves computing a vector of features from the time series which are then used to select the forecasting model. The model selection process is carried out using a classification algorithm \u0026ndash; we use the time series features as inputs, and the best forecasting algorithm as the output.","tags":null,"title":"seer: R package for feature-based forecast model selection","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e6c4171b3bda35c314832458341d0a1a","permalink":"/project/timeseries/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/timeseries/","section":"project","summary":"Computationally efficient forecasting methods for large-scale real-time applications","tags":["Demo"],"title":"Large-Scale Time Series Forecasting","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"5b7dc0394d1ea428e0024d4ead7f0b16","permalink":"/project/hellor/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/hellor/","section":"project","summary":"The course website for my teaching unit STA 326 2.0 Programming and Data Analysis with R","tags":["Demo"],"title":"Programming and Data Analysis with R","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1e861e939c4099fff7d4ea706e24220","permalink":"/project/dengue/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/dengue/","section":"project","summary":"Potential impacts of climate change on dengue fever","tags":["Demo"],"title":"Small Bite Big threat","type":"project"},{"authors":["Thiyanga S. Talagala","Robert Ford"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Thiyanga S. Talagala","Robert Ford"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]